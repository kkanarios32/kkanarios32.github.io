<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors>
      <fr:author>
        <fr:link href="https://kkanarios32.github.io/Tommi%20Jaakkola/" type="external">Tommi Jaakkola</fr:link>
      </fr:author>
      <fr:author>
        <fr:link href="https://kkanarios32.github.io/Michael%20I%20Jordan/" type="external">Michael I Jordan</fr:link>
      </fr:author>
      <fr:author>
        <fr:link href="https://kkanarios32.github.io/Satinder%20P%20Singh/" type="external">Satinder P Singh</fr:link>
      </fr:author>
    </fr:authors>
    <fr:uri>https://kkanarios32.github.io/jaakkolaConvergenceStochasticIterative/</fr:uri>
    <fr:display-uri>jaakkolaConvergenceStochasticIterative</fr:display-uri>
    <fr:route>/jaakkolaConvergenceStochasticIterative/</fr:route>
    <fr:title text="On the Convergence of Stochastic Iterative Dynamic Programming Algorithms">On the Convergence of Stochastic Iterative Dynamic Programming Algorithms</fr:title>
    <fr:taxon>Reference</fr:taxon>
    <fr:meta name="bibtex"><![CDATA[@article{jaakkolaConvergenceStochasticIterative,
 title = {On the {{Convergence}} of {{Stochastic Iterative Dynamic Programming Algorithms}}},
 author = {Jaakkola, Tommi and Jordan, Michael I and Singh, Satinder P},
 file = {/home/kellen/Zotero/storage/95ZWX95X/Jaakkola et al. - On the Convergence of Stochastic Iterative Dynamic Programming Algorithms.pdf},
 langid = {english},
 abstract = {Recent developments in the area of reinforcement learning have yielded a number of new algorithms for the prediction and control of Markovian environments. These algorithms, including the TD( ) algorithm of Sutton (1988) and the Q-learning algorithm of Watkins (1989), can be motivated heuristically as approximations to dynamic programming (DP). In this paper we provide a rigorous proof of convergence of these DP-based learning algorithms by relating them to the powerful techniques of stochastic approximation theory via a new convergence theorem. The theorem establishes a general class of convergent algorithms to which both TD( ) and Q-learning belong.}
}]]></fr:meta>
  </fr:frontmatter>
  <fr:mainmatter />
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
