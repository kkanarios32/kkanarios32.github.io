<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors>
      <fr:author>
        <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
      </fr:author>
    </fr:authors>
    <fr:date>
      <fr:year>2025</fr:year>
      <fr:month>6</fr:month>
      <fr:day>12</fr:day>
    </fr:date>
    <fr:uri>https://kellenkanarios.com/007S/</fr:uri>
    <fr:display-uri>007S</fr:display-uri>
    <fr:route>/007S/</fr:route>
    <fr:title text="Weeknotes">Weeknotes</fr:title>
  </fr:frontmatter>
  <fr:mainmatter>
    <html:p>Here I will document my progress for the week along with other miscellaneous things I feel like disclosing publicly.</html:p>
    <fr:tree show-metadata="true" expanded="false" numbered="false">
      <fr:frontmatter>
        <fr:authors>
          <fr:author>
            <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
          </fr:author>
        </fr:authors>
        <fr:uri>https://kellenkanarios.com/2025-W29/</fr:uri>
        <fr:display-uri>2025-W29</fr:display-uri>
        <fr:route>/2025-W29/</fr:route>
        <fr:title text="Weekly Review 2025-W29">Weekly Review 2025-W29</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:title text="The Quantified Me">The Quantified Me</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>This section is in large part to gaslight myself on the internet into being more productive but with the information provided let us introspect on what happened this week. </html:p>
  <html:p><html:strong>Coding:</html:strong> I will now proceed to justify and provide excuses on what went wrong this week. On Monday, we see that I spent a large part of my time on this forest. However, this was actually writing up my notes on <fr:link href="/ESQ3/" title="CS336 Lecture 3" uri="https://kellenkanarios.com/ESQ3/" display-uri="ESQ3" type="local">lecture 3</fr:link> of <fr:link href="/0085/" title="Notebook: Stanford CS336" uri="https://kellenkanarios.com/0085/" display-uri="0085" type="local">CS336</fr:link>. My goal of roughly 1ish hour of miscellaneous learning a day snowballed into what was seemingly <fr:tex display="inline"><![CDATA[4]]></fr:tex> hours of random activity, where I spiraled into <fr:link href="/W4YP/" title="Multi Query Attention" uri="https://kellenkanarios.com/W4YP/" display-uri="W4YP" type="local">MQA</fr:link>. I am thinking of putting this self-study on the backburner in favor of focusing on <fr:link href="/0084/" title="Notebook: Three Easy Pieces" uri="https://kellenkanarios.com/0084/" display-uri="0084" type="local">three easy pieces</fr:link> until the semester starts. I intend to take two courses on what is essentially LLMs systems this fall (very excited), so I might as well not double dip now. I am thinking about using projects 1 and 2 of this course to develop my own working LLM implementation. I can then use it as reference to try out and learn any new optimization tricks like <fr:link href="/W4YP/" title="Multi Query Attention" uri="https://kellenkanarios.com/W4YP/" display-uri="W4YP" type="local">MQA</fr:link> or <fr:link href="https://kellenkanarios.com/TJLA/" type="external">TJLA</fr:link>, etc. 
  <html:p>These plots also finally confirm what I noticed as a general trend in my working life. Namely, I spend a lot of time working Monday-Thu because of my weekly meetings with my advisor on Thursday. However, I do not properly make use of the rest of the week. This is a trend I hope to improve upon in future entries.</html:p></html:p>
<html:figure><html:img width="100%" src="/bafkrmibvtysmzc5gyedcfaj2sxjpviob6lxrcdiontte4cg4zu3cueiv7u.png" />
  <html:figcaption>Wakatime stats for week 2025-W29.</html:figcaption></html:figure>
  <html:p><html:strong>Rest of (computer) life:</html:strong> This week I did a pretty good job staying on task (at least on my computer). Very little brainrot was consumed and a decent amount of work was accomplished. Tune in next week to see if we can keep that up!
  </html:p>
<html:figure><html:img width="100%" src="/bafkrmie3tohm4dhy7zqt47zdirbm4xxk432rr4n3yncjdggmq4zetriwku.png" />
  <html:figcaption>Arbtt-stats for week 2025-W29.</html:figcaption></html:figure>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:title text="VO2 Max(ing)">VO2 Max(ing)</fr:title></fr:frontmatter><fr:mainmatter>
  <html:ul><html:li><html:strong>Current VO2 Max</html:strong>: 53</html:li>
    <html:li><html:strong>Weekly Mileage</html:strong>: 17.2</html:li></html:ul>
  <html:p>Unfortunately, I missed one run this week. The same one I miss every week: Sunday. I will still blame the shin splints, but this may be the last week I can do so (finally!). I am still maintaining a pretty good SPM, but I need to get some more lower HR runs in. From here on out, we should not dip below 20 miles a week. I have some travel coming up at <fr:link href="/rlc/" title="Reinforcement Learning Conference" uri="https://kellenkanarios.com/rlc/" display-uri="rlc" type="local">RLC</fr:link>, but I should be able to still run while I am there.</html:p>
<html:figure><html:img width="100%" src="/bafkrmicxnrelkrspghbameeb74obgst3bk2dj5vlirqeq73qymd7jsjuny.png" />
  <html:figcaption>Running stats for this week.</html:figcaption></html:figure>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:title text="Goals for next week">Goals for next week</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>This is another section, where I gaslight myself into some accountability on the internet.</html:p>
<html:p>For my imaginary audience, you should have a lot to look forward to in the next week. Namely, 
<html:ol><html:li>Look forward to an in-depth blog on <fr:link href="/lipmanFlowMatchingGenerative2023/" title="Flow Matching for Generative Modeling" uri="https://kellenkanarios.com/lipmanFlowMatchingGenerative2023/" display-uri="lipmanFlowMatchingGenerative2023" type="local">flow matching</fr:link> to accompany my <fr:link href="/FMTD/" title="Flow Matching and TD Flows" uri="https://kellenkanarios.com/FMTD/" display-uri="FMTD" type="local">slides</fr:link>.</html:li>
<html:li>I also should have two new <fr:link href="/005G/" title="Research Bible" uri="https://kellenkanarios.com/005G/" display-uri="005G" type="local">research bible</fr:link> entries one on the <fr:link href="/touatiLearningOneRepresentation2021/" title="Learning One Representation to Optimize All Rewards" uri="https://kellenkanarios.com/touatiLearningOneRepresentation2021/" display-uri="touatiLearningOneRepresentation2021" type="local">forward backward representation</fr:link> and the other on <fr:link href="/nachumNearOptimalRepresentationLearning2019/" title="Near-Optimal Representation Learning for Hierarchical Reinforcement Learning" uri="https://kellenkanarios.com/nachumNearOptimalRepresentationLearning2019/" display-uri="nachumNearOptimalRepresentationLearning2019" type="local">hierarchical rl</fr:link>.</html:li>
<html:li>For my <fr:link href="/0084/" title="Notebook: Three Easy Pieces" uri="https://kellenkanarios.com/0084/" display-uri="0084" type="local">OS adventure</fr:link>, you should see me (hopefully) get through memory virtualization.
However, I should definitely get to at least the TLB. Unlikely, I will continue to do all the exercises (because I spend more time writing them down than doing them). I might do one or two of the projects, but they are quite intimidating TBD.</html:li></html:ol>
Check back in next week to see if I am productive! Also TBD if in the future I will put research-related stuff in this review.
</html:p>
</fr:mainmatter></fr:tree>
</fr:mainmatter>
    </fr:tree>
  </fr:mainmatter>
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>Yaron Lipman</fr:author>
              <fr:author>Ricky T. Q. Chen</fr:author>
              <fr:author>Heli Ben-Hamu</fr:author>
              <fr:author>Maximilian Nickel</fr:author>
              <fr:author>Matt Le</fr:author>
            </fr:authors>
            <fr:date>
              <fr:year>2023</fr:year>
              <fr:month>2</fr:month>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/lipmanFlowMatchingGenerative2023/</fr:uri>
            <fr:display-uri>lipmanFlowMatchingGenerative2023</fr:display-uri>
            <fr:route>/lipmanFlowMatchingGenerative2023/</fr:route>
            <fr:title text="Flow Matching for Generative Modeling">Flow Matching for Generative Modeling</fr:title>
            <fr:taxon>Reference</fr:taxon>
            <fr:meta name="doi">10.48550/arXiv.2210.02747</fr:meta>
            <fr:meta name="external">https://arxiv.org/abs/2210.02747</fr:meta>
            <fr:meta name="bibtex"><![CDATA[@misc{lipmanFlowMatchingGenerative2023,
 title = {Flow {{Matching}} for {{Generative Modeling}}},
 author = {Lipman, Yaron and Chen, Ricky T. Q. and {Ben-Hamu}, Heli and Nickel, Maximilian and Le, Matt},
 year = {2023},
 doi = {10.48550/arXiv.2210.02747},
 urldate = {2025-06-20},
 number = {arXiv:2210.02747},
 publisher = {arXiv},
 file = {/home/kellen/Downloads/pdfs/storage/WMMQDW4B/Lipman et al. - 2023 - Flow Matching for Generative Modeling.pdf;/home/kellen/Downloads/pdfs/storage/R693NNL4/2210.html},
 keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
 archiveprefix = {arXiv},
 abstract = {We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples -- which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers.},
 primaryclass = {cs},
 eprint = {2210.02747},
 month = {February}
}]]></fr:meta>
          </fr:frontmatter>
          <fr:mainmatter />
        </fr:tree>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>Ahmed Touati</fr:author>
              <fr:author>Yann Ollivier</fr:author>
            </fr:authors>
            <fr:date>
              <fr:year>2021</fr:year>
              <fr:month>10</fr:month>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/touatiLearningOneRepresentation2021/</fr:uri>
            <fr:display-uri>touatiLearningOneRepresentation2021</fr:display-uri>
            <fr:route>/touatiLearningOneRepresentation2021/</fr:route>
            <fr:title text="Learning One Representation to Optimize All Rewards">Learning One Representation to Optimize All Rewards</fr:title>
            <fr:taxon>Reference</fr:taxon>
            <fr:meta name="doi">10.48550/arXiv.2103.07945</fr:meta>
            <fr:meta name="external">https://arxiv.org/abs/2103.07945</fr:meta>
            <fr:meta name="bibtex"><![CDATA[@misc{touatiLearningOneRepresentation2021,
 title = {Learning {{One Representation}} to {{Optimize All Rewards}}},
 author = {Touati, Ahmed and Ollivier, Yann},
 year = {2021},
 doi = {10.48550/arXiv.2103.07945},
 urldate = {2024-09-18},
 number = {arXiv:2103.07945},
 publisher = {arXiv},
 file = {/home/kellen/Downloads/pdfs/storage/FN8MPGES/Touati and Ollivier - 2021 - Learning One Representation to Optimize All Rewards.pdf;/home/kellen/Downloads/pdfs/storage/SXVNRKWC/2103.html},
 keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Optimization and Control},
 archiveprefix = {arXiv},
 abstract = {We introduce the forward-backward (FB) representation of the dynamics of a reward-free Markov decision process. It provides explicit near-optimal policies for any reward specified a posteriori. During an unsupervised phase, we use reward-free interactions with the environment to learn two representations via off-the-shelf deep learning methods and temporal difference (TD) learning. In the test phase, a reward representation is estimated either from observations or an explicit reward description (e.g., a target state). The optimal policy for that reward is directly obtained from these representations, with no planning. We assume access to an exploration scheme or replay buffer for the first phase. The corresponding unsupervised loss is well-principled: if training is perfect, the policies obtained are provably optimal for any reward function. With imperfect training, the sub-optimality is proportional to the unsupervised approximation error. The FB representation learns long-range relationships between states and actions, via a predictive occupancy map, without having to synthesize states as in model-based approaches. This is a step towards learning controllable agents in arbitrary black-box stochastic environments. This approach compares well to goal-oriented RL algorithms on discrete and continuous mazes, pixel-based MsPacman, and the FetchReach virtual robot arm. We also illustrate how the agent can immediately adapt to new tasks beyond goal-oriented RL.},
 primaryclass = {cs, math},
 eprint = {2103.07945},
 month = {October}
}]]></fr:meta>
          </fr:frontmatter>
          <fr:mainmatter />
        </fr:tree>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>Ofir Nachum</fr:author>
              <fr:author>Shixiang Gu</fr:author>
              <fr:author>Honglak Lee</fr:author>
              <fr:author>Sergey Levine</fr:author>
            </fr:authors>
            <fr:date>
              <fr:year>2019</fr:year>
              <fr:month>1</fr:month>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/nachumNearOptimalRepresentationLearning2019/</fr:uri>
            <fr:display-uri>nachumNearOptimalRepresentationLearning2019</fr:display-uri>
            <fr:route>/nachumNearOptimalRepresentationLearning2019/</fr:route>
            <fr:title text="Near-Optimal Representation Learning for Hierarchical Reinforcement Learning">Near-Optimal Representation Learning for Hierarchical Reinforcement Learning</fr:title>
            <fr:taxon>Reference</fr:taxon>
            <fr:meta name="external">https://arxiv.org/abs/1810.01257</fr:meta>
            <fr:meta name="bibtex"><![CDATA[@misc{nachumNearOptimalRepresentationLearning2019,
 title = {Near-{{Optimal Representation Learning}} for {{Hierarchical Reinforcement Learning}}},
 author = {Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
 year = {2019},
 urldate = {2024-11-07},
 number = {arXiv:1810.01257},
 publisher = {arXiv},
 file = {/home/kellen/Downloads/pdfs/storage/SIK848RC/Nachum et al. - 2019 - Near-Optimal Representation Learning for Hierarchical Reinforcement Learning.pdf},
 keywords = {Computer Science - Artificial Intelligence},
 langid = {english},
 archiveprefix = {arXiv},
 abstract = {We study the problem of representation learning in goal-conditioned hierarchical reinforcement learning. In such hierarchical structures, a higher-level controller solves tasks by iteratively communicating goals which a lower-level policy is trained to reach. Accordingly, the choice of representation -- the mapping of observation space to goal space -- is crucial. To study this problem, we develop a notion of sub-optimality of a representation, defined in terms of expected reward of the optimal hierarchical policy using this representation. We derive expressions which bound the sub-optimality and show how these expressions can be translated to representation learning objectives which may be optimized in practice. Results on a number of difficult continuous-control tasks show that our approach to representation learning yields qualitatively better representations as well as quantitatively better hierarchical policies, compared to existing methods (see videos at https://sites.google.com/view/representation-hrl).},
 primaryclass = {cs},
 eprint = {1810.01257},
 month = {January}
}]]></fr:meta>
          </fr:frontmatter>
          <fr:mainmatter />
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>
                <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
              </fr:author>
            </fr:authors>
            <fr:uri>https://kellenkanarios.com/about/</fr:uri>
            <fr:display-uri>about</fr:display-uri>
            <fr:route>/about/</fr:route>
            <fr:title text="Kellen Kanarios › About this website"><fr:link href="/index/" title="Kellen Kanarios" uri="https://kellenkanarios.com/index/" display-uri="index" type="local">Kellen Kanarios</fr:link> › About this website</fr:title>
          </fr:frontmatter>
          <fr:mainmatter>
            <html:p>
    This is my <fr:link href="https://www.forester-notes.org/index/index.xml" type="external">forest</fr:link> (shoutout to <fr:link href="/jonmsterling/" title="Jon Sterling" uri="https://kellenkanarios.com/jonmsterling/" display-uri="jonmsterling" type="local">Jon Sterling</fr:link> who is remarkably helpful). This website functions both as a <fr:link href="https://en.wikipedia.org/wiki/Personal_knowledge_management" type="external">personal knowledge management system</fr:link>, where I store my notes in <fr:link href="/0015/" title="Notebooks" uri="https://kellenkanarios.com/0015/" display-uri="0015" type="local">notebooks</fr:link> and also have some additional external resources in <fr:link href="/0004/" title="/dev/null" uri="https://kellenkanarios.com/0004/" display-uri="0004" type="local">/dev/null</fr:link>. Additionally, I store my thoughts in a variety of consumption mediums. Namely, short-form notes / blog posts can be found in the "<fr:link href="/007L/" title="Marginalia" uri="https://kellenkanarios.com/007L/" display-uri="007L" type="local">marginalia</fr:link>". I also maintain two weekly posting obligations: a <fr:link href="/007S/" title="Weeknotes" uri="https://kellenkanarios.com/007S/" display-uri="007S" type="local">weeknotes / lifelog</fr:link> and a <fr:link href="/005G/" title="Research Bible" uri="https://kellenkanarios.com/005G/" display-uri="005G" type="local">paper of the week</fr:link>. 
      </html:p>
          </fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
