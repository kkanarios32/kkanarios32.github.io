<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors />
    <fr:date>
      <fr:year>2024</fr:year>
      <fr:month>11</fr:month>
      <fr:day>4</fr:day>
    </fr:date>
    <fr:uri>https://kkanarios32.github.io/000C/</fr:uri>
    <fr:display-uri>000C</fr:display-uri>
    <fr:route>/000C/</fr:route>
    <fr:title text="Maximize Mutual info">Maximize Mutual info</fr:title>
    <fr:taxon>Theorem</fr:taxon>
  </fr:frontmatter>
  <fr:mainmatter><html:p><fr:tex display="inline"><![CDATA[\mathcal {L}_N]]></fr:tex> from <fr:link href="/vandenOord2018/" title="Contrastive Predictive Decoding" uri="https://kkanarios32.github.io/vandenOord2018/" display-uri="vandenOord2018" type="local">Contrastive Predictive Decoding</fr:link> maximizes a lower bound on the <fr:link href="/000V/" title="Mutual Information" uri="https://kkanarios32.github.io/000V/" display-uri="000V" type="local">Mutual Information</fr:link> between <fr:tex display="inline"><![CDATA[x_{t + k}]]></fr:tex> and <fr:tex display="inline"><![CDATA[c_t]]></fr:tex>.</html:p>
   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>All we must do is plug <fr:tex display="inline"><![CDATA[\frac {p(x \mid  c)}{p(x)}]]></fr:tex> back into the objective.
  <fr:tex display="block"><![CDATA[\begin {align*}
    \mathcal {L}_{\mathbb {N}}^{\text {opt}}&=-\,\mathbb {E}\log \left [\frac {\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}}{\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}+\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}}\right ] \\
    &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\
    &\approx \mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}(N-1)\,\mathbb {E}\,\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\
    &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k} \mid  c_t)}N\right ] \\
    &\geq  \mathbb {E} \log  \left [\frac {p(x_{t + k})}{p(x_{t + k} \mid  c_t)}N \right ] \\
    &= - I(x_{t + k}, c_t) + \log  N
 \end {align*}
  ]]></fr:tex>
</fr:mainmatter></fr:tree>
 

</fr:mainmatter>
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors />
            <fr:uri>https://kkanarios32.github.io/vandenOord2018/</fr:uri>
            <fr:display-uri>vandenOord2018</fr:display-uri>
            <fr:route>/vandenOord2018/</fr:route>
            <fr:title text="Contrastive Predictive Decoding">Contrastive Predictive Decoding</fr:title>
            <fr:taxon>Reference</fr:taxon>
            <fr:meta name="doi">10.48550/arXiv.1807.03748</fr:meta>
            <fr:meta name="bibtex"><![CDATA[@misc{oord2019representationlearningcontrastivepredictive,
      title={Representation Learning with Contrastive Predictive Coding}, 
      author={Aaron van den Oord and Yazhe Li and Oriol Vinyals},
      year={2019},
      eprint={1807.03748},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1807.03748}, 
}]]></fr:meta>
          </fr:frontmatter>
          <fr:mainmatter />
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors />
            <fr:date>
              <fr:year>2024</fr:year>
              <fr:month>10</fr:month>
              <fr:day>31</fr:day>
            </fr:date>
            <fr:uri>https://kkanarios32.github.io/0009/</fr:uri>
            <fr:display-uri>0009</fr:display-uri>
            <fr:route>/0009/</fr:route>
            <fr:title text="Contrastive Learning">Contrastive Learning</fr:title>
          </fr:frontmatter>
          <fr:mainmatter><html:p>Prior to understanding contrastive reinforcement learning, it is important to have an at least rudimentary understanding of contrastive learning. Historically, contrastive learning has been used to learn representations. The fundamental idea behind contrastive learning is to encourage the representations of similar outputs to be similar in representation space.</html:p><html:p><html:strong>Supervised setting:</html:strong> For now, assume we are in the supervised setting (we have access to lables). Suppose that we are learning a representation in <fr:tex display="inline"><![CDATA[\mathbb {R}^d]]></fr:tex>. Our model is a classifier on dogs and cats. If we have two dogs <fr:tex display="inline"><![CDATA[y_1]]></fr:tex> and <fr:tex display="inline"><![CDATA[y_2]]></fr:tex> then we want the learned representation map <fr:tex display="block"><![CDATA[\phi : \{\text {dogs}, \text {cats}\} \to  \mathbb {R}^d]]></fr:tex> to be such that <fr:tex display="inline"><![CDATA[\phi (y_1)]]></fr:tex> and <fr:tex display="inline"><![CDATA[\phi (y_2)]]></fr:tex> are "close" in <fr:tex display="inline"><![CDATA[\mathbb {R}^d]]></fr:tex>. Now the notion of "close" is to be determined by the user. An example could be to minimize the inner product between their representation maps i.e. we could learn a feature map parametrized by <fr:tex display="inline"><![CDATA[\theta ]]></fr:tex> with the following objective <fr:tex display="block"><![CDATA[\max _{\theta }\ \langle  \phi _{\theta }(y_1), \phi _{\theta }(y_2) \rangle .]]></fr:tex> Similarly, we want dissimilar outputs to be far apart in representation space. If <fr:tex display="inline"><![CDATA[y_3]]></fr:tex> is a cat, then we can introduce a regularization to encourage this i.e.
<fr:tex display="block"><![CDATA[\max _{\theta }\ \langle  \phi _{\theta }(y_1), \phi _{\theta }(y_2) \rangle  - \sum _{i \in  \{1, 2\}} \langle  \phi _{\theta }(y_i), \phi _{\theta }(y_3) \rangle .]]></fr:tex></html:p><html:p><html:strong>Unsupervised setting:</html:strong> Now suppose that we get rid of labels and are just given <fr:tex display="inline"><![CDATA[n]]></fr:tex> dog samples <fr:tex display="inline"><![CDATA[\mathcal {D}]]></fr:tex> from some distribution <fr:tex display="inline"><![CDATA[p_{\mathcal {D}}]]></fr:tex>. We now want to be able to learn <fr:tex display="inline"><![CDATA[p_{\theta }]]></fr:tex> to somehow estimate this distribution. An approach is to learn to distinguish the sample dogs given from random noise. To do so, we generate <fr:tex display="inline"><![CDATA[n]]></fr:tex> random images <fr:tex display="inline"><![CDATA[\mathcal {R}]]></fr:tex> according to some distribution <fr:tex display="inline"><![CDATA[p_{\mathcal {R}}]]></fr:tex>. We can now return to the supervised learning setting, where we treat <fr:tex display="inline"><![CDATA[\mathcal {D}]]></fr:tex> and <fr:tex display="inline"><![CDATA[\mathcal {R}]]></fr:tex> as two classes. If we recall standard supervised learning practice, given a sample <fr:tex display="inline"><![CDATA[x]]></fr:tex>, we then want to find <fr:tex display="block"><![CDATA[p(\mathcal {D} \mid  x) = 1 - p(\mathcal {R} \mid  X).]]></fr:tex> 
As an explicit example, we will use logistic regression. Namely, we will model <fr:tex display="inline"><![CDATA[p(x) = p(\mathcal {D} \mid  x)]]></fr:tex> as <fr:tex display="block"><![CDATA[p_{\theta }(x) = \frac {1}{1 + e^{-G_{\theta }(x)}}.]]></fr:tex> However, <fr:tex display="inline"><![CDATA[p_{\theta }(x)]]></fr:tex> is estimating <fr:tex display="inline"><![CDATA[p(\mathcal {D} \mid  x)]]></fr:tex>, where we care about <fr:tex display="inline"><![CDATA[p(x \mid  \mathcal {D})]]></fr:tex>. To estimate the correct quantity, we need to leverage our knowledge of the noise distribution. Recall that if <fr:tex display="inline"><![CDATA[p_{\theta }(x) = p(\mathcal {D} \mid  x)]]></fr:tex> then <fr:tex display="inline"><![CDATA[G_{\theta }(x) = \log  \frac {p(x \mid  \mathcal {D})}{p(x \mid  \mathcal {R})}]]></fr:tex>. Since we generated the samples from <fr:tex display="inline"><![CDATA[\mathcal {R}]]></fr:tex>, we have the explicit distribution i.e. <fr:tex display="inline"><![CDATA[p(x \mid  \mathcal {R}) = p_{\mathcal {R}}(x)]]></fr:tex>. Therefore, we can restrict <fr:tex display="inline"><![CDATA[G_{\theta }]]></fr:tex> to explicitly learn <fr:tex display="inline"><![CDATA[p(x \mid  \mathcal {D})]]></fr:tex> by considering <fr:tex display="block"><![CDATA[G_{\theta }(x) = \log  p_{\theta }(x \mid  \mathcal {D}) - \log  p_{\mathcal {R}}(x),]]></fr:tex> considering the cross entropy loss we get the <fr:link href="https://kkanarios32.github.io/nce/" type="external">NCE loss</fr:link></html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kkanarios32.github.io/000E/</fr:uri><fr:display-uri>000E</fr:display-uri><fr:route>/000E/</fr:route><fr:title text="NCE loss">NCE loss</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The <html:em><fr:link href="https://kkanarios32.github.io/nce/" type="external">NCE</fr:link></html:em> loss aims to minimize the following objective <fr:tex display="block"><![CDATA[\mathcal {L}_{N} = - \sum _{t} \log  \left [h(x_t; \theta )\right ] + \log \left [1 - h(y_t; \theta )\right ],]]></fr:tex> where <fr:tex display="inline"><![CDATA[x_t]]></fr:tex> are samples from the data distribution and <fr:tex display="inline"><![CDATA[y_t]]></fr:tex> are randomly generated samples and <fr:tex display="block"><![CDATA[\begin {array}{r c l}{{h({\bf  u};\theta )}}&{{=}}&{{\frac {1}{1+\exp \left [-G({\bf  u};\theta )\right ]},}}\\ {{G({\bf  u};\theta )}}&{{=}}&{{\ln  p_{m}({\bf  u};\theta )-\ln  p_{n}({\bf  u}).}}\end {array}]]></fr:tex></html:p></fr:mainmatter></fr:tree><html:p>In <fr:link href="/gutmann2012/" title="Noise-contrastive Estimation" uri="https://kkanarios32.github.io/gutmann2012/" display-uri="gutmann2012" type="local">Noise-contrastive Estimation</fr:link>, they show under mild conditions that the estimator <fr:tex display="inline"><![CDATA[p_{\theta }(x \mid  D) \to  p_{\mathcal {D}}(x)]]></fr:tex> in probability as the number of samples in the loss goes to infinity. Equivalently, the estimator is <fr:link href="/000F/" title="Consistent estimator" uri="https://kkanarios32.github.io/000F/" display-uri="000F" type="local">consistent</fr:link>.</html:p><html:p><html:strong>Time series:</html:strong> Before we get to contrastive RL, it is a natural question to wonder how does this apply to temporal sequences? Concretely, we want to make predictions about the future given the current "context". However, we want to do so in an unsupervised way, meaning we are only given trajectories not a notion of what it means for a trajectory to be good. Naively, one can try to do this in a supervised manner. For a <fr:tex display="inline"><![CDATA[k]]></fr:tex> step prediction, this would just be your model predicting what will happen in <fr:tex display="inline"><![CDATA[k]]></fr:tex> steps then seeing if it matches what occured <fr:tex display="inline"><![CDATA[k]]></fr:tex> steps in the future in the sample trajectory. However, if your sample space <fr:tex display="inline"><![CDATA[\mathcal {X}]]></fr:tex> is very high-dimensional, modeling this relationship can require an exorbinant amount of trajectories.</html:p><html:p>Fast forwarding to contrastive RL, current work is primarily considered with a particular contrastive objective.</html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kkanarios32.github.io/000B/</fr:uri><fr:display-uri>000B</fr:display-uri><fr:route>/000B/</fr:route><fr:title text="InfoNCE">InfoNCE</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The <html:em><fr:link href="/vandenOord2018/" title="Contrastive Predictive Decoding" uri="https://kkanarios32.github.io/vandenOord2018/" display-uri="vandenOord2018" type="local">InfoNCE</fr:link></html:em> loss aims to minimize the following information-theoretic objective <fr:tex display="block"><![CDATA[\mathcal {L}_{N} = - \mathbb {E}_{\mathcal {X}} \left [\log  \frac {f_k(x_{t + k}, c_t)}{\sum _{x_j \in  \mathcal {X}} f_k(x_j, c_t)}\right ]]]></fr:tex></html:p></fr:mainmatter></fr:tree><html:p>Now we need to unpack this very ominous loss. To start, what are <fr:tex display="inline"><![CDATA[x_k]]></fr:tex> and <fr:tex display="inline"><![CDATA[c_t]]></fr:tex>?</html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kkanarios32.github.io/000C/</fr:uri><fr:display-uri>000C</fr:display-uri><fr:route>/000C/</fr:route><fr:title text="Maximize Mutual info">Maximize Mutual info</fr:title><fr:taxon>Theorem</fr:taxon></fr:frontmatter><fr:mainmatter><html:p><fr:tex display="inline"><![CDATA[\mathcal {L}_N]]></fr:tex> from <fr:link href="/vandenOord2018/" title="Contrastive Predictive Decoding" uri="https://kkanarios32.github.io/vandenOord2018/" display-uri="vandenOord2018" type="local">Contrastive Predictive Decoding</fr:link> maximizes a lower bound on the <fr:link href="/000V/" title="Mutual Information" uri="https://kkanarios32.github.io/000V/" display-uri="000V" type="local">Mutual Information</fr:link> between <fr:tex display="inline"><![CDATA[x_{t + k}]]></fr:tex> and <fr:tex display="inline"><![CDATA[c_t]]></fr:tex>.</html:p>
   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>All we must do is plug <fr:tex display="inline"><![CDATA[\frac {p(x \mid  c)}{p(x)}]]></fr:tex> back into the objective.
  <fr:tex display="block"><![CDATA[\begin {align*}
    \mathcal {L}_{\mathbb {N}}^{\text {opt}}&=-\,\mathbb {E}\log \left [\frac {\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}}{\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}+\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}}\right ] \\
    &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\
    &\approx \mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}(N-1)\,\mathbb {E}\,\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\
    &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k} \mid  c_t)}N\right ] \\
    &\geq  \mathbb {E} \log  \left [\frac {p(x_{t + k})}{p(x_{t + k} \mid  c_t)}N \right ] \\
    &= - I(x_{t + k}, c_t) + \log  N
 \end {align*}
  ]]></fr:tex>
</fr:mainmatter></fr:tree>
 

</fr:mainmatter></fr:tree><fr:tex display="block"><![CDATA[
\operatorname *{max}_{f(u,v)}\mathbb {E}_{(u,v^{+})\sim  p(u,v)}\left [\log \sigma (\underbrace {f(u,{\green  v^{+}})}_{\phi (u)^{T}\psi ({\green  v^{+}})})+\log (1-\sigma (\underbrace {f(u,{\red  v^{-}})}_{\phi (u)^{T}\psi ({\red  v^{-}})}))\right ]
]]></fr:tex><fr:tex display="block"><![CDATA[
\begin {align*}
&\operatorname *{max}_{f}\mathbb {E}_{(s,a)\sim  p(s,a),s_{f}^{-}\sim  p(s_{f})}\left [\mathcal {L}(s,a,s_{f}^{+},s_{f}^{-})\right ] \\
\end {align*}
]]></fr:tex><fr:tex display="block"><![CDATA[
\mathcal {L}_1(\theta ) = \log \sigma (f_{\theta }(s_1,a_1,{\color {green} s_{8}})) + \log (1-\sigma (f_{\theta }(s_1,a_1, {\color {red} s_3})))
]]></fr:tex><fr:tex display="block"><![CDATA[
\begin {align*}
\widehat {\mathcal {L}}(\theta ) &= \frac {1}{n} \sum _{i = 1}^{n} \mathcal {L}_i \\
&= \frac {1}{n} \sum _{i = 1}^{n} \Big [\log \sigma (f_{\theta }(s_i,a_i,{\color {green} s_{f}^{+}})) + \log (1-\sigma (f_{\theta }(s_i,a_i, {\color {red} s_{f}^{-}})))\Big ]
\end {align*}
]]></fr:tex><fr:tex display="block"><![CDATA[
\mathcal {L}(\theta ) = \mathbb {E}_{x \sim  p_X, y \sim  p_Y}\Big [\log \sigma (f_{\theta }(x)) + \log (1-\sigma (f_{\theta }(y)))\Big ]
]]></fr:tex><fr:tex display="block"><![CDATA[f^*(s, a, s_g) = \log \left (\frac {p^{\pi (\cdot  \mid  \cdot )}(s_g \mid  s, a)}{p(s_g)}\right )]]></fr:tex>
   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>10</fr:month><fr:day>31</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>
    We want to maximize
<fr:tex display="block"><![CDATA[
    \begin {align*}
\mathcal {L}(\theta ) &= \mathbb {E}_{x \sim  p_X, y \sim  p_Y}\Big [\log \sigma (f_{\theta }(x)) + \log (1-\sigma (f_{\theta }(y)))\Big ] \\
&= \int  \log \sigma (f_{\theta }(x)) P_X(x) + \int  \log (1-\sigma (f_{\theta }(y))) P_Y(y) \\
&= \int  \log \sigma (f_{\theta }(z)) P_X(z) + \log (1-\sigma (f_{\theta }(z))) P_Y(z)
    \end {align*}
    ]]></fr:tex>
    Since we are maximizing <fr:tex display="inline"><![CDATA[f(s)]]></fr:tex>, we can just maximize the integrand i.e.
<fr:tex display="block"><![CDATA[
      \begin {align*}
        \frac {\mathrm {d}}{\mathrm {d}f(z)} \Big [\log \sigma (f_{\theta }(z)) P_X(z) + \log (1-\sigma (f_{\theta }(z))) P_Y(z)\Big ] = 0
      \end {align*}
    ]]></fr:tex>
    Solving,
    <fr:tex display="block"><![CDATA[
        \begin {align*}
          P_X(z)\big (1 - \sigma (f(z))\big ) - P_Y(z)\sigma (f(z)) = 0 &\iff  \sigma (f(z)) = \frac {P_X(z)}{P_X(z) + P_Y(z)} \\
          &\iff  f(z) = \log \left (\frac {P_X(z)}{P_Y(z)}\right )
        \end {align*}
      ]]></fr:tex>
  </fr:mainmatter></fr:tree>
 


   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>10</fr:month><fr:day>31</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>
The first step is to prove that the average Q-values are close to the task-conditioned Q-values. Below, we will use <fr:tex display="inline"><![CDATA[R_{c}(\tau )\triangleq \sum _{\ell =0}^{\infty }\gamma ^{\ell }r_{\ell }(s_{\ell },a_{\ell })]]></fr:tex>:

<fr:tex display="block"><![CDATA[
\begin {align*}
\left |Q^{\beta (\cdot |\cdot ,a)}(s,a,e)-Q^{\beta (\cdot |\cdot ,\epsilon ^{\prime })}(s,a,e)\right |&=\left |\int \beta (\tau \mid  s,a,e)R_{e}(\tau )d\tau -\int \beta (\tau \mid  s,a,e^{\prime })R_{e}(\tau )d\tau \right |\\ 
&=\left |\int \beta (\tau \mid  s,a,e)-\beta (\tau \mid  s,a,e^{\prime })R_{e}(\tau )d\tau \right | \\
&=\left |\int \beta (\tau \mid  s,a,e)\left (1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right )R_{e}(\tau )d\tau \right | \\
&\leq \int \left |\beta (\tau \mid  s,a,e)\left (1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right )\right |d\tau \cdot \operatorname *{max}_{\tau }|R_{e}(\tau )d\tau | \\
&\leq \int \beta (\tau \mid  s,a,e)\left |1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right |d\tau \cdot  1 \\
&=\mathbb {E}_{\beta (\tau |s,a,e)}\left [\left |1-{\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}}\right |\right ] \\
&\leq  \epsilon .
\end {align*}
  ]]></fr:tex>
</fr:mainmatter></fr:tree>
 

</fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors />
            <fr:date>
              <fr:year>2024</fr:year>
              <fr:month>11</fr:month>
              <fr:day>21</fr:day>
            </fr:date>
            <fr:uri>https://kkanarios32.github.io/000V/</fr:uri>
            <fr:display-uri>000V</fr:display-uri>
            <fr:route>/000V/</fr:route>
            <fr:title text="Mutual Information">Mutual Information</fr:title>
            <fr:taxon>Definition</fr:taxon>
          </fr:frontmatter>
          <fr:mainmatter>
            <html:p>The <html:em>mutual information</html:em> between two random variables <fr:tex display="inline"><![CDATA[X, Y]]></fr:tex> is defined with respect to their joint distribution. Namely, it is the <fr:link href="/000W/" title="Kullback-Liebler Divergence" uri="https://kkanarios32.github.io/000W/" display-uri="000W" type="local">Kullback-Liebler Divergence</fr:link> between the joint distribution <fr:tex display="inline"><![CDATA[p(x,y)]]></fr:tex> and the product of the marginals <fr:tex display="inline"><![CDATA[p(x)p(y)]]></fr:tex> i.e. 
<fr:tex display="block"><![CDATA[H(X || Y) = \mathbb {E}_{x,y \sim  p(x,y)}\left [\log  \frac {p(x, y)}{p(x)p(y)}\right ]]]></fr:tex></html:p>
          </fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
