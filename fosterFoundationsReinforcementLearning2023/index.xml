<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors>
      <fr:author>Dylan J. Foster</fr:author>
      <fr:author>Alexander Rakhlin</fr:author>
    </fr:authors>
    <fr:date>
      <fr:year>2023</fr:year>
      <fr:month>12</fr:month>
    </fr:date>
    <fr:uri>https://kellenkanarios.com/fosterFoundationsReinforcementLearning2023/</fr:uri>
    <fr:display-uri>fosterFoundationsReinforcementLearning2023</fr:display-uri>
    <fr:route>/fosterFoundationsReinforcementLearning2023/</fr:route>
    <fr:title text="Foundations of Reinforcement Learning and Interactive Decision Making">Foundations of Reinforcement Learning and Interactive Decision Making</fr:title>
    <fr:taxon>Reference</fr:taxon>
    <fr:meta name="doi">10.48550/arXiv.2312.16730</fr:meta>
    <fr:meta name="external">https://arxiv.org/abs/2312.16730</fr:meta>
    <fr:meta name="bibtex"><![CDATA[@misc{fosterFoundationsReinforcementLearning2023,
 title = {Foundations of {{Reinforcement Learning}} and {{Interactive Decision Making}}},
 author = {Foster, Dylan J. and Rakhlin, Alexander},
 year = {2023},
 doi = {10.48550/arXiv.2312.16730},
 urldate = {2025-01-23},
 number = {arXiv:2312.16730},
 publisher = {arXiv},
 file = {/home/kellen/Downloads/pdfs/storage/EFVPRXIJ/Foster and Rakhlin - 2023 - Foundations of Reinforcement Learning and Interactive Decision Making.pdf;/home/kellen/Downloads/pdfs/storage/GJCWUBT3/2312.html},
 keywords = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Mathematics - Statistics Theory,Statistics - Machine Learning,Statistics - Statistics Theory},
 archiveprefix = {arXiv},
 abstract = {These lecture notes give a statistical perspective on the foundations of reinforcement learning and interactive decision making. We present a unifying framework for addressing the exploration-exploitation dilemma using frequentist and Bayesian approaches, with connections and parallels between supervised learning/estimation and decision making as an overarching theme. Special attention is paid to function approximation and flexible model classes such as neural networks. Topics covered include multi-armed and contextual bandits, structured bandits, and reinforcement learning with high-dimensional feedback.},
 primaryclass = {cs},
 eprint = {2312.16730},
 month = {December}
}]]></fr:meta>
  </fr:frontmatter>
  <fr:mainmatter />
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
