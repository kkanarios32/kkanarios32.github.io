<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors />
    <fr:date>
      <fr:year>2024</fr:year>
      <fr:month>11</fr:month>
      <fr:day>4</fr:day>
    </fr:date>
    <fr:uri>https://kellenkanarios.com/000E/</fr:uri>
    <fr:display-uri>000E</fr:display-uri>
    <fr:route>/000E/</fr:route>
    <fr:title text="NCE loss">NCE loss</fr:title>
    <fr:taxon>Definition</fr:taxon>
  </fr:frontmatter>
  <fr:mainmatter>
    <html:p>The <html:em><fr:link href="/gutmannNoisecontrastiveEstimationNew2010/" title="Noise-contrastive estimation: A new estimation principle for unnormalized statistical models" uri="https://kellenkanarios.com/gutmannNoisecontrastiveEstimationNew2010/" display-uri="gutmannNoisecontrastiveEstimationNew2010" type="local">NCE</fr:link></html:em> loss aims to minimize the following objective <fr:tex display="block"><![CDATA[\mathcal {L}_{N} = - \sum _{t} \log  \left [h(x_t; \theta )\right ] + \log \left [1 - h(y_t; \theta )\right ],]]></fr:tex> where <fr:tex display="inline"><![CDATA[x_t]]></fr:tex> are samples from the data distribution and <fr:tex display="inline"><![CDATA[y_t]]></fr:tex> are randomly generated samples and <fr:tex display="block"><![CDATA[\begin {array}{r c l}{{h({\bf  u};\theta )}}&{{=}}&{{\frac {1}{1+\exp \left [-G({\bf  u};\theta )\right ]},}}\\ {{G({\bf  u};\theta )}}&{{=}}&{{\ln  p_{m}({\bf  u};\theta )-\ln  p_{n}({\bf  u}).}}\end {array}]]></fr:tex></html:p>
  </fr:mainmatter>
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>Michael Gutmann</fr:author>
              <fr:author>Aapo Hyvärinen</fr:author>
            </fr:authors>
            <fr:date>
              <fr:year>2010</fr:year>
              <fr:month>3</fr:month>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/gutmannNoisecontrastiveEstimationNew2010/</fr:uri>
            <fr:display-uri>gutmannNoisecontrastiveEstimationNew2010</fr:display-uri>
            <fr:route>/gutmannNoisecontrastiveEstimationNew2010/</fr:route>
            <fr:title text="Noise-contrastive estimation: A new estimation principle for unnormalized statistical models">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</fr:title>
            <fr:taxon>Reference</fr:taxon>
            <fr:meta name="bibtex"><![CDATA[@inproceedings{gutmannNoisecontrastiveEstimationNew2010,
 title = {Noise-Contrastive Estimation: {{A}} New Estimation Principle for Unnormalized Statistical Models},
 author = {Gutmann, Michael and Hyv{\"a}rinen, Aapo},
 year = {2010},
 urldate = {2025-01-24},
 booktitle = {Proceedings of the {{Thirteenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},
 pages = {297--304},
 publisher = {{JMLR Workshop and Conference Proceedings}},
 file = {/home/kellenkanarios/Downloads/Papers/Papers/Contrastive RL/Gutmann_Hyvärinen_2010_Noise-contrastive estimation.pdf},
 langid = {english},
 abstract = {We present a new estimation principle for parameterized statistical models. The idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise, using the model log-density function in the regression nonlinearity.  We show that this leads to a consistent (convergent) estimator of the parameters, and analyze the asymptotic variance.  In particular, the method is shown to directly work for unnormalized models, i.e. models where the density function does not integrate to one. The normalization constant can be estimated just like any other parameter. For a tractable ICA model, we compare the method with other estimation methods that can be used to learn unnormalized models, including score matching, contrastive divergence, and maximum-likelihood where the normalization constant is estimated with importance sampling. Simulations show that noise-contrastive estimation offers the best trade-off between computational and statistical efficiency. The method is then applied to the modeling of natural images: We show that the method can successfully estimate a large-scale two-layer model and a Markov random field.},
 issn = {1938-7228},
 month = {March},
 shorttitle = {Noise-Contrastive Estimation}
}]]></fr:meta>
          </fr:frontmatter>
          <fr:mainmatter />
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors />
            <fr:date>
              <fr:year>2024</fr:year>
              <fr:month>10</fr:month>
              <fr:day>31</fr:day>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/0009/</fr:uri>
            <fr:display-uri>0009</fr:display-uri>
            <fr:route>/0009/</fr:route>
            <fr:title text="Contrastive Learning">Contrastive Learning</fr:title>
          </fr:frontmatter>
          <fr:mainmatter><html:p>Recall the longstanding objective of machine learning i.e. given data <fr:tex display="inline"><![CDATA[\mathcal {X}]]></fr:tex> find the distribution <fr:tex display="inline"><![CDATA[p(x)]]></fr:tex> that generated the data <fr:tex display="inline"><![CDATA[\mathcal {X}]]></fr:tex>. The most fundamental approach is <html:em>maximum likelihood estimation</html:em>. Namely, we want to maximize the <html:em>log-likelhood</html:em> of the data
<fr:tex display="block"><![CDATA[\max _{\theta } \sum _{x \in  \mathcal {X}} \log  p_{\theta }(x) ]]></fr:tex></html:p>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>10</fr:month><fr:day>31</fr:day></fr:date><fr:title text="NCE">NCE</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>Suppose we are given <fr:tex display="inline"><![CDATA[N]]></fr:tex> dog samples <fr:tex display="inline"><![CDATA[\mathcal {D}]]></fr:tex> from some distribution <fr:tex display="inline"><![CDATA[p_d(x)]]></fr:tex>. We want to learn <fr:tex display="inline"><![CDATA[\theta ]]></fr:tex> so that <fr:tex display="inline"><![CDATA[p_{\theta }(x) \approx  p_d(x)]]></fr:tex>. The idea is to learn to distinguish the dogs from our dataset and random samples according to some noisy distribution <fr:tex display="inline"><![CDATA[g(x)]]></fr:tex>. We can now return to the supervised learning setting, where we treat <fr:tex display="inline"><![CDATA[\mathcal {D}]]></fr:tex> and <fr:tex display="inline"><![CDATA[\mathcal {R}]]></fr:tex> as two classes. If we recall standard supervised learning practice, given a sample <fr:tex display="inline"><![CDATA[x]]></fr:tex>, we can easily estimate <fr:tex display="block"><![CDATA[p(x \text { is a dog}) = 1 - p(x \text { is random noise})]]></fr:tex> 
via binary classification.
</html:p>
<html:p>
Explicitly, we will use logistic regression with the parametrization <fr:tex display="block"><![CDATA[p_{\theta }(x) = \frac {1}{1 + e^{-G_{\theta }(x)}}.]]></fr:tex> However, solving the logistic regression problem will yield <fr:tex display="inline"><![CDATA[p_{\theta ^*}(x) \approx  p(x \text { is a dog})]]></fr:tex>. Recall that we want to estimate <fr:tex display="inline"><![CDATA[p_d(x)]]></fr:tex> which is the distribution over the "dog manifold".
</html:p>
<html:p> To estimate the correct quantity, we need to leverage our knowledge of the noise distribution. Recall that if <fr:tex display="inline"><![CDATA[p_{\theta }(x) = p(\mathcal {D} \mid  x)]]></fr:tex> then <fr:tex display="inline"><![CDATA[G_{\theta }(x) = \log  \frac {p(x \mid  \mathcal {D})}{p(x \mid  \mathcal {R})}]]></fr:tex>. Since we generated the samples from <fr:tex display="inline"><![CDATA[\mathcal {R}]]></fr:tex>, we have the explicit distribution i.e. <fr:tex display="inline"><![CDATA[p(x \mid  \mathcal {R}) = p_{\mathcal {R}}(x)]]></fr:tex>. Therefore, we can restrict <fr:tex display="inline"><![CDATA[G_{\theta }]]></fr:tex> to explicitly learn <fr:tex display="inline"><![CDATA[p(x \mid  \mathcal {D})]]></fr:tex> by considering <fr:tex display="block"><![CDATA[G_{\theta }(x) = \log  p_{\theta }(x \mid  \mathcal {D}) - \log  p_{\mathcal {R}}(x),]]></fr:tex> considering the cross entropy loss we get the <fr:link href="/000E/" title="NCE loss" uri="https://kellenkanarios.com/000E/" display-uri="000E" type="local">NCE loss</fr:link></html:p>
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kellenkanarios.com/000E/</fr:uri><fr:display-uri>000E</fr:display-uri><fr:route>/000E/</fr:route><fr:title text="NCE loss">NCE loss</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The <html:em><fr:link href="/gutmannNoisecontrastiveEstimationNew2010/" title="Noise-contrastive estimation: A new estimation principle for unnormalized statistical models" uri="https://kellenkanarios.com/gutmannNoisecontrastiveEstimationNew2010/" display-uri="gutmannNoisecontrastiveEstimationNew2010" type="local">NCE</fr:link></html:em> loss aims to minimize the following objective <fr:tex display="block"><![CDATA[\mathcal {L}_{N} = - \sum _{t} \log  \left [h(x_t; \theta )\right ] + \log \left [1 - h(y_t; \theta )\right ],]]></fr:tex> where <fr:tex display="inline"><![CDATA[x_t]]></fr:tex> are samples from the data distribution and <fr:tex display="inline"><![CDATA[y_t]]></fr:tex> are randomly generated samples and <fr:tex display="block"><![CDATA[\begin {array}{r c l}{{h({\bf  u};\theta )}}&{{=}}&{{\frac {1}{1+\exp \left [-G({\bf  u};\theta )\right ]},}}\\ {{G({\bf  u};\theta )}}&{{=}}&{{\ln  p_{m}({\bf  u};\theta )-\ln  p_{n}({\bf  u}).}}\end {array}]]></fr:tex></html:p></fr:mainmatter></fr:tree>

<html:p>In the <fr:link href="/gutmannNoisecontrastiveEstimationNew2010/" title="Noise-contrastive estimation: A new estimation principle for unnormalized statistical models" uri="https://kellenkanarios.com/gutmannNoisecontrastiveEstimationNew2010/" display-uri="gutmannNoisecontrastiveEstimationNew2010" type="local">NCE paper</fr:link>, they show under mild conditions that the estimator <fr:tex display="inline"><![CDATA[p_{\theta }(x \mid  D) \to  p_{\mathcal {D}}(x)]]></fr:tex> in probability as the number of samples in the loss goes to infinity. Equivalently, the estimator is <fr:link href="/000F/" title="Consistent estimator" uri="https://kellenkanarios.com/000F/" display-uri="000F" type="local">consistent</fr:link>.</html:p>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>10</fr:month><fr:day>31</fr:day></fr:date><fr:title text="Temporally Contrastive Learning in Time Series">Temporally Contrastive Learning in Time Series</fr:title></fr:frontmatter><fr:mainmatter>
    <html:p>
Before we get to contrastive RL, it is a natural question to wonder how does this apply to temporal sequences? Concretely, we want to make predictions about the future given the current "context". However, we want to do so in an unsupervised way, meaning we are only given trajectories not a notion of what it means for a trajectory to be good. Naively, one can try to do this in a supervised manner.
    </html:p>
<html:p>
For a <fr:tex display="inline"><![CDATA[k]]></fr:tex> step prediction, this would just be your model predicting what will happen in <fr:tex display="inline"><![CDATA[k]]></fr:tex> steps then seeing if it matches what occured <fr:tex display="inline"><![CDATA[k]]></fr:tex> steps in the future in the sample trajectory. However, if your sample space <fr:tex display="inline"><![CDATA[\mathcal {X}]]></fr:tex> is very high-dimensional, modeling this relationship can require an exorbinant amount of trajectories.</html:p>
<html:p>This is a central question in the <fr:link href="/oordRepresentationLearningContrastive2019/" title="Representation Learning with Contrastive Predictive Coding" uri="https://kellenkanarios.com/oordRepresentationLearningContrastive2019/" display-uri="oordRepresentationLearningContrastive2019" type="local">InfoNCE paper</fr:link>, where they propose the following loss:</html:p>
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kellenkanarios.com/000B/</fr:uri><fr:display-uri>000B</fr:display-uri><fr:route>/000B/</fr:route><fr:title text="InfoNCE">InfoNCE</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The <html:em><fr:link href="/oordRepresentationLearningContrastive2019/" title="Representation Learning with Contrastive Predictive Coding" uri="https://kellenkanarios.com/oordRepresentationLearningContrastive2019/" display-uri="oordRepresentationLearningContrastive2019" type="local">InfoNCE</fr:link></html:em> loss aims to minimize the following information-theoretic objective <fr:tex display="block"><![CDATA[\mathcal {L}_{N} = - \mathbb {E}_{\mathcal {X}} \left [\log  \frac {f_k(x_{t + k}, c_t)}{\sum _{x_j \in  \mathcal {X}} f_k(x_j, c_t)}\right ]]]></fr:tex></html:p></fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree>
<html:p>Now we need to unpack this very ominous loss. To start, what are <fr:tex display="inline"><![CDATA[x_k]]></fr:tex> and <fr:tex display="inline"><![CDATA[c_t]]></fr:tex>?</html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kellenkanarios.com/000C/</fr:uri><fr:display-uri>000C</fr:display-uri><fr:route>/000C/</fr:route><fr:title text="Maximize Mutual info">Maximize Mutual info</fr:title><fr:taxon>Theorem</fr:taxon></fr:frontmatter><fr:mainmatter><html:p><fr:tex display="inline"><![CDATA[\mathcal {L}_N]]></fr:tex> from <fr:link href="/oordRepresentationLearningContrastive2019/" title="Representation Learning with Contrastive Predictive Coding" uri="https://kellenkanarios.com/oordRepresentationLearningContrastive2019/" display-uri="oordRepresentationLearningContrastive2019" type="local">InfoNCE paper</fr:link> maximizes a lower bound on the <fr:link href="/000V/" title="Mutual Information" uri="https://kellenkanarios.com/000V/" display-uri="000V" type="local">Mutual Information</fr:link> between <fr:tex display="inline"><![CDATA[x_{t + k}]]></fr:tex> and <fr:tex display="inline"><![CDATA[c_t]]></fr:tex>.</html:p>
   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>All we must do is plug <fr:tex display="inline"><![CDATA[\frac {p(x \mid  c)}{p(x)}]]></fr:tex> back into the objective.
  <fr:tex display="block"><![CDATA[\begin {align*}
    \mathcal {L}_{\mathbb {N}}^{\text {opt}}&=-\,\mathbb {E}\log \left [\frac {\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}}{\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}+\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}}\right ] \\
    &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\
    &\approx \mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}(N-1)\,\mathbb {E}\,\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\
    &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k} \mid  c_t)}N\right ] \\
    &\geq  \mathbb {E} \log  \left [\frac {p(x_{t + k})}{p(x_{t + k} \mid  c_t)}N \right ] \\
    &= - I(x_{t + k}, c_t) + \log  N
 \end {align*}
  ]]></fr:tex>
</fr:mainmatter></fr:tree>
 

</fr:mainmatter></fr:tree><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>17</fr:day></fr:date><fr:uri>https://kellenkanarios.com/P658/</fr:uri><fr:display-uri>P658</fr:display-uri><fr:route>/P658/</fr:route><fr:title text="Contrastive Learning as GCRL">Contrastive Learning as GCRL</fr:title></fr:frontmatter><fr:mainmatter><fr:tex display="block"><![CDATA[
\operatorname *{max}_{f(u,v)}\mathbb {E}_{(u,v^{+})\sim  p(u,v)}\left [\log \sigma (\underbrace {f(u,{\green  v^{+}})}_{\phi (u)^{T}\psi ({\green  v^{+}})})+\log (1-\sigma (\underbrace {f(u,{\red  v^{-}})}_{\phi (u)^{T}\psi ({\red  v^{-}})}))\right ]
]]></fr:tex><fr:tex display="block"><![CDATA[
\begin {align*}
&\operatorname *{max}_{f}\mathbb {E}_{(s,a)\sim  p(s,a),s_{f}^{-}\sim  p(s_{f})}\left [\mathcal {L}(s,a,s_{f}^{+},s_{f}^{-})\right ] \\
\end {align*}
]]></fr:tex><fr:tex display="block"><![CDATA[
\mathcal {L}_1(\theta ) = \log \sigma (f_{\theta }(s_1,a_1,{\color {green} s_{8}})) + \log (1-\sigma (f_{\theta }(s_1,a_1, {\color {red} s_3})))
]]></fr:tex><fr:tex display="block"><![CDATA[
\begin {align*}
\widehat {\mathcal {L}}(\theta ) &= \frac {1}{n} \sum _{i = 1}^{n} \mathcal {L}_i \\
&= \frac {1}{n} \sum _{i = 1}^{n} \Big [\log \sigma (f_{\theta }(s_i,a_i,{\color {green} s_{f}^{+}})) + \log (1-\sigma (f_{\theta }(s_i,a_i, {\color {red} s_{f}^{-}})))\Big ]
\end {align*}
]]></fr:tex><fr:tex display="block"><![CDATA[
\mathcal {L}(\theta ) = \mathbb {E}_{x \sim  p_X, y \sim  p_Y}\Big [\log \sigma (f_{\theta }(x)) + \log (1-\sigma (f_{\theta }(y)))\Big ]
]]></fr:tex><fr:tex display="block"><![CDATA[f^*(s, a, s_g) = \log \left (\frac {p^{\pi (\cdot  \mid  \cdot )}(s_g \mid  s, a)}{p(s_g)}\right )]]></fr:tex>
   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>17</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>
    We want to maximize
<fr:tex display="block"><![CDATA[
    \begin {align*}
\mathcal {L}(\theta ) &= \mathbb {E}_{x \sim  p_X, y \sim  p_Y}\Big [\log \sigma (f_{\theta }(x)) + \log (1-\sigma (f_{\theta }(y)))\Big ] \\
&= \int  \log \sigma (f_{\theta }(x)) P_X(x) + \int  \log (1-\sigma (f_{\theta }(y))) P_Y(y) \\
&= \int  \log \sigma (f_{\theta }(z)) P_X(z) + \log (1-\sigma (f_{\theta }(z))) P_Y(z)
    \end {align*}
    ]]></fr:tex>
    Since we are maximizing <fr:tex display="inline"><![CDATA[f(s)]]></fr:tex>, we can just maximize the integrand i.e.
<fr:tex display="block"><![CDATA[
      \begin {align*}
        \frac {\mathrm {d}}{\mathrm {d}f(z)} \Big [\log \sigma (f_{\theta }(z)) P_X(z) + \log (1-\sigma (f_{\theta }(z))) P_Y(z)\Big ] = 0
      \end {align*}
    ]]></fr:tex>
    Solving,
    <fr:tex display="block"><![CDATA[
        \begin {align*}
          P_X(z)\big (1 - \sigma (f(z))\big ) - P_Y(z)\sigma (f(z)) = 0 &\iff  \sigma (f(z)) = \frac {P_X(z)}{P_X(z) + P_Y(z)} \\
          &\iff  f(z) = \log \left (\frac {P_X(z)}{P_Y(z)}\right )
        \end {align*}
      ]]></fr:tex>
  </fr:mainmatter></fr:tree>
 


   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>17</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>
The first step is to prove that the average Q-values are close to the task-conditioned Q-values. Below, we will use <fr:tex display="inline"><![CDATA[R_{c}(\tau )\triangleq \sum _{\ell =0}^{\infty }\gamma ^{\ell }r_{\ell }(s_{\ell },a_{\ell })]]></fr:tex>:

<fr:tex display="block"><![CDATA[
\begin {align*}
\left |Q^{\beta (\cdot |\cdot ,a)}(s,a,e)-Q^{\beta (\cdot |\cdot ,\epsilon ^{\prime })}(s,a,e)\right |&=\left |\int \beta (\tau \mid  s,a,e)R_{e}(\tau )d\tau -\int \beta (\tau \mid  s,a,e^{\prime })R_{e}(\tau )d\tau \right |\\ 
&=\left |\int \beta (\tau \mid  s,a,e)-\beta (\tau \mid  s,a,e^{\prime })R_{e}(\tau )d\tau \right | \\
&=\left |\int \beta (\tau \mid  s,a,e)\left (1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right )R_{e}(\tau )d\tau \right | \\
&\leq \int \left |\beta (\tau \mid  s,a,e)\left (1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right )\right |d\tau \cdot \operatorname *{max}_{\tau }|R_{e}(\tau )d\tau | \\
&\leq \int \beta (\tau \mid  s,a,e)\left |1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right |d\tau \cdot  1 \\
&=\mathbb {E}_{\beta (\tau |s,a,e)}\left [\left |1-{\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}}\right |\right ] \\
&\leq  \epsilon .
\end {align*}
  ]]></fr:tex>
</fr:mainmatter></fr:tree>
 

</fr:mainmatter></fr:tree></fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors />
            <fr:date>
              <fr:year>2024</fr:year>
              <fr:month>10</fr:month>
              <fr:day>31</fr:day>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/0009/</fr:uri>
            <fr:display-uri>0009</fr:display-uri>
            <fr:route>/0009/</fr:route>
            <fr:title text="Contrastive Learning">Contrastive Learning</fr:title>
          </fr:frontmatter>
          <fr:mainmatter><html:p>Recall the longstanding objective of machine learning i.e. given data <fr:tex display="inline"><![CDATA[\mathcal {X}]]></fr:tex> find the distribution <fr:tex display="inline"><![CDATA[p(x)]]></fr:tex> that generated the data <fr:tex display="inline"><![CDATA[\mathcal {X}]]></fr:tex>. The most fundamental approach is <html:em>maximum likelihood estimation</html:em>. Namely, we want to maximize the <html:em>log-likelhood</html:em> of the data
<fr:tex display="block"><![CDATA[\max _{\theta } \sum _{x \in  \mathcal {X}} \log  p_{\theta }(x) ]]></fr:tex></html:p>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>10</fr:month><fr:day>31</fr:day></fr:date><fr:title text="NCE">NCE</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>Suppose we are given <fr:tex display="inline"><![CDATA[N]]></fr:tex> dog samples <fr:tex display="inline"><![CDATA[\mathcal {D}]]></fr:tex> from some distribution <fr:tex display="inline"><![CDATA[p_d(x)]]></fr:tex>. We want to learn <fr:tex display="inline"><![CDATA[\theta ]]></fr:tex> so that <fr:tex display="inline"><![CDATA[p_{\theta }(x) \approx  p_d(x)]]></fr:tex>. The idea is to learn to distinguish the dogs from our dataset and random samples according to some noisy distribution <fr:tex display="inline"><![CDATA[g(x)]]></fr:tex>. We can now return to the supervised learning setting, where we treat <fr:tex display="inline"><![CDATA[\mathcal {D}]]></fr:tex> and <fr:tex display="inline"><![CDATA[\mathcal {R}]]></fr:tex> as two classes. If we recall standard supervised learning practice, given a sample <fr:tex display="inline"><![CDATA[x]]></fr:tex>, we can easily estimate <fr:tex display="block"><![CDATA[p(x \text { is a dog}) = 1 - p(x \text { is random noise})]]></fr:tex> 
via binary classification.
</html:p>
<html:p>
Explicitly, we will use logistic regression with the parametrization <fr:tex display="block"><![CDATA[p_{\theta }(x) = \frac {1}{1 + e^{-G_{\theta }(x)}}.]]></fr:tex> However, solving the logistic regression problem will yield <fr:tex display="inline"><![CDATA[p_{\theta ^*}(x) \approx  p(x \text { is a dog})]]></fr:tex>. Recall that we want to estimate <fr:tex display="inline"><![CDATA[p_d(x)]]></fr:tex> which is the distribution over the "dog manifold".
</html:p>
<html:p> To estimate the correct quantity, we need to leverage our knowledge of the noise distribution. Recall that if <fr:tex display="inline"><![CDATA[p_{\theta }(x) = p(\mathcal {D} \mid  x)]]></fr:tex> then <fr:tex display="inline"><![CDATA[G_{\theta }(x) = \log  \frac {p(x \mid  \mathcal {D})}{p(x \mid  \mathcal {R})}]]></fr:tex>. Since we generated the samples from <fr:tex display="inline"><![CDATA[\mathcal {R}]]></fr:tex>, we have the explicit distribution i.e. <fr:tex display="inline"><![CDATA[p(x \mid  \mathcal {R}) = p_{\mathcal {R}}(x)]]></fr:tex>. Therefore, we can restrict <fr:tex display="inline"><![CDATA[G_{\theta }]]></fr:tex> to explicitly learn <fr:tex display="inline"><![CDATA[p(x \mid  \mathcal {D})]]></fr:tex> by considering <fr:tex display="block"><![CDATA[G_{\theta }(x) = \log  p_{\theta }(x \mid  \mathcal {D}) - \log  p_{\mathcal {R}}(x),]]></fr:tex> considering the cross entropy loss we get the <fr:link href="/000E/" title="NCE loss" uri="https://kellenkanarios.com/000E/" display-uri="000E" type="local">NCE loss</fr:link></html:p>
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kellenkanarios.com/000E/</fr:uri><fr:display-uri>000E</fr:display-uri><fr:route>/000E/</fr:route><fr:title text="NCE loss">NCE loss</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The <html:em><fr:link href="/gutmannNoisecontrastiveEstimationNew2010/" title="Noise-contrastive estimation: A new estimation principle for unnormalized statistical models" uri="https://kellenkanarios.com/gutmannNoisecontrastiveEstimationNew2010/" display-uri="gutmannNoisecontrastiveEstimationNew2010" type="local">NCE</fr:link></html:em> loss aims to minimize the following objective <fr:tex display="block"><![CDATA[\mathcal {L}_{N} = - \sum _{t} \log  \left [h(x_t; \theta )\right ] + \log \left [1 - h(y_t; \theta )\right ],]]></fr:tex> where <fr:tex display="inline"><![CDATA[x_t]]></fr:tex> are samples from the data distribution and <fr:tex display="inline"><![CDATA[y_t]]></fr:tex> are randomly generated samples and <fr:tex display="block"><![CDATA[\begin {array}{r c l}{{h({\bf  u};\theta )}}&{{=}}&{{\frac {1}{1+\exp \left [-G({\bf  u};\theta )\right ]},}}\\ {{G({\bf  u};\theta )}}&{{=}}&{{\ln  p_{m}({\bf  u};\theta )-\ln  p_{n}({\bf  u}).}}\end {array}]]></fr:tex></html:p></fr:mainmatter></fr:tree>

<html:p>In the <fr:link href="/gutmannNoisecontrastiveEstimationNew2010/" title="Noise-contrastive estimation: A new estimation principle for unnormalized statistical models" uri="https://kellenkanarios.com/gutmannNoisecontrastiveEstimationNew2010/" display-uri="gutmannNoisecontrastiveEstimationNew2010" type="local">NCE paper</fr:link>, they show under mild conditions that the estimator <fr:tex display="inline"><![CDATA[p_{\theta }(x \mid  D) \to  p_{\mathcal {D}}(x)]]></fr:tex> in probability as the number of samples in the loss goes to infinity. Equivalently, the estimator is <fr:link href="/000F/" title="Consistent estimator" uri="https://kellenkanarios.com/000F/" display-uri="000F" type="local">consistent</fr:link>.</html:p>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>10</fr:month><fr:day>31</fr:day></fr:date><fr:title text="Temporally Contrastive Learning in Time Series">Temporally Contrastive Learning in Time Series</fr:title></fr:frontmatter><fr:mainmatter>
    <html:p>
Before we get to contrastive RL, it is a natural question to wonder how does this apply to temporal sequences? Concretely, we want to make predictions about the future given the current "context". However, we want to do so in an unsupervised way, meaning we are only given trajectories not a notion of what it means for a trajectory to be good. Naively, one can try to do this in a supervised manner.
    </html:p>
<html:p>
For a <fr:tex display="inline"><![CDATA[k]]></fr:tex> step prediction, this would just be your model predicting what will happen in <fr:tex display="inline"><![CDATA[k]]></fr:tex> steps then seeing if it matches what occured <fr:tex display="inline"><![CDATA[k]]></fr:tex> steps in the future in the sample trajectory. However, if your sample space <fr:tex display="inline"><![CDATA[\mathcal {X}]]></fr:tex> is very high-dimensional, modeling this relationship can require an exorbinant amount of trajectories.</html:p>
<html:p>This is a central question in the <fr:link href="/oordRepresentationLearningContrastive2019/" title="Representation Learning with Contrastive Predictive Coding" uri="https://kellenkanarios.com/oordRepresentationLearningContrastive2019/" display-uri="oordRepresentationLearningContrastive2019" type="local">InfoNCE paper</fr:link>, where they propose the following loss:</html:p>
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kellenkanarios.com/000B/</fr:uri><fr:display-uri>000B</fr:display-uri><fr:route>/000B/</fr:route><fr:title text="InfoNCE">InfoNCE</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The <html:em><fr:link href="/oordRepresentationLearningContrastive2019/" title="Representation Learning with Contrastive Predictive Coding" uri="https://kellenkanarios.com/oordRepresentationLearningContrastive2019/" display-uri="oordRepresentationLearningContrastive2019" type="local">InfoNCE</fr:link></html:em> loss aims to minimize the following information-theoretic objective <fr:tex display="block"><![CDATA[\mathcal {L}_{N} = - \mathbb {E}_{\mathcal {X}} \left [\log  \frac {f_k(x_{t + k}, c_t)}{\sum _{x_j \in  \mathcal {X}} f_k(x_j, c_t)}\right ]]]></fr:tex></html:p></fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree>
<html:p>Now we need to unpack this very ominous loss. To start, what are <fr:tex display="inline"><![CDATA[x_k]]></fr:tex> and <fr:tex display="inline"><![CDATA[c_t]]></fr:tex>?</html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kellenkanarios.com/000C/</fr:uri><fr:display-uri>000C</fr:display-uri><fr:route>/000C/</fr:route><fr:title text="Maximize Mutual info">Maximize Mutual info</fr:title><fr:taxon>Theorem</fr:taxon></fr:frontmatter><fr:mainmatter><html:p><fr:tex display="inline"><![CDATA[\mathcal {L}_N]]></fr:tex> from <fr:link href="/oordRepresentationLearningContrastive2019/" title="Representation Learning with Contrastive Predictive Coding" uri="https://kellenkanarios.com/oordRepresentationLearningContrastive2019/" display-uri="oordRepresentationLearningContrastive2019" type="local">InfoNCE paper</fr:link> maximizes a lower bound on the <fr:link href="/000V/" title="Mutual Information" uri="https://kellenkanarios.com/000V/" display-uri="000V" type="local">Mutual Information</fr:link> between <fr:tex display="inline"><![CDATA[x_{t + k}]]></fr:tex> and <fr:tex display="inline"><![CDATA[c_t]]></fr:tex>.</html:p>
   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>All we must do is plug <fr:tex display="inline"><![CDATA[\frac {p(x \mid  c)}{p(x)}]]></fr:tex> back into the objective.
  <fr:tex display="block"><![CDATA[\begin {align*}
    \mathcal {L}_{\mathbb {N}}^{\text {opt}}&=-\,\mathbb {E}\log \left [\frac {\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}}{\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}+\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}}\right ] \\
    &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\
    &\approx \mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}(N-1)\,\mathbb {E}\,\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\
    &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k} \mid  c_t)}N\right ] \\
    &\geq  \mathbb {E} \log  \left [\frac {p(x_{t + k})}{p(x_{t + k} \mid  c_t)}N \right ] \\
    &= - I(x_{t + k}, c_t) + \log  N
 \end {align*}
  ]]></fr:tex>
</fr:mainmatter></fr:tree>
 

</fr:mainmatter></fr:tree><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>17</fr:day></fr:date><fr:uri>https://kellenkanarios.com/P658/</fr:uri><fr:display-uri>P658</fr:display-uri><fr:route>/P658/</fr:route><fr:title text="Contrastive Learning as GCRL">Contrastive Learning as GCRL</fr:title></fr:frontmatter><fr:mainmatter><fr:tex display="block"><![CDATA[
\operatorname *{max}_{f(u,v)}\mathbb {E}_{(u,v^{+})\sim  p(u,v)}\left [\log \sigma (\underbrace {f(u,{\green  v^{+}})}_{\phi (u)^{T}\psi ({\green  v^{+}})})+\log (1-\sigma (\underbrace {f(u,{\red  v^{-}})}_{\phi (u)^{T}\psi ({\red  v^{-}})}))\right ]
]]></fr:tex><fr:tex display="block"><![CDATA[
\begin {align*}
&\operatorname *{max}_{f}\mathbb {E}_{(s,a)\sim  p(s,a),s_{f}^{-}\sim  p(s_{f})}\left [\mathcal {L}(s,a,s_{f}^{+},s_{f}^{-})\right ] \\
\end {align*}
]]></fr:tex><fr:tex display="block"><![CDATA[
\mathcal {L}_1(\theta ) = \log \sigma (f_{\theta }(s_1,a_1,{\color {green} s_{8}})) + \log (1-\sigma (f_{\theta }(s_1,a_1, {\color {red} s_3})))
]]></fr:tex><fr:tex display="block"><![CDATA[
\begin {align*}
\widehat {\mathcal {L}}(\theta ) &= \frac {1}{n} \sum _{i = 1}^{n} \mathcal {L}_i \\
&= \frac {1}{n} \sum _{i = 1}^{n} \Big [\log \sigma (f_{\theta }(s_i,a_i,{\color {green} s_{f}^{+}})) + \log (1-\sigma (f_{\theta }(s_i,a_i, {\color {red} s_{f}^{-}})))\Big ]
\end {align*}
]]></fr:tex><fr:tex display="block"><![CDATA[
\mathcal {L}(\theta ) = \mathbb {E}_{x \sim  p_X, y \sim  p_Y}\Big [\log \sigma (f_{\theta }(x)) + \log (1-\sigma (f_{\theta }(y)))\Big ]
]]></fr:tex><fr:tex display="block"><![CDATA[f^*(s, a, s_g) = \log \left (\frac {p^{\pi (\cdot  \mid  \cdot )}(s_g \mid  s, a)}{p(s_g)}\right )]]></fr:tex>
   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>17</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>
    We want to maximize
<fr:tex display="block"><![CDATA[
    \begin {align*}
\mathcal {L}(\theta ) &= \mathbb {E}_{x \sim  p_X, y \sim  p_Y}\Big [\log \sigma (f_{\theta }(x)) + \log (1-\sigma (f_{\theta }(y)))\Big ] \\
&= \int  \log \sigma (f_{\theta }(x)) P_X(x) + \int  \log (1-\sigma (f_{\theta }(y))) P_Y(y) \\
&= \int  \log \sigma (f_{\theta }(z)) P_X(z) + \log (1-\sigma (f_{\theta }(z))) P_Y(z)
    \end {align*}
    ]]></fr:tex>
    Since we are maximizing <fr:tex display="inline"><![CDATA[f(s)]]></fr:tex>, we can just maximize the integrand i.e.
<fr:tex display="block"><![CDATA[
      \begin {align*}
        \frac {\mathrm {d}}{\mathrm {d}f(z)} \Big [\log \sigma (f_{\theta }(z)) P_X(z) + \log (1-\sigma (f_{\theta }(z))) P_Y(z)\Big ] = 0
      \end {align*}
    ]]></fr:tex>
    Solving,
    <fr:tex display="block"><![CDATA[
        \begin {align*}
          P_X(z)\big (1 - \sigma (f(z))\big ) - P_Y(z)\sigma (f(z)) = 0 &\iff  \sigma (f(z)) = \frac {P_X(z)}{P_X(z) + P_Y(z)} \\
          &\iff  f(z) = \log \left (\frac {P_X(z)}{P_Y(z)}\right )
        \end {align*}
      ]]></fr:tex>
  </fr:mainmatter></fr:tree>
 


   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>17</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>
The first step is to prove that the average Q-values are close to the task-conditioned Q-values. Below, we will use <fr:tex display="inline"><![CDATA[R_{c}(\tau )\triangleq \sum _{\ell =0}^{\infty }\gamma ^{\ell }r_{\ell }(s_{\ell },a_{\ell })]]></fr:tex>:

<fr:tex display="block"><![CDATA[
\begin {align*}
\left |Q^{\beta (\cdot |\cdot ,a)}(s,a,e)-Q^{\beta (\cdot |\cdot ,\epsilon ^{\prime })}(s,a,e)\right |&=\left |\int \beta (\tau \mid  s,a,e)R_{e}(\tau )d\tau -\int \beta (\tau \mid  s,a,e^{\prime })R_{e}(\tau )d\tau \right |\\ 
&=\left |\int \beta (\tau \mid  s,a,e)-\beta (\tau \mid  s,a,e^{\prime })R_{e}(\tau )d\tau \right | \\
&=\left |\int \beta (\tau \mid  s,a,e)\left (1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right )R_{e}(\tau )d\tau \right | \\
&\leq \int \left |\beta (\tau \mid  s,a,e)\left (1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right )\right |d\tau \cdot \operatorname *{max}_{\tau }|R_{e}(\tau )d\tau | \\
&\leq \int \beta (\tau \mid  s,a,e)\left |1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right |d\tau \cdot  1 \\
&=\mathbb {E}_{\beta (\tau |s,a,e)}\left [\left |1-{\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}}\right |\right ] \\
&\leq  \epsilon .
\end {align*}
  ]]></fr:tex>
</fr:mainmatter></fr:tree>
 

</fr:mainmatter></fr:tree></fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
