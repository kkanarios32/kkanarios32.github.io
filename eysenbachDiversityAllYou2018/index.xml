<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors>
      <fr:author>Benjamin Eysenbach</fr:author>
      <fr:author>Abhishek Gupta</fr:author>
      <fr:author>Julian Ibarz</fr:author>
      <fr:author>Sergey Levine</fr:author>
    </fr:authors>
    <fr:date>
      <fr:year>2018</fr:year>
      <fr:month>10</fr:month>
    </fr:date>
    <fr:uri>https://kellenkanarios.com/eysenbachDiversityAllYou2018/</fr:uri>
    <fr:display-uri>eysenbachDiversityAllYou2018</fr:display-uri>
    <fr:route>/eysenbachDiversityAllYou2018/</fr:route>
    <fr:title text="Diversity is All You Need: Learning Skills without a Reward Function">Diversity is All You Need: Learning Skills without a Reward Function</fr:title>
    <fr:taxon>Reference</fr:taxon>
    <fr:meta name="doi">10.48550/arXiv.1802.06070</fr:meta>
    <fr:meta name="external">https://arxiv.org/abs/1802.06070</fr:meta>
    <fr:meta name="bibtex"><![CDATA[@misc{eysenbachDiversityAllYou2018,
 title = {Diversity Is {{All You Need}}: {{Learning Skills}} without a {{Reward Function}}},
 author = {Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
 year = {2018},
 doi = {10.48550/arXiv.1802.06070},
 urldate = {2025-06-30},
 number = {arXiv:1802.06070},
 publisher = {arXiv},
 file = {/home/kellen/Downloads/pdfs/storage/RMASJINK/Eysenbach et al. - 2018 - Diversity is All You Need Learning Skills without.pdf},
 keywords = {Computer Science - Artificial Intelligence,Computer Science - Robotics},
 langid = {english},
 archiveprefix = {arXiv},
 abstract = {Intelligent creatures can explore their environments and learn useful skills without supervision. In this paper, we propose ``Diversity is All You Need''(DIAYN), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. We show how pretrained skills can provide a good parameter initialization for downstream tasks, and can be composed hierarchically to solve complex, sparse reward tasks. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning.},
 primaryclass = {cs},
 eprint = {1802.06070},
 month = {October},
 shorttitle = {Diversity Is {{All You Need}}}
}]]></fr:meta>
  </fr:frontmatter>
  <fr:mainmatter />
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
