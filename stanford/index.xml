<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors />
    <fr:uri>https://kellenkanarios.com/stanford/</fr:uri>
    <fr:display-uri>stanford</fr:display-uri>
    <fr:route>/stanford/</fr:route>
    <fr:title text="Stanford University">Stanford University</fr:title>
    <fr:taxon>Institute</fr:taxon>
    <fr:meta name="external">https://www.stanford.edu/</fr:meta>
  </fr:frontmatter>
  <fr:mainmatter />
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>
                <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
              </fr:author>
            </fr:authors>
            <fr:date>
              <fr:year>2025</fr:year>
              <fr:month>7</fr:month>
              <fr:day>1</fr:day>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/0085/</fr:uri>
            <fr:display-uri>0085</fr:display-uri>
            <fr:route>/0085/</fr:route>
            <fr:title text="Notebook: Stanford CS336">Notebook: <fr:link href="/stanford/" title="Stanford University" uri="https://kellenkanarios.com/stanford/" display-uri="stanford" type="local">Stanford</fr:link> <fr:link href="https://stanford-cs336.github.io/spring2025/index.htmlschedule" type="external">CS336</fr:link></fr:title>
          </fr:frontmatter>
          <fr:mainmatter>
            <html:p>Formal notebook for my journey in <fr:link href="/stanford/" title="Stanford University" uri="https://kellenkanarios.com/stanford/" display-uri="stanford" type="local">Stanford's</fr:link> <fr:link href="https://stanford-cs336.github.io/spring2025/index.htmlschedule" type="external">CS336</fr:link> as part of my <fr:link href="/003W/" title="LLMs" uri="https://kellenkanarios.com/003W/" display-uri="003W" type="local">LLM</fr:link> self-study endeavors.</html:p>
            <fr:tree show-metadata="false" expanded="false">
              <fr:frontmatter>
                <fr:authors>
                  <fr:author>
                    <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
                  </fr:author>
                </fr:authors>
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>7</fr:month>
                  <fr:day>1</fr:day>
                </fr:date>
                <fr:uri>https://kellenkanarios.com/0086/</fr:uri>
                <fr:display-uri>0086</fr:display-uri>
                <fr:route>/0086/</fr:route>
                <fr:title text="CS336 Lecture 1"><fr:link href="/0085/" title="Notebook: Stanford CS336" uri="https://kellenkanarios.com/0085/" display-uri="0085" type="local">CS336</fr:link> Lecture 1</fr:title>
              </fr:frontmatter>
              <fr:mainmatter>
                <html:p><fr:link href="/007U/" title="Deliberate-Practice" uri="https://kellenkanarios.com/007U/" display-uri="007U" type="local">Deliberate-Practice</fr:link> (2/66)</html:p>
                <html:p>First they give a brief outline of the course (provided below) along with some of the challenges and problem definitions for each of the sections</html:p>
                <fr:tree show-metadata="false">
                  <fr:frontmatter>
                    <fr:authors />
                    <fr:date>
                      <fr:year>2025</fr:year>
                      <fr:month>7</fr:month>
                      <fr:day>3</fr:day>
                    </fr:date>
                    <fr:uri>https://kellenkanarios.com/DEQT/</fr:uri>
                    <fr:display-uri>DEQT</fr:display-uri>
                    <fr:route>/DEQT/</fr:route>
                    <fr:title text="Course outline">Course outline</fr:title>
                  </fr:frontmatter>
                  <fr:mainmatter>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:title text="Basics">Basics</fr:title></fr:frontmatter><fr:mainmatter>
<html:ol><html:li>Tokenization</html:li>
  <html:li>Architecture</html:li>
  <html:li>Loss function</html:li>
  <html:li>Optimizer</html:li>
  <html:li>Learning rate</html:li></html:ol>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:title text="Systems">Systems</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p><html:strong>Goal:</html:strong> Squeeze the most out of the hardware. </html:p>
<html:ol><html:li><html:strong>Kernels</html:strong></html:li>
  <html:p>Basic idea is that the GPU needs to perform computation, but the data cannot fit on the GPU. GPU is the <html:em>factory</html:em> memory is the <html:em>warehouse</html:em></html:p>
  
 <html:div class="jms-indent-block" style="
  margin-left: 1em;
  margin-bottom: 1em;
  border-left: 4px solid black;
  padding-left: 12px;
  background-color: whitesmoke;
  ">
    <html:em>How do we best organize computation to maximize utilization of GPUs by minimizing data movement?</html:em>
  </html:div>

  <html:li><html:strong>Parallelism</html:strong></html:li>
  <html:p>Beyond one GPU, we must then learn how to scale these ideas to multiple GPUs.</html:p>
  <html:ul><html:li>Sharding</html:li>
    <html:li>{data,tensor,piple,sequence} parallelism</html:li>
    <html:li>Quantization</html:li>
    <html:li>Activation checkpointing</html:li>
    <html:li>CPU offloading</html:li></html:ul>
  <html:li><html:strong>Inference</html:strong></html:li>
  <html:p>Two phases: prefill and decode</html:p>
  <html:ul><html:li>In prefill all tokens are given and you just want to output the next coding (compute bound).</html:li>
    <html:li>In decoding, we need to output one token at a time (memory-bound). </html:li></html:ul></html:ol>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:title text="Scaling Laws">Scaling Laws</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p><html:strong>Goal:</html:strong> do experiments at small scale in order to pick hyperparameters for much more expensive runs at large scale.</html:p>
<html:ol><html:li>Scaling sequence</html:li>
  <html:li>Model complexity</html:li>
  <html:li>Loss metric</html:li>
  <html:li>Parametric form</html:li></html:ol>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:title text="Data">Data</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p><html:strong>Goal:</html:strong> what we want the model to actually do i.e. pick your data for your task.</html:p>
<html:ol><html:li>Evaluation</html:li>
  <html:li>Curation</html:li>
  <html:li>Transformation</html:li>
  <html:li>Filtering</html:li>
  <html:li>Deduplication</html:li>
  <html:li>Mixing</html:li></html:ol>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:title text="Alignment">Alignment</fr:title></fr:frontmatter><fr:mainmatter>
<html:ol><html:li>Supervised fine-tuning</html:li>
  <html:li>Reinforcement learning</html:li>
  <html:li>Preference data</html:li>
  <html:li>Synthetic data</html:li>
  <html:li>Verifiers</html:li></html:ol>
</fr:mainmatter></fr:tree>
</fr:mainmatter>
                </fr:tree>
                <fr:tree show-metadata="false">
                  <fr:frontmatter>
                    <fr:authors>
                      <fr:author>
                        <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
                      </fr:author>
                    </fr:authors>
                    <fr:date>
                      <fr:year>2025</fr:year>
                      <fr:month>7</fr:month>
                      <fr:day>1</fr:day>
                    </fr:date>
                    <fr:uri>https://kellenkanarios.com/0087/</fr:uri>
                    <fr:display-uri>0087</fr:display-uri>
                    <fr:route>/0087/</fr:route>
                    <fr:title text="Tokenization">Tokenization</fr:title>
                  </fr:frontmatter>
                  <fr:mainmatter>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>1</fr:day></fr:date><fr:title text="Introduction">Introduction</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>
A <html:em>tokenizer</html:em> is responsible for taking text and turning it into a numerical representation we can pass to a neural network i.e.
<fr:tex display="block"><![CDATA[\mathsf {encode}(\text {hello world}) \mapsto  \begin {bmatrix} 24912, & 2375 \end {bmatrix} ]]></fr:tex>
    However, we also need 
    <fr:tex display="block"><![CDATA[\mathsf {decode}(\begin {bmatrix} 24912, & 2375 \end {bmatrix}) \mapsto  \text {hello world} 
    ]]></fr:tex>
 When defining a "good" tokenizer, we are concerned with the <html:em>compression ratio</html:em> i.e. the # of bytes per token.
    </html:p>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>1</fr:day></fr:date><fr:title text="Character-based tokenization">Character-based tokenization</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>Trivially, we can do <html:em>character-based tokenization</html:em> i.e. mapping each character to a unique number. For example, <fr:tex display="inline"><![CDATA[\mathsf {chr}(97) = \text {``a''}]]></fr:tex> and <fr:tex display="inline"><![CDATA[\mathsf {ord}(\text {``a''}) = 97]]></fr:tex>. The compression ratio will be <fr:tex display="inline"><![CDATA[> 1]]></fr:tex> because each token corresponds to a character potentially consisting of more than one byte.</html:p>

 <html:div class="jms-indent-block" style="
  margin-left: 1em;
  margin-bottom: 1em;
  border-left: 4px solid black;
  padding-left: 12px;
  background-color: whitesmoke;
  ">
  <html:strong>Problems:</html:strong>
  <html:ol><html:li>Very large vocabulary</html:li>
    <html:li>Many characters are quite rare.</html:li></html:ol>
</html:div>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>1</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
There is a fundamental <html:strong>tradeoff</html:strong> between compression ratio and vocabulary size. As an example, suppose we map every sequence of <fr:tex display="inline"><![CDATA[n]]></fr:tex> bytes to a token. This would achieve a compression ratio of <fr:tex display="inline"><![CDATA[n]]></fr:tex>. However, this would require <fr:tex display="inline"><![CDATA[256^n]]></fr:tex> tokens in our vocabulary.
</fr:mainmatter></fr:tree>

<html:p>
  Problem 2 was not entirely straight-forward to me. This actually reminds me of an idea from my <fr:link href="/004B/" title="Notebook: Information Theory" uri="https://kellenkanarios.com/004B/" display-uri="004B" type="local">information theory</fr:link> course, where we can assume we are given a "prior" over human language then we want to map low-probability characters to large strings in order to minimize the expected length (see <fr:link href="/005Z/" title="Huffman Code" uri="https://kellenkanarios.com/005Z/" display-uri="005Z" type="local">huffman coding</fr:link>).
</html:p>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>1</fr:day></fr:date><fr:title text="Byte-based tokenization">Byte-based tokenization</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>In byte-based tokenization, each byte is a token achieving a compression ratio of exactly <fr:tex display="inline"><![CDATA[1]]></fr:tex>, where a byte <fr:tex display="inline"><![CDATA[\mapsto  [0, 256]]]></fr:tex>
. This is very elegant in the sense that our vocabulary size is fixed at <fr:tex display="inline"><![CDATA[256]]></fr:tex>.
</html:p>

 <html:div class="jms-indent-block" style="
  margin-left: 1em;
  margin-bottom: 1em;
  border-left: 4px solid black;
  padding-left: 12px;
  background-color: whitesmoke;
  ">
  <html:strong>Problem:</html:strong>
However, with this, the length of our encoding is # of bytes in the string, which will become too long.
</html:div>

</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>1</fr:day></fr:date><fr:title text="Word-based tokenization">Word-based tokenization</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>
In <html:em>word-based tokenization</html:em>, we simply split the string into the corresponding words then map each of these to a unique integer.
    </html:p>

 <html:div class="jms-indent-block" style="
  margin-left: 1em;
  margin-bottom: 1em;
  border-left: 4px solid black;
  padding-left: 12px;
  background-color: whitesmoke;
  ">
  <html:strong>Problem:</html:strong> The vocabulary size is "unbounded" i.e. if we see a word we have not seen before then we need to extend the vocabulary size.
</html:div>

</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>1</fr:day></fr:date><fr:title text="Byte Pair Encoding">Byte Pair Encoding</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>For the <html:em>byte pair encoding</html:em> (BPE), we instead <html:em>train</html:em> the tokenizer on raw text to automatically determine the vocabulary.</html:p>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>1</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
In GPT2, they first split the raw text into words and then do this byte pair encoding.
</fr:mainmatter></fr:tree>

<html:p><html:strong>Algorithm:</html:strong></html:p>

 <html:div class="jms-indent-block" style="
  margin-left: 1em;
  margin-bottom: 1em;
  border-left: 4px solid black;
  padding-left: 12px;
  background-color: whitesmoke;
  ">
<html:em>while</html:em> <html:strong>true</html:strong>:
<html:ol><html:li>Count occurences of byte pairs. Store in dict <fr:tex display="inline"><![CDATA[D]]></fr:tex> with <fr:tex display="inline"><![CDATA[\{(b_1, b_2): \text {count}\}]]></fr:tex></html:li>
  <html:li>Find <fr:tex display="inline"><![CDATA[(b_1, b_2)]]></fr:tex> with highest count.</html:li>
  <html:li>Merge <fr:tex display="inline"><![CDATA[(b_1, b_2)]]></fr:tex> by <fr:tex display="inline"><![CDATA[(b_{1}, b_{2}) \mapsto  b']]></fr:tex></html:li>
  <html:li>Replace all instances of <fr:tex display="inline"><![CDATA[(b_{1}, b_{2})]]></fr:tex> in string with <fr:tex display="inline"><![CDATA[b']]></fr:tex> i.e. 
  <fr:tex display="block"><![CDATA[b_{1} b_{2} b_{3} b_{4} \mapsto  b'b_{3} b_{4}]]></fr:tex></html:li></html:ol>
</html:div>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>1</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
  There are a few additional implementation details to consider for project 1.
<html:ol><html:li><fr:tex display="inline"><![CDATA[\mathsf {encode}]]></fr:tex> loops over all merges. Only loop over merges that matter.</html:li>
  <html:li>Detect and preserve special tokens (e.g. &lt;|endoftext|&gt;)</html:li>
  <html:li>Use pre-tokenization (GPT2 regex)</html:li></html:ol>
</fr:mainmatter></fr:tree>

</fr:mainmatter></fr:tree>
</fr:mainmatter>
                </fr:tree>
              </fr:mainmatter>
            </fr:tree>
            <fr:tree show-metadata="false" expanded="false">
              <fr:frontmatter>
                <fr:authors>
                  <fr:author>
                    <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
                  </fr:author>
                </fr:authors>
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>7</fr:month>
                  <fr:day>3</fr:day>
                </fr:date>
                <fr:uri>https://kellenkanarios.com/DEQS/</fr:uri>
                <fr:display-uri>DEQS</fr:display-uri>
                <fr:route>/DEQS/</fr:route>
                <fr:title text="CS336 Lecture 2"><fr:link href="/0085/" title="Notebook: Stanford CS336" uri="https://kellenkanarios.com/0085/" display-uri="0085" type="local">CS336</fr:link> Lecture 2</fr:title>
              </fr:frontmatter>
              <fr:mainmatter><html:p><fr:link href="/007U/" title="Deliberate-Practice" uri="https://kellenkanarios.com/007U/" display-uri="007U" type="local">Deliberate-Practice</fr:link> (4/66)</html:p>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:title text="Motivating Questions">Motivating Questions</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>We start by discussing a few essential questions one hopes to answer when they set out to train a large model.</html:p>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:taxon>Question</fr:taxon></fr:frontmatter><fr:mainmatter>How long to train a 70b parameter model on 15T tokens on 1024 H100s?
</fr:mainmatter></fr:tree>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:taxon>Answer</fr:taxon></fr:frontmatter><fr:mainmatter>Mysteriously, we spawn from the ether (will be explained later) that <html:code>total_flops = 6 * 70e9 * 15e12</html:code>. Intuitively, we know that we need to perform some computation for each parameter for each token. However, the 6 is still an ominous mystery. Given the total flops, we then can just take the GPUs FLOP/s multiply by the number of seconds in the day and divide <html:code>total_flops</html:code> by this number i.e. 
<html:code>days = total_flops / flops_per_day</html:code>
</fr:mainmatter></fr:tree>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
In practice, we must also consider the <html:em>model flop utilization</html:em> (MFU). Basically, our algorithm cannot utilize the entirety of the maximum FLOP/s provided by the hardware due to things like memory bandwidth, etc. To account for this in the calculation, they just take <html:code>flops_per_day / 2</html:code>.
</fr:mainmatter></fr:tree>



    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:taxon>Question</fr:taxon></fr:frontmatter><fr:mainmatter>
  What is the largest model that you can train on 8 H100s using AdamW?
</fr:mainmatter></fr:tree>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:taxon>Answer</fr:taxon></fr:frontmatter><fr:mainmatter>
  An H100 has 80gb of shared memory i.e. <html:code>h100_bytes = 80e9</html:code>. The calculation then proceeds as
  <html:pre><![CDATA[# parameters, gradients, optimizer state
bytest_per_param = 4 + 4 + (4 + 4)
num_parameters = (h100_bytes * 8) / bytes_per_parameter]]></html:pre>
  what we need each of parameters, gradients, optimizer state will become clear later.
</fr:mainmatter></fr:tree>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
In practice, we also need to account for activations, which will depend on <html:strong>both</html:strong> batch size and sequence length.
</fr:mainmatter></fr:tree>

  </fr:mainmatter></fr:tree>
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:uri>https://kellenkanarios.com/DEQU/</fr:uri><fr:display-uri>DEQU</fr:display-uri><fr:route>/DEQU/</fr:route><fr:title text="Memory Accounting">Memory Accounting</fr:title></fr:frontmatter><fr:mainmatter><html:p><html:strong>Tensor Memory</html:strong>:
Tensors are stored as a <html:em>floating point number</html:em>. Memory is determined by (i) number of values in tensor and (ii) data type of each value.
</html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:uri>https://kellenkanarios.com/DEQV/</fr:uri><fr:display-uri>DEQV</fr:display-uri><fr:route>/DEQV/</fr:route><fr:title text="Low Precision Data Types">Low Precision Data Types</fr:title></fr:frontmatter><fr:mainmatter><html:p><html:code>float16</html:code>: here, we decrease both the fraction and exponent bits. Importantly, there are only <fr:tex display="inline"><![CDATA[5]]></fr:tex> exponent bits making the effective range <fr:tex display="inline"><![CDATA[(2^{-6}, 2^{6})]]></fr:tex>. The dynamic range for small numbers is pretty bad. This can cause small numbers to "die" effectively killing these neurons for the remainder of learning due to backpropagation.
</html:p><html:p><html:code>bfloat16</html:code>: to fix the problems with <html:code>float16</html:code>, they instead keep <fr:tex display="inline"><![CDATA[8]]></fr:tex> exponent bits and reduce the fraction bits to <fr:tex display="inline"><![CDATA[7]]></fr:tex>. This maintains the same dynamic range as <html:code>float32</html:code> while still only using <fr:tex display="inline"><![CDATA[16]]></fr:tex> bits. 
</html:p><html:p><html:code>fp8</html:code>: Two variants
<html:ol><html:li>E4M3: has 4 exponent bits and 3 mantissa bits</html:li> 
<html:li>E5M2: has 5 exponent bits and 2 mantissa bits</html:li></html:ol>
Requires modern Hopper Architecture i.e. H100 to perform operations. Also supported by TPUs.
</html:p></fr:mainmatter></fr:tree><html:p><html:strong>Training Implications</html:strong>
<html:ol><html:li><html:code>float32</html:code> training works but requires lots of memory</html:li>
  <html:li>Using <fr:link href="/DEQV/" title="Low Precision Data Types" uri="https://kellenkanarios.com/DEQV/" display-uri="DEQV" type="local">lower precision data types</fr:link> allows you to train larger models due to lower memory requirements, but can cause instability</html:li>
  <html:li>To optimize this tradeoff, use <html:em>mixed-precision training</html:em>.</html:li></html:ol></html:p></fr:mainmatter></fr:tree><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:uri>https://kellenkanarios.com/DYIV/</fr:uri><fr:display-uri>DYIV</fr:display-uri><fr:route>/DYIV/</fr:route><fr:title text="Torch Tensors">Torch Tensors</fr:title></fr:frontmatter><fr:mainmatter><html:p>
In pytorch, tensors are <html:em>contiguous</html:em> blocks of memory, where their shape is controlled by <html:em>strides</html:em>. A stride basically just refers to how far you have to jump in physical memory to correspond to incrementing the logical index i.e. in a (2, 3) matrix each row requires jumping <fr:tex display="inline"><![CDATA[3]]></fr:tex> spots in physical memory. Thus, <html:code>stride[1] = 3</html:code>.
  </html:p>
    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
Calling <html:code>.view((m, n))</html:code> just changes the stride but does <html:strong>not</html:strong> modify the physical memory. If you call <html:code>.view</html:code> that results in a non-contiguous view, then you cannot call <html:code>.view</html:code> again because it assumes contiguous indexing to properly adjust the strides. To deal with this, they have <html:code>.contiguous()</html:code> and <html:code>.reshape()</html:code> is basically <html:code>.contiguous().view()</html:code>.
</fr:mainmatter></fr:tree>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
All <html:strong>elementwise</html:strong> operations make a copy i.e. <html:code>x + y</html:code>. A useful function for masked attention is <html:code>triu()</html:code>.
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:title text="Einops">Einops</fr:title></fr:frontmatter><fr:mainmatter>
Einops is a useful python library to keep track of high-dimensional matrix operations i.e. matmuls over <html:code>batch_size</html:code>, <html:code>seqlen</html:code>, etc. High level overview
<html:ul><html:li>Initialize like <html:code>X[float.tensor, "batch seq hidden"] = torch.tensor((2, 3, 4))</html:code></html:li>
  <html:li>Can perform matmul with named dims like</html:li>
  <html:code>z = einsum(x, y, "batch seq1 hidden, batch seq2 hidden -&gt; batch seq1 seq2")</html:code>
  <html:li><html:code>reduce</html:code>: <html:code>x = reduce(x, "x y z -&gt; x y 1")</html:code> is just like <html:code>mean(x, axis=-1)</html:code></html:li>
  <html:li><html:code>rearrange</html:code>: <html:code>x = rearrange(x, "... (heads hidden1) -&gt; ... heads hidden 1")</html:code></html:li></html:ul>
</fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:title text="Computation">Computation</fr:title></fr:frontmatter><fr:mainmatter>
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>12</fr:day></fr:date><fr:uri>https://kellenkanarios.com/4K5H/</fr:uri><fr:display-uri>4K5H</fr:display-uri><fr:route>/4K5H/</fr:route><fr:title text="Floating Point Operations">Floating Point Operations</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>We refer to the <html:strong>total</html:strong> number of floating point operatings as <html:em>FLOPS</html:em>. Alternatively, we refer to the number of floating point operations per second as <html:em>FLOP/s</html:em>.</html:p></fr:mainmatter></fr:tree>
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>12</fr:day></fr:date><fr:uri>https://kellenkanarios.com/99G8/</fr:uri><fr:display-uri>99G8</fr:display-uri><fr:route>/99G8/</fr:route><fr:title text="Model FLOP Utilization (MFU)">Model FLOP Utilization (MFU)</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>Given a promised <fr:link href="/4K5H/" title="Floating Point Operations" uri="https://kellenkanarios.com/4K5H/" display-uri="4K5H" type="local">FLOP/s</fr:link>, the <html:em>model flop utilization</html:em> is given by
<fr:tex display="block"><![CDATA[\frac {\text {actual FLOP/s}}{\text {promised FLOP/s}}]]></fr:tex></html:p></fr:mainmatter></fr:tree>

   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:taxon>Example</fr:taxon></fr:frontmatter><fr:mainmatter>
Performing a matrix multiplication <fr:tex display="inline"><![CDATA[A \cdot  B]]></fr:tex> for <fr:tex display="inline"><![CDATA[A \in  \mathbb {R}^{(B \times  D)}]]></fr:tex> and <fr:tex display="inline"><![CDATA[B \in  \mathbb {R}^{(D \times  K)}]]></fr:tex>, requires <fr:tex display="inline"><![CDATA[2 \times  B \times  D \times  K]]></fr:tex> <fr:link href="/4K5H/" title="Floating Point Operations" uri="https://kellenkanarios.com/4K5H/" display-uri="4K5H" type="local">FLOPS</fr:link></fr:mainmatter></fr:tree>
 

</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:title text="Optimizers">Optimizers</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>I hope to do a formal blog touring optimizers because I have written a paper on deep learning optimizers for my <fr:link href="/0033/" title="Notebook: Optimization Theory" uri="https://kellenkanarios.com/0033/" display-uri="0033" type="local">optimization course</fr:link>. Due to this, I will leave this blank for now. A brief list of the covered concepts are below:</html:p>
<html:ul><html:li>momentum</html:li>
  <html:li>adagrad</html:li>
  <html:li>RMSProp</html:li>
  <html:li>Adam</html:li></html:ul>
<html:p>A key formula to remember:
<fr:tex display="block"><![CDATA[\text {total memory} \approx  4 \times  (\text {params} + \text {activations} + \text {grad size} + \text {optimizer state size})]]></fr:tex></html:p>
</fr:mainmatter></fr:tree>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>3</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
Another useful trick is to use <fr:link href="/DEQV/" title="Low Precision Data Types" uri="https://kellenkanarios.com/DEQV/" display-uri="DEQV" type="local">low precision</fr:link> for forward pass activations, then use <html:code>float32</html:code> for gradients and network parameters.
</fr:mainmatter></fr:tree>
</fr:mainmatter>
            </fr:tree>
            <fr:tree show-metadata="false" expanded="false">
              <fr:frontmatter>
                <fr:authors>
                  <fr:author>
                    <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
                  </fr:author>
                </fr:authors>
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>7</fr:month>
                  <fr:day>13</fr:day>
                </fr:date>
                <fr:uri>https://kellenkanarios.com/ESQ3/</fr:uri>
                <fr:display-uri>ESQ3</fr:display-uri>
                <fr:route>/ESQ3/</fr:route>
                <fr:title text="CS336 Lecture 3"><fr:link href="/0085/" title="Notebook: Stanford CS336" uri="https://kellenkanarios.com/0085/" display-uri="0085" type="local">CS336</fr:link> Lecture 3</fr:title>
              </fr:frontmatter>
              <fr:mainmatter><html:p><fr:link href="/007U/" title="Deliberate-Practice" uri="https://kellenkanarios.com/007U/" display-uri="007U" type="local">Deliberate practice</fr:link> (5/66).</html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>13</fr:day></fr:date><fr:uri>https://kellenkanarios.com/W4WB/</fr:uri><fr:display-uri>W4WB</fr:display-uri><fr:route>/W4WB/</fr:route><fr:title text="Architecture Variations">Architecture Variations</fr:title></fr:frontmatter><fr:mainmatter>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>13</fr:day></fr:date><fr:title text="Norms">Norms</fr:title></fr:frontmatter><fr:mainmatter>
<html:p><html:strong>Pre-norm vs. Post-norm</html:strong>: The first architecture variation discussed is when to apply the <fr:link href="/LVV4/" title="Layer Normalization" uri="https://kellenkanarios.com/LVV4/" display-uri="LVV4" type="local">layer norm</fr:link>. As can be seen in the figure below, rather than apply the <fr:link href="/LVV4/" title="Layer Normalization" uri="https://kellenkanarios.com/LVV4/" display-uri="LVV4" type="local">layer norm</fr:link> in the residual stream. They instead place it before the FFN and MHA layers.</html:p>
<html:figure><html:img width="40%" src="/bafkrmiawz4eenenwuvnx3pzxjniwghlortvgc5ytxzq5z5oyznugozl22y.png" />
<html:figcaption>Post norm (a) vs. pre norm (b).</html:figcaption></html:figure>
<html:p>They actually found that adding <fr:link href="/LVV4/" title="Layer Normalization" uri="https://kellenkanarios.com/LVV4/" display-uri="LVV4" type="local">layer normalization</fr:link> before and after the MHA and FFN works the best. This is known as <html:em>double norm</html:em>.</html:p>
<html:p><html:strong><fr:link href="/1XNO/" title="RMS Norm" uri="https://kellenkanarios.com/1XNO/" display-uri="1XNO" type="local">RMSNorm</fr:link> vs. <fr:link href="/LVV4/" title="Layer Normalization" uri="https://kellenkanarios.com/LVV4/" display-uri="LVV4" type="local">LayerNorm</fr:link></html:strong>:
Another useful trick is to use the <fr:link href="/1XNO/" title="RMS Norm" uri="https://kellenkanarios.com/1XNO/" display-uri="1XNO" type="local">RMSNorm</fr:link> instead of <fr:link href="/LVV4/" title="Layer Normalization" uri="https://kellenkanarios.com/LVV4/" display-uri="LVV4" type="local">LayerNorm</fr:link>.
</html:p>
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/1XNO/</fr:uri><fr:display-uri>1XNO</fr:display-uri><fr:route>/1XNO/</fr:route><fr:title text="RMS Norm">RMS Norm</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The RMS norm is simply the <fr:link href="/LVV4/" title="Layer Normalization" uri="https://kellenkanarios.com/LVV4/" display-uri="LVV4" type="local">layer norm</fr:link> without the added bias term and centering i.e. 
<fr:tex display="block"><![CDATA[\mathrm {RMSNorm}: \mathbb {R}^d \to  \mathbb {R}^d, \quad  \mathbf {x} \mapsto  \frac {\mathbf {x}}{\sqrt {\mathrm {Var}[\mathbf {x}_i] + \epsilon }}*\gamma .]]></fr:tex>
This is used to spare memory movement of <fr:link href="/LVV4/" title="Layer Normalization" uri="https://kellenkanarios.com/LVV4/" display-uri="LVV4" type="local">layernorm</fr:link>, where the bias term <fr:tex display="inline"><![CDATA[\beta  \in  \mathbb {R}^d]]></fr:tex> and has been found to be empirically almost if not as good.
</html:p></fr:mainmatter></fr:tree>
<html:p>One might wonder if matrix multiplies are the only thing that matters what can such a small change really accomplish.</html:p>
<html:ul><html:li>Due to memory movement, despite being .17<![CDATA[%]]> of <fr:link href="/4K5H/" title="Floating Point Operations" uri="https://kellenkanarios.com/4K5H/" display-uri="4K5H" type="local">FLOPS</fr:link>, provided 25<![CDATA[%]]> speedup in runtime!!</html:li></html:ul>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>13</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
Most people apparently just drop the bias term and keep the centering i.e. subtracting the mean. This makes sense because computing the mean does not require loading any additional information back to memory.
</fr:mainmatter></fr:tree>

</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>13</fr:day></fr:date><fr:title text="Activations">Activations</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>Despite a long list of activations, the two focused on are <fr:link href="/BEA2/" title="Rectified Linear Unit (ReLU)" uri="https://kellenkanarios.com/BEA2/" display-uri="BEA2" type="local">ReLU</fr:link> and <fr:link href="/5SPM/" title="Gaussian Error Linear Unit (GELU)" uri="https://kellenkanarios.com/5SPM/" display-uri="5SPM" type="local">GELU</fr:link>.</html:p>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/BEA2/</fr:uri><fr:display-uri>BEA2</fr:display-uri><fr:route>/BEA2/</fr:route><fr:title text="Rectified Linear Unit (ReLU)">Rectified Linear Unit (ReLU)</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The <html:em>rectified linear unit</html:em>(ReLU) is defined as
<fr:tex display="block"><![CDATA[\mathrm {ReLU} : \mathbb {R}^d \to  \mathbb {R}^d, \quad  \mathbf {x} \mapsto  \max (0, \mathbf {x}),]]></fr:tex>
where the <fr:tex display="inline"><![CDATA[\max ]]></fr:tex> is done elementwise i.e. <fr:tex display="inline"><![CDATA[\mathrm {ReLU}(\mathbf {x})_i = \max (0, x_i)]]></fr:tex>
This provides "nice" gradients, making it common when training neural networks.
</html:p></fr:mainmatter></fr:tree>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/5SPM/</fr:uri><fr:display-uri>5SPM</fr:display-uri><fr:route>/5SPM/</fr:route><fr:title text="Gaussian Error Linear Unit (GELU)">Gaussian Error Linear Unit (GELU)</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The <html:em>Gaussian Error Linear Unit</html:em> (GELU) is a slight modification to the <fr:link href="/BEA2/" title="Rectified Linear Unit (ReLU)" uri="https://kellenkanarios.com/BEA2/" display-uri="BEA2" type="local">ReLU</fr:link> to account for the non-differentiability at <fr:tex display="inline"><![CDATA[0]]></fr:tex>. Namely,
<fr:tex display="block"><![CDATA[\mathrm {GELU}(\mathbf {x}) : \mathbb {R}^d \to  \mathbb {R}^d, \quad  \mathbf {x} \mapsto  \mathbf {x} \cdot  \psi (\mathbf {x}),]]></fr:tex>
where <fr:tex display="inline"><![CDATA[\psi (\mathbf {x}) = \mathrm {CDF}(\mathcal {N}(\mathbf {x}, \mathbf {I}))]]></fr:tex></html:p><html:figure><html:img width="70%" src="/bafkrmian7h7ke2dp6nqdq4624wx4off5lk346f7d5pp6mv7bbimcy7azni.png" />
<html:figcaption>GELU vs. ReLU activation and derivative. Taken from <fr:link href="https://www.baeldung.com/cs/gelu-activation-function" type="external">here</fr:link>.</html:figcaption></html:figure></fr:mainmatter></fr:tree>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/OZD8/</fr:uri><fr:display-uri>OZD8</fr:display-uri><fr:route>/OZD8/</fr:route><fr:title text="Swish Activation">Swish Activation</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The <html:em>Swish</html:em> activation is given by
<fr:tex display="block"><![CDATA[\mathrm {Swish}(\mathbf {x}) : \mathbb {R}^d \to  \mathbb {R}^d, \quad  \mathbf {x} \mapsto  \mathbf {x} s(\mathbf {x}),]]></fr:tex>
where <fr:tex display="inline"><![CDATA[s : \mathbb {R}^d \to  \mathbb {R}^d]]></fr:tex> is the <fr:link href="/NNDS/" title="Sigmoid" uri="https://kellenkanarios.com/NNDS/" display-uri="NNDS" type="local">sigmoid function</fr:link>.
</html:p></fr:mainmatter></fr:tree>
  
    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>13</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
  The extra computation required by <fr:link href="/5SPM/" title="Gaussian Error Linear Unit (GELU)" uri="https://kellenkanarios.com/5SPM/" display-uri="5SPM" type="local">GELU</fr:link> or <fr:link href="/OZD8/" title="Swish Activation" uri="https://kellenkanarios.com/OZD8/" display-uri="OZD8" type="local">Swish</fr:link> is a non-factor because <fr:link href="/4K5H/" title="Floating Point Operations" uri="https://kellenkanarios.com/4K5H/" display-uri="4K5H" type="local">FLOPS</fr:link> are dominated by matrix multiplication and there is no increase in memory pressure.
  </fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/K2N7/</fr:uri><fr:display-uri>K2N7</fr:display-uri><fr:route>/K2N7/</fr:route><fr:title text="Gated Linear Unit (GLU)">Gated Linear Unit (GLU)</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>A <html:em>gated linear unit</html:em> is an activation function combined with an elementwise multiplication i.e. 
<html:ul><html:li><fr:tex display="inline"><![CDATA[\mathrm {ReGLU} = \mathrm {ReLU}(\mathbf {x}) \otimes  \mathbf {V} \mathbf {x},]]></fr:tex></html:li>
  <html:li><fr:tex display="inline"><![CDATA[\mathrm {SwiGLU} = \mathrm {Swish}(\mathbf {x}) \otimes  \mathbf {V} \mathbf {x},]]></fr:tex></html:li></html:ul>
where <fr:tex display="inline"><![CDATA[\mathrm {ReLU}]]></fr:tex> is the <fr:link href="/BEA2/" title="Rectified Linear Unit (ReLU)" uri="https://kellenkanarios.com/BEA2/" display-uri="BEA2" type="local">ReLU</fr:link> activation and <fr:tex display="inline"><![CDATA[\mathrm {Swish}]]></fr:tex> is the <fr:link href="/OZD8/" title="Swish Activation" uri="https://kellenkanarios.com/OZD8/" display-uri="OZD8" type="local">Swish</fr:link> activation respectively.
</html:p>
    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
The matrix <fr:tex display="inline"><![CDATA[\mathbf {V}]]></fr:tex> introduces additional learnable parameters. Therefore, an architecture that uses gating typically reduces their other parameters by a factor of <fr:tex display="inline"><![CDATA[\frac {2}{3}]]></fr:tex>.
</fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>13</fr:day></fr:date><fr:title text="Serial vs. Parallel">Serial vs. Parallel</fr:title></fr:frontmatter><fr:mainmatter>
Another small trick is to parallelize computation. Traditionally, one computes the <fr:tex display="inline"><![CDATA[\mathrm {MHA}]]></fr:tex> output and then passes this to the <fr:tex display="inline"><![CDATA[\mathrm {FFN}]]></fr:tex> i.e.
<fr:tex display="block"><![CDATA[\mathbf {y} = \mathbf {x} + \mathrm {FFN}(\mathrm {LN}(\mathbf {x} + \mathrm {MHA}(\mathrm {LN}(\mathbf {x})))).]]></fr:tex>
However, this requires waiting for the <fr:tex display="inline"><![CDATA[\mathrm {MHA}]]></fr:tex> to complete before performing the <fr:tex display="inline"><![CDATA[\mathrm {FFN}]]></fr:tex> computation. It has been found that performing these in parallel does not cause any severe degradation in performance. Explicitly, instead they do
<fr:tex display="block"><![CDATA[\mathbf {y} = \mathbf {x} + \mathrm {FFN}(\mathrm {LN}(\mathbf {x})) + \mathrm {MHA}(\mathrm {LN}(\mathbf {x}))]]></fr:tex>
</fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/TOD6/</fr:uri><fr:display-uri>TOD6</fr:display-uri><fr:route>/TOD6/</fr:route><fr:title text="Rotary Position Embeddings (ROPE)">Rotary Position Embeddings (ROPE)</fr:title></fr:frontmatter><fr:mainmatter><html:p><html:strong>Notation</html:strong>:
For this section, our notion of an <html:em>embedding</html:em> is a function <fr:tex display="inline"><![CDATA[f]]></fr:tex> that takes a token and a position i.e. <fr:tex display="inline"><![CDATA[f(x, i)]]></fr:tex> is the embedding of token <fr:tex display="inline"><![CDATA[x]]></fr:tex>, occurring at position <fr:tex display="inline"><![CDATA[i]]></fr:tex>.
</html:p><html:p><html:strong>Idea:</html:strong> the <fr:link href="/B1RI/" title="Inner Product" uri="https://kellenkanarios.com/B1RI/" display-uri="B1RI" type="local">inner product</fr:link> of two embeddings should only need relative positioning i.e. for any two <fr:tex display="inline"><![CDATA[\mathbf {x}]]></fr:tex>, <fr:tex display="inline"><![CDATA[\mathbf {y}]]></fr:tex> with positions <fr:tex display="inline"><![CDATA[i]]></fr:tex> and <fr:tex display="inline"><![CDATA[j]]></fr:tex> respectively, there should exist some <fr:tex display="inline"><![CDATA[g]]></fr:tex>, such that
<fr:tex display="block"><![CDATA[\langle  f(\mathbf {x}, i), f(\mathbf {y}, j) \rangle  = g(\mathbf {x}, \mathbf {y}, i - j)]]></fr:tex>
Namely, this can be written as a function of just the relative positioning between the embeddings.
</html:p><html:p>The simplest transformation that only preserves this relative information are <fr:link href="/10H9/" title="Rotation matrix" uri="https://kellenkanarios.com/10H9/" display-uri="10H9" type="local">rotations</fr:link>.</html:p><html:figure><html:img width="50%" src="/bafkrmiba4muc7qqk2agccjalqpm24hxw7u4gkfpozmnhz7if6ncagxpsgi.png" />
<html:figcaption>Rotating embeddings does not change relative position.</html:figcaption></html:figure><html:p>However, <fr:link href="/10H9/" title="Rotation matrix" uri="https://kellenkanarios.com/10H9/" display-uri="10H9" type="local">rotations</fr:link> are only easily defined for <fr:tex display="inline"><![CDATA[\mathbb {R}^2]]></fr:tex>. To get around this, they simply partition their input 2d slices and apply the rotation via
<fr:tex display="block"><![CDATA[\mathrm {ROT} = \begin {bmatrix} \cos  m \theta _{1} & - \sin  m \theta _{1} & & & \\
\sin  m \theta _{1} & \cos  m \theta _{1} & & & \\
& & \cos  m \theta _{2} & -\sin  m \theta _{2} & \\
& & \sin  m \theta _{2} & \cos  m \theta _{2} & \\
& & & & \ddots 
\end {bmatrix} ]]></fr:tex></html:p>
    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
The <fr:tex display="inline"><![CDATA[\theta _i]]></fr:tex>'s are fixed and chosen according to some schedule to capture different "frequencies". 
</fr:mainmatter></fr:tree>
<html:p>The embedding are used by appling them to the query and key matrices separately i.e. 
<fr:tex display="block"><![CDATA[W_K = \mathrm {ROT}(W_K), \quad  W_Q = \mathrm {ROT}(W_Q)]]></fr:tex>
These are then what is used in self-attention.
</html:p></fr:mainmatter></fr:tree><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/9VZH/</fr:uri><fr:display-uri>9VZH</fr:display-uri><fr:route>/9VZH/</fr:route><fr:title text="Hyperparameter Rules (CS336)">Hyperparameter Rules (<fr:link href="/0085/" title="Notebook: Stanford CS336" uri="https://kellenkanarios.com/0085/" display-uri="0085" type="local">CS336</fr:link>)</fr:title></fr:frontmatter><fr:mainmatter><html:p><html:strong>Rule 1</html:strong>: <fr:tex display="inline"><![CDATA[d_{\text {ff}} = d_{\text {model}}]]></fr:tex>
<html:ul><html:li><fr:tex display="inline"><![CDATA[d_{\text {model}}]]></fr:tex> is the input dimension</html:li>
  <html:li><fr:tex display="inline"><![CDATA[d_{\text {ff}}]]></fr:tex> is the hidden dimension</html:li></html:ul></html:p><html:p><html:strong>Exception 1</html:strong>: in the case of <fr:link href="/K2N7/" title="Gated Linear Unit (GLU)" uri="https://kellenkanarios.com/K2N7/" display-uri="K2N7" type="local">GLUs</fr:link>, we recall that to account for extra parameters we scale <fr:tex display="inline"><![CDATA[\frac {2}{3}]]></fr:tex>. Therefore, <fr:tex display="inline"><![CDATA[d_{\text {ff}} = \frac {8}{3}d_{\text {model}}]]></fr:tex>.</html:p><html:p><html:strong>Exception 2</html:strong>: In T5, they use <fr:tex display="inline"><![CDATA[d_{\text {ff}} = 64d_{\text {model}}]]></fr:tex>. The logic for this was that we could maximize the <fr:link href="/99G8/" title="Model FLOP Utilization (MFU)" uri="https://kellenkanarios.com/99G8/" display-uri="99G8" type="local">MFU</fr:link> by increasing matrix size. Ended up going back to small <fr:tex display="inline"><![CDATA[d_{\text {model}}]]></fr:tex>.</html:p><html:p><html:strong>Rule 2</html:strong>: <fr:tex display="inline"><![CDATA[d_{\text {head}} = d_{\text {model}} / \text {num heads}]]></fr:tex>
<html:ul><html:li>I believe the <fr:tex display="inline"><![CDATA[d_{\text {head}}]]></fr:tex> is the output dim of each head.</html:li>
  <html:li>This just says the total output dim for <fr:tex display="inline"><![CDATA[n]]></fr:tex> heads is the same as if we did one head.</html:li>
  <html:li>Means there is something important about splitting up the heads.</html:li></html:ul></html:p><html:p><html:strong>Rule 3</html:strong>: Aspect ratio = <fr:tex display="inline"><![CDATA[\frac {d_{\text {model}}}{n_{\text {layer}}} \approx  100-200]]></fr:tex>
<html:ul><html:li>Pipeline dependent: if network speed is fast than parallelizing is easier and shallow networks are better.</html:li>
  <html:li>If poor network speed then pipeline parallel might be more viable and deeper networks would be more parallelizable.</html:li></html:ul></html:p><html:p><html:strong>Rule 4:</html:strong> Vocab size
<html:ul><html:li>For single language models, vocab size is typically <fr:tex display="inline"><![CDATA[30-50k]]></fr:tex></html:li>
  <html:li>For multi language models, vocab size is typically <fr:tex display="inline"><![CDATA[100-250k]]></fr:tex></html:li></html:ul></html:p></fr:mainmatter></fr:tree>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>13</fr:day></fr:date><fr:title text="Regularization and Dropout">Regularization and Dropout</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>Since there is so much data, it is not feasible to train your model for multiple epochs. This is actually nice in the sense that we do not have to worry about overfitting and performing regularization.</html:p>
<html:p>However, many of the large models are still trained with weight decay. Tatsu claims that this is not to do with regularization but actually due to some weird interaction with the learning rate schedule. I am not sure I entirely understood this part.</html:p>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>13</fr:day></fr:date><fr:title text="Stability Tricks">Stability Tricks</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>The <fr:link href="/C00V/" title="Softmax" uri="https://kellenkanarios.com/C00V/" display-uri="C00V" type="local">softmax</fr:link> is ill-behaved due to the exponentials. In the transformer, we have two softmaxes: one at the end and one in the <fr:link href="/004G/" title="Self-Attention" uri="https://kellenkanarios.com/004G/" display-uri="004G" type="local">attention</fr:link>.
<html:ul><html:li>For the first, note <fr:tex display="block"><![CDATA[\log  \sigma (\mathbf {x})_i = \log (x_i) - \log  \underbrace {\sum _{j=1}^{d} e^{x_j}}_{D(\mathbf {x})}]]></fr:tex>
   The only problem is the denominator term. The idea is to enforce the <fr:tex display="inline"><![CDATA[D(\mathbf {x}) = 1]]></fr:tex> by regularizing via a penalty on <fr:tex display="inline"><![CDATA[\log  D(\mathbf {x})]]></fr:tex> ie.
<fr:tex display="block"><![CDATA[\mathcal {L}_{\text {aux}} = 10^{-4} \log ^2(D(\mathbf {x}))]]></fr:tex>
With the <fr:tex display="inline"><![CDATA[\nabla  D(\mathbf {x})]]></fr:tex> should be <fr:tex display="inline"><![CDATA[0]]></fr:tex> and we are effectively only considering the non-exponential term.
   </html:li>
   <html:li>For the <fr:link href="/004G/" title="Self-Attention" uri="https://kellenkanarios.com/004G/" display-uri="004G" type="local">attention</fr:link>, they primarily operate on the <html:em>logits</html:em> prior to the softmax. One way is via <fr:link href="/LVV4/" title="Layer Normalization" uri="https://kellenkanarios.com/LVV4/" display-uri="LVV4" type="local">layer norm</fr:link> before the <fr:link href="/C00V/" title="Softmax" uri="https://kellenkanarios.com/C00V/" display-uri="C00V" type="local">softmax</fr:link>. Another is via <html:em>softcapping</html:em> i.e.
   <fr:tex display="block"><![CDATA[\mathrm {logits} = \mathrm {softcap} \cdot  \tanh  \left ( \frac {\mathrm {logits}}{\mathrm {softcap}} \right ) ]]></fr:tex></html:li></html:ul></html:p>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>13</fr:day></fr:date><fr:title text="Attention Variants">Attention Variants</fr:title></fr:frontmatter><fr:mainmatter>
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/W4YP/</fr:uri><fr:display-uri>W4YP</fr:display-uri><fr:route>/W4YP/</fr:route><fr:title text="Multi Query Attention">Multi Query Attention</fr:title></fr:frontmatter><fr:mainmatter><html:p>Notes on the paper <fr:link href="/shazeerFastTransformerDecoding2019/" title="Fast Transformer Decoding: One Write-Head is All You Need" uri="https://kellenkanarios.com/shazeerFastTransformerDecoding2019/" display-uri="shazeerFastTransformerDecoding2019" type="local">Fast Transformer Decoding: One Write-Head is All You Need</fr:link>.</html:p><html:p>For, 
<html:ul><html:li><fr:tex display="inline"><![CDATA[b]]></fr:tex> batch dimension,</html:li>
  <html:li><fr:tex display="inline"><![CDATA[n]]></fr:tex> sequence length,</html:li>
  <html:li><fr:tex display="inline"><![CDATA[d]]></fr:tex> hidden dimension,</html:li>
  <html:li><fr:tex display="inline"><![CDATA[h]]></fr:tex> number of heads.</html:li></html:ul>
The total <fr:link href="/4K5H/" title="Floating Point Operations" uri="https://kellenkanarios.com/4K5H/" display-uri="4K5H" type="local">FLOPS</fr:link> for <fr:link href="/004G/" title="Self-Attention" uri="https://kellenkanarios.com/004G/" display-uri="004G" type="local">attention</fr:link> are roughly <fr:tex display="inline"><![CDATA[bnd^2]]></fr:tex>. This comes from 
<html:ol><html:li><fr:tex display="inline"><![CDATA[3nd^2]]></fr:tex> FLOPS to compute <fr:tex display="inline"><![CDATA[Q = XW_Q, K = XW_K, V = XW_V]]></fr:tex>.</html:li>
  <html:li>Need to do this <fr:tex display="inline"><![CDATA[b]]></fr:tex> times for each input in batch.</html:li></html:ol>
and the total memory accesses are roughly <fr:tex display="inline"><![CDATA[\underbrace {bnd}_{X} + \underbrace {bhn^2}_{\text {softmax}} + \underbrace {d^2}_{\text {projection}}]]></fr:tex>.
This gives high arithmetic intensity
<fr:tex display="block"><![CDATA[O\left (\left (\frac {h}{d} + \frac {1}{bn}\right )^{-1}\right )]]></fr:tex></html:p><html:p>However, if we do incremental inference then we must multiply our total number of memory accesses by <fr:tex display="inline"><![CDATA[n]]></fr:tex> i.e. <fr:tex display="inline"><![CDATA[bn^2d + nd^2]]></fr:tex>. This gives arithmetic intensity
<fr:tex display="block"><![CDATA[O\left (\left (\frac {n}{d} + \frac {1}{b}\right )^{-1}\right ),]]></fr:tex>
which requires large batch and short sequence length.
</html:p>
    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
I believe we just ignore the softmax memory contribution in the inference case because it does not scale with <fr:tex display="inline"><![CDATA[n]]></fr:tex> anymore as we are computing the logits just for the next token. Therefore, it becomes a <fr:tex display="inline"><![CDATA[\frac {d}{h}]]></fr:tex> term, which we can safely ignore?
</fr:mainmatter></fr:tree>
<html:p>The key is that the <fr:tex display="inline"><![CDATA[\frac {n}{d}]]></fr:tex> term comes from the <fr:tex display="inline"><![CDATA[bn^2d]]></fr:tex> term, where we are loading <fr:tex display="inline"><![CDATA[h]]></fr:tex> <fr:tex display="inline"><![CDATA[(b \times  n \times  d / h)]]></fr:tex> <fr:tex display="inline"><![CDATA[K]]></fr:tex> and <fr:tex display="inline"><![CDATA[V]]></fr:tex> matrices <fr:tex display="inline"><![CDATA[n]]></fr:tex> times. Thus, we can improve the <fr:tex display="inline"><![CDATA[\frac {n}{d}]]></fr:tex> term by a factor of <fr:tex display="inline"><![CDATA[h]]></fr:tex> by simply not using a different <fr:tex display="inline"><![CDATA[K]]></fr:tex> and <fr:tex display="inline"><![CDATA[V]]></fr:tex> matrix for each head. This is the entire idea behind <fr:link href="/shazeerFastTransformerDecoding2019/" title="Fast Transformer Decoding: One Write-Head is All You Need" uri="https://kellenkanarios.com/shazeerFastTransformerDecoding2019/" display-uri="shazeerFastTransformerDecoding2019" type="local">MQA</fr:link>.</html:p>
    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
Similar to the <fr:link href="https://kellenkanarios.com/TJLA/" type="external">TJLA</fr:link>, we still can use <fr:tex display="inline"><![CDATA[h]]></fr:tex> <fr:tex display="inline"><![CDATA[Q]]></fr:tex> matrices because we do not need to load <fr:tex display="inline"><![CDATA[n]]></fr:tex> of them into memory because only the last one matters for inference.
</fr:mainmatter></fr:tree>
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/XUVV/</fr:uri><fr:display-uri>XUVV</fr:display-uri><fr:route>/XUVV/</fr:route><fr:title text="Group Query Attention">Group Query Attention</fr:title></fr:frontmatter><fr:mainmatter><html:p><html:em>Group query attention</html:em> is the same idea as <fr:link href="/shazeerFastTransformerDecoding2019/" title="Fast Transformer Decoding: One Write-Head is All You Need" uri="https://kellenkanarios.com/shazeerFastTransformerDecoding2019/" display-uri="shazeerFastTransformerDecoding2019" type="local">MQA</fr:link> but instead of using one <fr:tex display="inline"><![CDATA[K]]></fr:tex> and <fr:tex display="inline"><![CDATA[V]]></fr:tex> for every head, they use a <html:em>group</html:em> of them. Where obviously the number of groups needs to be less than the number of heads.</html:p><html:figure><html:img width="80%" src="/bafkrmicmjlgi2o3oetsssjdwk6y2pqce4vrdwiw2ah4wwe3ulnt74upkiu.png" />
<html:figcaption>Grouped query uses subset of <fr:tex display="inline"><![CDATA[K]]></fr:tex> and <fr:tex display="inline"><![CDATA[V]]></fr:tex> matrices.</html:figcaption></html:figure></fr:mainmatter></fr:tree><html:p>Also inspired by this idea of reducing the dependence of <fr:tex display="inline"><![CDATA[K]]></fr:tex> and <fr:tex display="inline"><![CDATA[V]]></fr:tex> on the sequence length is sliding window attention.</html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/WM3M/</fr:uri><fr:display-uri>WM3M</fr:display-uri><fr:route>/WM3M/</fr:route><fr:title text="Sliding Window Attention">Sliding Window Attention</fr:title></fr:frontmatter><fr:mainmatter><html:p>The idea behind <html:em>sliding window attention</html:em> is to ensure the number of weight matrices needed for the keys <fr:tex display="inline"><![CDATA[K]]></fr:tex> and values <fr:tex display="inline"><![CDATA[V]]></fr:tex> does not scale with the sequence length. Intuitively, this means allowing each word to "attend" to only some fixed number of previous words rather than the whole sequence</html:p><html:figure><html:img width="80%" src="/bafkrmidqeoo6wx6s4ry6u74fcelfzxvwreyf7d44whnql4ffnnyd2dwcha.png" />
<html:figcaption>"the" only sees "on" and "sat" rather than the full sentence.</html:figcaption></html:figure></fr:mainmatter></fr:tree></fr:mainmatter></fr:tree>
</fr:mainmatter></fr:tree>
</fr:mainmatter>
            </fr:tree>
          </fr:mainmatter>
        </fr:tree>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>
                <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
              </fr:author>
            </fr:authors>
            <fr:date>
              <fr:year>2025</fr:year>
              <fr:month>7</fr:month>
              <fr:day>1</fr:day>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/003W/</fr:uri>
            <fr:display-uri>003W</fr:display-uri>
            <fr:route>/003W/</fr:route>
            <fr:title text="LLMs">LLMs</fr:title>
          </fr:frontmatter>
          <fr:mainmatter><html:p>This will be my backlog accumulator / dump of related resources for my journey through the dubious waters of <fr:link href="/stanford/" title="Stanford University" uri="https://kellenkanarios.com/stanford/" display-uri="stanford" type="local">Stanford's</fr:link> <fr:link href="https://stanford-cs336.github.io/spring2025/index.htmlschedule" type="external">CS336</fr:link> and the broader journey toward understanding industry-level LLMs.</html:p>


  <fr:tree show-metadata="false" numbered="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>1</fr:day></fr:date><fr:title text="Reading List / Useful Resources">Reading List / Useful Resources</fr:title></fr:frontmatter><fr:mainmatter>
    <html:ul><html:li><fr:link href="https://hijkzzz.notion.site/rlhf-implementation-tricks?v=158d9a33ecc98132bf9e000c39227361" type="external">PPO + LLM Tricks</fr:link></html:li></html:ul>
</fr:mainmatter></fr:tree>

</fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
