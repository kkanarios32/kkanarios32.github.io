<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors>
      <fr:author>Ofir Nachum</fr:author>
      <fr:author>Shixiang Gu</fr:author>
      <fr:author>Honglak Lee</fr:author>
      <fr:author>Sergey Levine</fr:author>
    </fr:authors>
    <fr:date>
      <fr:year>2019</fr:year>
      <fr:month>1</fr:month>
    </fr:date>
    <fr:uri>https://kellenkanarios.com/nachumNearOptimalRepresentationLearning2019/</fr:uri>
    <fr:display-uri>nachumNearOptimalRepresentationLearning2019</fr:display-uri>
    <fr:route>/nachumNearOptimalRepresentationLearning2019/</fr:route>
    <fr:title text="Near-Optimal Representation Learning for Hierarchical Reinforcement Learning">Near-Optimal Representation Learning for Hierarchical Reinforcement Learning</fr:title>
    <fr:taxon>Reference</fr:taxon>
    <fr:meta name="external">https://arxiv.org/abs/1810.01257</fr:meta>
    <fr:meta name="bibtex"><![CDATA[@misc{nachumNearOptimalRepresentationLearning2019,
 title = {Near-{{Optimal Representation Learning}} for {{Hierarchical Reinforcement Learning}}},
 author = {Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
 year = {2019},
 urldate = {2024-11-07},
 number = {arXiv:1810.01257},
 publisher = {arXiv},
 file = {/home/kellen/Downloads/pdfs/storage/SIK848RC/Nachum et al. - 2019 - Near-Optimal Representation Learning for Hierarchical Reinforcement Learning.pdf},
 keywords = {Computer Science - Artificial Intelligence},
 langid = {english},
 archiveprefix = {arXiv},
 abstract = {We study the problem of representation learning in goal-conditioned hierarchical reinforcement learning. In such hierarchical structures, a higher-level controller solves tasks by iteratively communicating goals which a lower-level policy is trained to reach. Accordingly, the choice of representation -- the mapping of observation space to goal space -- is crucial. To study this problem, we develop a notion of sub-optimality of a representation, defined in terms of expected reward of the optimal hierarchical policy using this representation. We derive expressions which bound the sub-optimality and show how these expressions can be translated to representation learning objectives which may be optimized in practice. Results on a number of difficult continuous-control tasks show that our approach to representation learning yields qualitatively better representations as well as quantitatively better hierarchical policies, compared to existing methods (see videos at https://sites.google.com/view/representation-hrl).},
 primaryclass = {cs},
 eprint = {1810.01257},
 month = {January}
}]]></fr:meta>
  </fr:frontmatter>
  <fr:mainmatter />
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>
                <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
              </fr:author>
            </fr:authors>
            <fr:uri>https://kellenkanarios.com/2025-W29/</fr:uri>
            <fr:display-uri>2025-W29</fr:display-uri>
            <fr:route>/2025-W29/</fr:route>
            <fr:title text="Weekly Review 2025-W29">Weekly Review 2025-W29</fr:title>
          </fr:frontmatter>
          <fr:mainmatter>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:title text="The Quantified Me">The Quantified Me</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>This section is in large part to gaslight myself on the internet into being more productive but with the information provided let us introspect on what happened this week. </html:p>
  <html:p><html:strong>Coding:</html:strong> I will now proceed to justify and provide excuses on what went wrong this week. On Monday, we see that I spent a large part of my time on this forest. However, this was actually writing up my notes on <fr:link href="/ESQ3/" title="CS336 Lecture 3" uri="https://kellenkanarios.com/ESQ3/" display-uri="ESQ3" type="local">lecture 3</fr:link> of <fr:link href="/0085/" title="Notebook: Stanford CS336" uri="https://kellenkanarios.com/0085/" display-uri="0085" type="local">CS336</fr:link>. My goal of roughly 1ish hour of miscellaneous learning a day snowballed into what was seemingly <fr:tex display="inline"><![CDATA[4]]></fr:tex> hours of random activity, where I spiraled into <fr:link href="/W4YP/" title="Multi Query Attention" uri="https://kellenkanarios.com/W4YP/" display-uri="W4YP" type="local">MQA</fr:link>. I am thinking of putting this self-study on the backburner in favor of focusing on <fr:link href="/0084/" title="Notebook: Three Easy Pieces" uri="https://kellenkanarios.com/0084/" display-uri="0084" type="local">three easy pieces</fr:link> until the semester starts. I intend to take two courses on what is essentially LLMs systems this fall (very excited), so I might as well not double dip now. I am thinking about using projects 1 and 2 of this course to develop my own working LLM implementation. I can then use it as reference to try out and learn any new optimization tricks like <fr:link href="/W4YP/" title="Multi Query Attention" uri="https://kellenkanarios.com/W4YP/" display-uri="W4YP" type="local">MQA</fr:link> or <fr:link href="https://kellenkanarios.com/TJLA/" type="external">TJLA</fr:link>, etc. 
  <html:p>These plots also finally confirm what I noticed as a general trend in my working life. Namely, I spend a lot of time working Monday-Thu because of my weekly meetings with my advisor on Thursday. However, I do not properly make use of the rest of the week. This is a trend I hope to improve upon in future entries.</html:p></html:p>
<html:figure><html:img width="100%" src="/bafkrmibvtysmzc5gyedcfaj2sxjpviob6lxrcdiontte4cg4zu3cueiv7u.png" />
  <html:figcaption>Wakatime stats for week 2025-W29.</html:figcaption></html:figure>
  <html:p><html:strong>Rest of (computer) life:</html:strong> This week I did a pretty good job staying on task (at least on my computer). Very little brainrot was consumed and a decent amount of work was accomplished. Tune in next week to see if we can keep that up!
  </html:p>
<html:figure><html:img width="100%" src="/bafkrmie3tohm4dhy7zqt47zdirbm4xxk432rr4n3yncjdggmq4zetriwku.png" />
  <html:figcaption>Arbtt-stats for week 2025-W29.</html:figcaption></html:figure>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:title text="VO2 Max(ing)">VO2 Max(ing)</fr:title></fr:frontmatter><fr:mainmatter>
  <html:ul><html:li><html:strong>Current VO2 Max</html:strong>: 53</html:li>
    <html:li><html:strong>Weekly Mileage</html:strong>: 17.2</html:li></html:ul>
  <html:p>Unfortunately, I missed one run this week. The same one I miss every week: Sunday. I will still blame the shin splints, but this may be the last week I can do so (finally!). I am still maintaining a pretty good SPM, but I need to get some more lower HR runs in. From here on out, we should not dip below 20 miles a week. I have some travel coming up at <fr:link href="/rlc/" title="Reinforcement Learning Conference" uri="https://kellenkanarios.com/rlc/" display-uri="rlc" type="local">RLC</fr:link>, but I should be able to still run while I am there.</html:p>
<html:figure><html:img width="100%" src="/bafkrmicxnrelkrspghbameeb74obgst3bk2dj5vlirqeq73qymd7jsjuny.png" />
  <html:figcaption>Running stats for this week.</html:figcaption></html:figure>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:title text="Goals for next week">Goals for next week</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>This is another section, where I gaslight myself into some accountability on the internet.</html:p>
<html:p>For my imaginary audience, you should have a lot to look forward to in the next week. Namely, 
<html:ol><html:li>Look forward to an in-depth blog on <fr:link href="/lipmanFlowMatchingGenerative2023/" title="Flow Matching for Generative Modeling" uri="https://kellenkanarios.com/lipmanFlowMatchingGenerative2023/" display-uri="lipmanFlowMatchingGenerative2023" type="local">flow matching</fr:link> to accompany my <fr:link href="/FMTD/" title="Flow Matching and TD Flows" uri="https://kellenkanarios.com/FMTD/" display-uri="FMTD" type="local">slides</fr:link>.</html:li>
<html:li>I also should have two new <fr:link href="/005G/" title="Research Bible" uri="https://kellenkanarios.com/005G/" display-uri="005G" type="local">research bible</fr:link> entries one on the <fr:link href="/touatiLearningOneRepresentation2021/" title="Learning One Representation to Optimize All Rewards" uri="https://kellenkanarios.com/touatiLearningOneRepresentation2021/" display-uri="touatiLearningOneRepresentation2021" type="local">forward backward representation</fr:link> and the other on <fr:link href="/nachumNearOptimalRepresentationLearning2019/" title="Near-Optimal Representation Learning for Hierarchical Reinforcement Learning" uri="https://kellenkanarios.com/nachumNearOptimalRepresentationLearning2019/" display-uri="nachumNearOptimalRepresentationLearning2019" type="local">hierarchical rl</fr:link>.</html:li>
<html:li>For my <fr:link href="/0084/" title="Notebook: Three Easy Pieces" uri="https://kellenkanarios.com/0084/" display-uri="0084" type="local">OS adventure</fr:link>, you should see me (hopefully) get through memory virtualization.
However, I should definitely get to at least the TLB. Unlikely, I will continue to do all the exercises (because I spend more time writing them down than doing them). I might do one or two of the projects, but they are quite intimidating TBD.</html:li></html:ol>
Check back in next week to see if I am productive! Also TBD if in the future I will put research-related stuff in this review.
</html:p>
</fr:mainmatter></fr:tree>
</fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
