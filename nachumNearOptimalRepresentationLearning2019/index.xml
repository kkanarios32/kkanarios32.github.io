<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors>
      <fr:author>Ofir Nachum</fr:author>
      <fr:author>Shixiang Gu</fr:author>
      <fr:author>Honglak Lee</fr:author>
      <fr:author>Sergey Levine</fr:author>
    </fr:authors>
    <fr:date>
      <fr:year>2019</fr:year>
      <fr:month>1</fr:month>
    </fr:date>
    <fr:uri>https://kellenkanarios.com/nachumNearOptimalRepresentationLearning2019/</fr:uri>
    <fr:display-uri>nachumNearOptimalRepresentationLearning2019</fr:display-uri>
    <fr:route>/nachumNearOptimalRepresentationLearning2019/</fr:route>
    <fr:title text="Near-Optimal Representation Learning for Hierarchical Reinforcement Learning">Near-Optimal Representation Learning for Hierarchical Reinforcement Learning</fr:title>
    <fr:taxon>Reference</fr:taxon>
    <fr:meta name="external">https://arxiv.org/abs/1810.01257</fr:meta>
    <fr:meta name="bibtex"><![CDATA[@misc{nachumNearOptimalRepresentationLearning2019,
 title = {Near-{{Optimal Representation Learning}} for {{Hierarchical Reinforcement Learning}}},
 author = {Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
 year = {2019},
 urldate = {2024-11-07},
 number = {arXiv:1810.01257},
 publisher = {arXiv},
 file = {/home/kellen/Downloads/pdfs/storage/SIK848RC/Nachum et al. - 2019 - Near-Optimal Representation Learning for Hierarchical Reinforcement Learning.pdf},
 keywords = {Computer Science - Artificial Intelligence},
 langid = {english},
 archiveprefix = {arXiv},
 abstract = {We study the problem of representation learning in goal-conditioned hierarchical reinforcement learning. In such hierarchical structures, a higher-level controller solves tasks by iteratively communicating goals which a lower-level policy is trained to reach. Accordingly, the choice of representation -- the mapping of observation space to goal space -- is crucial. To study this problem, we develop a notion of sub-optimality of a representation, defined in terms of expected reward of the optimal hierarchical policy using this representation. We derive expressions which bound the sub-optimality and show how these expressions can be translated to representation learning objectives which may be optimized in practice. Results on a number of difficult continuous-control tasks show that our approach to representation learning yields qualitatively better representations as well as quantitatively better hierarchical policies, compared to existing methods (see videos at https://sites.google.com/view/representation-hrl).},
 primaryclass = {cs},
 eprint = {1810.01257},
 month = {January}
}]]></fr:meta>
  </fr:frontmatter>
  <fr:mainmatter />
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
