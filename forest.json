[{"title":"Flow Matching Loss","uri":"LRL4","taxon":"Definition","tags":["public"],"route":"/LRL4/","metas":{}},{"title":"FM Gradient Equivalence","uri":"DZ1D","taxon":"Theorem","tags":["public"],"route":"/DZ1D/","metas":{}},{"title":"Marginal Generation","uri":"93R8","taxon":"Theorem","tags":["public"],"route":"/93R8/","metas":{}},{"title":"Marginal Vector Field","uri":"373T","taxon":"Definition","tags":["public"],"route":"/373T/","metas":{}},{"title":"Conditional Vector Field","uri":"8XAJ","taxon":"Definition","tags":["public"],"route":"/8XAJ/","metas":{}},{"title":"Absolutely Continuous","uri":"HEXF","taxon":"Definition","tags":["public","public"],"route":"/HEXF/","metas":{}},{"title":"Continuity Equation","uri":"EFN0","taxon":"Definition","tags":["public","todo"],"route":"/EFN0/","metas":{}},{"title":"https://kellenkanarios.com/QIFY/","uri":"QIFY","taxon":"Definition","tags":["public","public"],"route":"/QIFY/","metas":{}},{"title":"AlphaCraftax","uri":"EE7A","taxon":null,"tags":["public","project"],"route":"/EE7A/","metas":{"author":"True"}},{"title":"Contrastive RL + Deepseek R1 Talk","uri":"CRLR1","taxon":null,"tags":["public","group","talk"],"route":"/CRLR1/","metas":{"date":"false","slides":"https://kellenkanarios.com/bafkrmietzsrc4u2kxu6vzdty2i7xvfe734uapzyesmuk62vbvhlbvfzabu.pdf"}},{"title":"RLHF Talk","uri":"RLHF","taxon":null,"tags":["public","group","talk"],"route":"/RLHF/","metas":{"date":"false","slides":"https://kellenkanarios.com/bafkrmid63jfs3kuhekwcujc7vdgvbbphyyd7kg4dmajlvp2xf7vqecz33i.pdf"}},{"title":"Contrastive Motion Planning","uri":"DERC","taxon":null,"tags":["public","project"],"route":"/DERC/","metas":{"author":"True"}},{"title":"Optimization on the Riemmanian Manifold","uri":"DERB","taxon":null,"tags":["public"],"route":"/DERB/","metas":{}},{"title":"Newton and Quasi-Newton Method","uri":"DERA","taxon":null,"tags":["public"],"route":"/DERA/","metas":{}},{"title":"How function properties affect convergence","uri":"DER9","taxon":null,"tags":["public"],"route":"/DER9/","metas":{}},{"title":"Line Search","uri":"DER8","taxon":null,"tags":["public"],"route":"/DER8/","metas":{}},{"title":"Accelerated Gradient Descent","uri":"DER7","taxon":null,"tags":["public"],"route":"/DER7/","metas":{}},{"title":"Convergence of Gradient Descent","uri":"DER6","taxon":null,"tags":["public"],"route":"/DER6/","metas":{}},{"title":"Rate of Convergence","uri":"DER5","taxon":null,"tags":["public"],"route":"/DER5/","metas":{}},{"title":"Constrained Optimality","uri":"DER4","taxon":null,"tags":["public"],"route":"/DER4/","metas":{}},{"title":"Optimality Conditions","uri":"DER3","taxon":null,"tags":["public"],"route":"/DER3/","metas":{}},{"title":"Taylor Expansion and Lipschitz Functions","uri":"DER2","taxon":null,"tags":["public"],"route":"/DER2/","metas":{}},{"title":"Basic Matrix Analysis","uri":"DER1","taxon":null,"tags":["public"],"route":"/DER1/","metas":{}},{"title":"Operations that preserve convexity","uri":"DER0","taxon":null,"tags":["public"],"route":"/DER0/","metas":{}},{"title":"https://kellenkanarios.com/DEQZ/","uri":"DEQZ","taxon":null,"tags":["public"],"route":"/DEQZ/","metas":{}},{"title":"https://kellenkanarios.com/DEQY/","uri":"DEQY","taxon":null,"tags":["public"],"route":"/DEQY/","metas":{}},{"title":"https://kellenkanarios.com/DEQX/","uri":"DEQX","taxon":null,"tags":["public"],"route":"/DEQX/","metas":{}},{"title":"https://kellenkanarios.com/DEQW/","uri":"DEQW","taxon":null,"tags":["public"],"route":"/DEQW/","metas":{}},{"title":"Low Precision Data Types","uri":"DEQV","taxon":null,"tags":["public"],"route":"/DEQV/","metas":{}},{"title":"Course outline","uri":"DEQT","taxon":null,"tags":["public"],"route":"/DEQT/","metas":{}},{"title":"https://kellenkanarios.com/0Q9H/","uri":"0Q9H","taxon":null,"tags":["public"],"route":"/0Q9H/","metas":{}},{"title":"https://kellenkanarios.com/008J/","uri":"008J","taxon":null,"tags":["public"],"route":"/008J/","metas":{}},{"title":"Generation via Continuity Equation","uri":"008I","taxon":"Theorem","tags":["public"],"route":"/008I/","metas":{}},{"title":"https://kellenkanarios.com/008H/","uri":"008H","taxon":"Definition","tags":["public"],"route":"/008H/","metas":{}},{"title":"https://kellenkanarios.com/008G/","uri":"008G","taxon":"Definition","tags":["public"],"route":"/008G/","metas":{}},{"title":"Time-dependent vector field","uri":"008C","taxon":"Definition","tags":["public"],"route":"/008C/","metas":{}},{"title":"Probablity density path","uri":"008B","taxon":"Definition","tags":["public"],"route":"/008B/","metas":{}},{"title":"Flow","uri":"008D","taxon":"Definition","tags":["public"],"route":"/008D/","metas":{}},{"title":"Reparametrization Trick","uri":"0089","taxon":null,"tags":["public"],"route":"/0089/","metas":{}},{"title":"Expectation Maximization","uri":"0088","taxon":null,"tags":["public"],"route":"/0088/","metas":{}},{"title":"Tokenization","uri":"0087","taxon":null,"tags":["public"],"route":"/0087/","metas":{}},{"title":"CS336 Lecture 1","uri":"0086","taxon":null,"tags":["public"],"route":"/0086/","metas":{}},{"title":"Notebook: Stanford CS336","uri":"0085","taxon":null,"tags":["public","note","top"],"route":"/0085/","metas":{}},{"title":"Notebook: Three Easy Pieces","uri":"0084","taxon":null,"tags":["public","note","top"],"route":"/0084/","metas":{}},{"title":"TPE Process Interlude","uri":"007Y","taxon":null,"tags":["public"],"route":"/007Y/","metas":{}},{"title":"LLMs","uri":"003W","taxon":null,"tags":["public","project","top"],"route":"/003W/","metas":{}},{"title":"Latent Variable","uri":"0083","taxon":"Definition","tags":["public"],"route":"/0083/","metas":{}},{"title":"Evidence Lower Bound","uri":"0082","taxon":null,"tags":["public"],"route":"/0082/","metas":{}},{"title":"TPE Processes","uri":"007V","taxon":null,"tags":["public"],"route":"/007V/","metas":{}},{"title":"Weeknotes","uri":"007S","taxon":null,"tags":["public","top"],"route":"/007S/","metas":{}},{"title":"Constrained MDPs?","uri":"007P","taxon":null,"tags":["public"],"route":"/007P/","metas":{}},{"title":"RL as Probablistic Inference","uri":"007O","taxon":null,"tags":["public"],"route":"/007O/","metas":{}},{"title":"https://kellenkanarios.com/007J/","uri":"007J","taxon":null,"tags":["public"],"route":"/007J/","metas":{}},{"title":"https://kellenkanarios.com/007K/","uri":"007K","taxon":null,"tags":["public"],"route":"/007K/","metas":{}},{"title":"Marginalia","uri":"007L","taxon":null,"tags":["public"],"route":"/007L/","metas":{}},{"title":"Upcoming Blogs","uri":"007M","taxon":null,"tags":["public","blog","upcoming"],"route":"/007M/","metas":{}},{"title":"Upcoming papers of the week","uri":"007N","taxon":null,"tags":["public"],"route":"/007N/","metas":{}},{"title":"General agents need world models","uri":"richensGeneralAgentsNeed2025","taxon":"Reference","tags":[],"route":"/richensGeneralAgentsNeed2025/","metas":{"doi":"10.48550/arXiv.2506.01622","external":"https://arxiv.org/abs/2506.01622","bibtex":"@misc{richensGeneralAgentsNeed2025,\n title = {General Agents Need World Models},\n author = {Richens, Jonathan and Abel, David and Bellot, Alexis and Everitt, Tom},\n year = {2025},\n doi = {10.48550/arXiv.2506.01622},\n urldate = {2025-06-05},\n number = {arXiv:2506.01622},\n publisher = {arXiv},\n file = {/home/kellen/Downloads/pdfs/storage/XJACDMMA/Richens et al. - 2025 - General agents need world models.pdf;/home/kellen/Downloads/pdfs/storage/9PQHSPK2/2506.html},\n keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics,Statistics - Machine Learning},\n archiveprefix = {arXiv},\n abstract = {Are world models a necessary ingredient for flexible, goal-directed behaviour, or is model-free learning sufficient? We provide a formal answer to this question, showing that any agent capable of generalizing to multi-step goal-directed tasks must have learned a predictive model of its environment. We show that this model can be extracted from the agent's policy, and that increasing the agents performance or the complexity of the goals it can achieve requires learning increasingly accurate world models. This has a number of consequences: from developing safe and general agents, to bounding agent capabilities in complex environments, and providing new algorithms for eliciting world models from agents.},\n primaryclass = {cs},\n eprint = {2506.01622},\n month = {June}\n}"}},{"title":"https://kellenkanarios.com/007F/","uri":"007F","taxon":"Theorem","tags":["public"],"route":"/007F/","metas":{}},{"title":"Differential Entropy","uri":"007C","taxon":"Definition","tags":["public"],"route":"/007C/","metas":{}},{"title":"Discrete Approximation of Differential Entropy","uri":"007G","taxon":"Definition","tags":["public"],"route":"/007G/","metas":{}},{"title":"Information dimension","uri":"007H","taxon":"Definition","tags":["public"],"route":"/007H/","metas":{}},{"title":"Multivariate Normal Distribution","uri":"007I","taxon":"Definition","tags":["public"],"route":"/007I/","metas":{}},{"title":"Typical Set for Continuous Random Variables","uri":"007E","taxon":"Definition","tags":["public","8.11"],"route":"/007E/","metas":{}},{"title":"Volume of set","uri":"007D","taxon":"Definition","tags":["public"],"route":"/007D/","metas":{}},{"title":"Retraction","uri":"0076","taxon":"Definition","tags":["public"],"route":"/0076/","metas":{}},{"title":"Riemannian Gradient","uri":"0077","taxon":"Definition","tags":["public"],"route":"/0077/","metas":{}},{"title":"Riemannian Gradient Descent","uri":"007B","taxon":"Definition","tags":["public"],"route":"/007B/","metas":{}},{"title":"Riemannian Hessian","uri":"007A","taxon":"Definition","tags":["public"],"route":"/007A/","metas":{}},{"title":"Riemannian Manifold","uri":"0072","taxon":"Definition","tags":["public"],"route":"/0072/","metas":{}},{"title":"Riemannian Metric","uri":"0079","taxon":"Definition","tags":["public"],"route":"/0079/","metas":{}},{"title":"Riemmanian Metric","uri":"0078","taxon":"Claim","tags":["public"],"route":"/0078/","metas":{}},{"title":"Smooth Manifold","uri":"0073","taxon":"Definition","tags":["public"],"route":"/0073/","metas":{}},{"title":"Tangent Bundle","uri":"0074","taxon":"Definition","tags":["public"],"route":"/0074/","metas":{}},{"title":"Tangent Space","uri":"0075","taxon":"Definition","tags":["public"],"route":"/0075/","metas":{}},{"title":"Encoder","uri":"0071","taxon":"Definition","tags":["public"],"route":"/0071/","metas":{}},{"title":"General definition of channel","uri":"0070","taxon":"Definition","tags":["public"],"route":"/0070/","metas":{}},{"title":"Coming Soon!!!","uri":"006Z","taxon":null,"tags":["public"],"route":"/006Z/","metas":{}},{"title":"Achievable rates","uri":"006U","taxon":"Definition","tags":["public"],"route":"/006U/","metas":{}},{"title":"Channel capacity","uri":"006V","taxon":"Definition","tags":["public"],"route":"/006V/","metas":{}},{"title":"Channel coding problem","uri":"006S","taxon":"Definition","tags":["public"],"route":"/006S/","metas":{}},{"title":"Discrete memoryless channel","uri":"006T","taxon":"Definition","tags":["public"],"route":"/006T/","metas":{}},{"title":"Information channel capacity","uri":"006W","taxon":"Definition","tags":["public"],"route":"/006W/","metas":{}},{"title":"Shannon's coding theorem","uri":"006X","taxon":"Theorem","tags":["public"],"route":"/006X/","metas":{}},{"title":"Symmetric Channels","uri":"006Y","taxon":"Definition","tags":["public"],"route":"/006Y/","metas":{}},{"title":"A Dynamic Duo: Tree Search + RL","uri":"006Q","taxon":null,"tags":["public"],"route":"/006Q/","metas":{}},{"title":"Alpha-Zero","uri":"006R","taxon":null,"tags":["public"],"route":"/006R/","metas":{}},{"title":"https://kellenkanarios.com/006O/","uri":"006O","taxon":"Theorem","tags":["public"],"route":"/006O/","metas":{}},{"title":"https://kellenkanarios.com/006M/","uri":"006M","taxon":"Proposition","tags":["public"],"route":"/006M/","metas":{}},{"title":"https://kellenkanarios.com/006L/","uri":"006L","taxon":"Theorem","tags":["public"],"route":"/006L/","metas":{}},{"title":"Fixed rate universal code","uri":"006K","taxon":"Definition","tags":["public"],"route":"/006K/","metas":{}},{"title":"Lempel-Ziv Algorithm","uri":"006P","taxon":null,"tags":["public"],"route":"/006P/","metas":{}},{"title":"Minimax Redundancy","uri":"006N","taxon":"Definition","tags":["public"],"route":"/006N/","metas":{}},{"title":"Optimal Bayesian Error Exponent","uri":"006I","taxon":"Definition","tags":["public"],"route":"/006I/","metas":{}},{"title":"Optimal Bayesian Error Exponent","uri":"006J","taxon":"Theorem","tags":["public"],"route":"/006J/","metas":{}},{"title":"Optimal Bayesian Test","uri":"006F","taxon":"Proposition","tags":["public"],"route":"/006F/","metas":{}},{"title":"Optimal Error Exponent in NP setting","uri":"006G","taxon":"Definition","tags":["public"],"route":"/006G/","metas":{}},{"title":"Stein's Lemma","uri":"006H","taxon":"Theorem","tags":["public"],"route":"/006H/","metas":{}},{"title":"https://kellenkanarios.com/0065/","uri":"0065","taxon":"Lemma","tags":["public"],"route":"/0065/","metas":{}},{"title":"https://kellenkanarios.com/0063/","uri":"0063","taxon":"Proposition","tags":["public"],"route":"/0063/","metas":{}},{"title":"https://kellenkanarios.com/0062/","uri":"0062","taxon":"Proposition","tags":["public"],"route":"/0062/","metas":{}},{"title":"https://kellenkanarios.com/005V/","uri":"005V","taxon":null,"tags":["public"],"route":"/005V/","metas":{}},{"title":"https://kellenkanarios.com/0064/","uri":"0064","taxon":"Theorem","tags":["public"],"route":"/0064/","metas":{}},{"title":"Bayesian Framework","uri":"006D","taxon":"Definition","tags":["public"],"route":"/006D/","metas":{}},{"title":"Huffman Code","uri":"005Z","taxon":null,"tags":["public"],"route":"/005Z/","metas":{}},{"title":"Huffman Code","uri":"005W","taxon":"Definition","tags":["public"],"route":"/005W/","metas":{}},{"title":"Hypothesis error","uri":"006B","taxon":"Definition","tags":["public"],"route":"/006B/","metas":{}},{"title":"Hypothesis test","uri":"006A","taxon":"Definition","tags":["public"],"route":"/006A/","metas":{}},{"title":"Hypothesis testing problem","uri":"0069","taxon":"Definition","tags":["public"],"route":"/0069/","metas":{}},{"title":"Minimax Optimal","uri":"006E","taxon":"Definition","tags":["public"],"route":"/006E/","metas":{}},{"title":"Neyman-Pearson Framework","uri":"006C","taxon":"Definition","tags":["public"],"route":"/006C/","metas":{}},{"title":"Optimal NP Test","uri":"0068","taxon":"Theorem","tags":["public"],"route":"/0068/","metas":{}},{"title":"Optimality of Huffman Code","uri":"0060","taxon":"Theorem","tags":["public"],"route":"/0060/","metas":{}},{"title":"Sanov's Theorem","uri":"0067","taxon":"Theorem","tags":["public"],"route":"/0067/","metas":{}},{"title":"Set of all types","uri":"005Y","taxon":"Definition","tags":["public"],"route":"/005Y/","metas":{}},{"title":"The probability of a type class","uri":"0066","taxon":"Theorem","tags":["public"],"route":"/0066/","metas":{}},{"title":"Type classes","uri":"0061","taxon":"Definition","tags":["public"],"route":"/0061/","metas":{}},{"title":"type or empirical distribution","uri":"005X","taxon":"Definition","tags":["public"],"route":"/005X/","metas":{}},{"title":"Singularity of a code","uri":"005U","taxon":"Definition","tags":["public"],"route":"/005U/","metas":{}},{"title":"https://kellenkanarios.com/005K/","uri":"005K","taxon":"Definition","tags":["public"],"route":"/005K/","metas":{}},{"title":"https://kellenkanarios.com/005J/","uri":"005J","taxon":null,"tags":["public"],"route":"/005J/","metas":{}},{"title":"https://kellenkanarios.com/005L/","uri":"005L","taxon":"Definition","tags":["public"],"route":"/005L/","metas":{}},{"title":"https://kellenkanarios.com/005S/","uri":"005S","taxon":"Theorem","tags":["public"],"route":"/005S/","metas":{}},{"title":"https://kellenkanarios.com/005I/","uri":"005I","taxon":"Theorem","tags":["public"],"route":"/005I/","metas":{}},{"title":"Extensions and Unique Decodability","uri":"005M","taxon":"Definition","tags":["public"],"route":"/005M/","metas":{}},{"title":"Kraft's inequality","uri":"005O","taxon":"Theorem","tags":["public"],"route":"/005O/","metas":{}},{"title":"Shannon Fano Elias Code","uri":"005T","taxon":null,"tags":["public","2025-03-23"],"route":"/005T/","metas":{}},{"title":"Variable minimum rate","uri":"005R","taxon":"Definition","tags":["public"],"route":"/005R/","metas":{}},{"title":"Variable rate achievability","uri":"005Q","taxon":"Definition","tags":["public"],"route":"/005Q/","metas":{}},{"title":"Variable rate code","uri":"005P","taxon":"Definition","tags":["public"],"route":"/005P/","metas":{}},{"title":"instantaneous / prefix-free code","uri":"005N","taxon":"Definition","tags":["public"],"route":"/005N/","metas":{}},{"title":"https://kellenkanarios.com/005H/","uri":"005H","taxon":null,"tags":["public"],"route":"/005H/","metas":{}},{"title":"Papers of a Week","uri":"005G","taxon":null,"tags":["public"],"route":"/005G/","metas":{}},{"title":"Rebuilding My (Neo)Vim Config From Scratch","uri":"005F","taxon":null,"tags":["public"],"route":"/005F/","metas":{}},{"title":"Optimization from a Deep Learning Perspective","uri":"005D","taxon":null,"tags":["public","blog","upcoming"],"route":"/005D/","metas":{}},{"title":"Achievability","uri":"005A","taxon":"Definition","tags":["public"],"route":"/005A/","metas":{}},{"title":"Coding system","uri":"0059","taxon":"Definition","tags":["public"],"route":"/0059/","metas":{}},{"title":"Entropy as MRSC","uri":"005C","taxon":"Theorem","tags":["public"],"route":"/005C/","metas":{}},{"title":"Minimum rate of source coding","uri":"005B","taxon":"Definition","tags":["public"],"route":"/005B/","metas":{}},{"title":"https://kellenkanarios.com/0058/","uri":"0058","taxon":"Theorem","tags":["public"],"route":"/0058/","metas":{}},{"title":"https://kellenkanarios.com/0052/","uri":"0052","taxon":"Corollary","tags":["public"],"route":"/0052/","metas":{}},{"title":"AEP Theorem","uri":"0054","taxon":"Theorem","tags":["public"],"route":"/0054/","metas":{}},{"title":"Continuous Mapping Theorem","uri":"0053","taxon":"Theorem","tags":["public"],"route":"/0053/","metas":{}},{"title":"Decomposition Theorem","uri":"0057","taxon":"Theorem","tags":["public"],"route":"/0057/","metas":{}},{"title":"High probability sets","uri":"0056","taxon":"Corollary","tags":["public"],"route":"/0056/","metas":{}},{"title":"Weak Law of Large Numbers","uri":"0051","taxon":"Theorem","tags":["public"],"route":"/0051/","metas":{}},{"title":"\\epsilon -typical set","uri":"0055","taxon":null,"tags":["public"],"route":"/0055/","metas":{}},{"title":"Data Processing Inequality","uri":"004Z","taxon":"Theorem","tags":["public"],"route":"/004Z/","metas":{}},{"title":"Fano's Inequality","uri":"0050","taxon":null,"tags":["public"],"route":"/0050/","metas":{}},{"title":"Maximum Aposteriori Estimator","uri":"004Y","taxon":"Theorem","tags":["public"],"route":"/004Y/","metas":{}},{"title":"A Note on Advantage Estimation","uri":"004X","taxon":null,"tags":["public","blog","upcoming"],"route":"/004X/","metas":{}},{"title":"Armijo Condition","uri":"004R","taxon":"Definition","tags":["public"],"route":"/004R/","metas":{}},{"title":"Convergence of GD with backtracking","uri":"004T","taxon":"Theorem","tags":["public"],"route":"/004T/","metas":{}},{"title":"Convergence of accelerated GD","uri":"004P","taxon":"Theorem","tags":["public"],"route":"/004P/","metas":{}},{"title":"Exact Linesearch","uri":"004Q","taxon":"Definition","tags":["public"],"route":"/004Q/","metas":{}},{"title":"Linear convergence for strong convexity","uri":"004U","taxon":"Theorem","tags":["public"],"route":"/004U/","metas":{}},{"title":"Nesterov's Method","uri":"004O","taxon":null,"tags":["public"],"route":"/004O/","metas":{}},{"title":"Newton's Method","uri":"004V","taxon":null,"tags":["public"],"route":"/004V/","metas":{}},{"title":"Quasi-Newton's Method","uri":"004W","taxon":null,"tags":["public"],"route":"/004W/","metas":{}},{"title":"Sublinear convergence of GD","uri":"004M","taxon":"Theorem","tags":["public"],"route":"/004M/","metas":{}},{"title":"Suboptimality of Gradient Descent","uri":"004N","taxon":"Theorem","tags":["public"],"route":"/004N/","metas":{}},{"title":"Sufficient Value","uri":"004L","taxon":"Lemma","tags":["public"],"route":"/004L/","metas":{}},{"title":"Wolfe condition","uri":"004S","taxon":"Definition","tags":["public"],"route":"/004S/","metas":{}},{"title":"Word Embeddings","uri":"004J","taxon":null,"tags":["public"],"route":"/004J/","metas":{}},{"title":"forester2html","uri":"004K","taxon":null,"tags":["public"],"route":"/004K/","metas":{}},{"title":"The Computer in Computer Science","uri":"004H","taxon":null,"tags":["public","project","top","systems","systems"],"route":"/004H/","metas":{}},{"title":"Virtual Memory","uri":"004I","taxon":null,"tags":["public"],"route":"/004I/","metas":{}},{"title":"Convex Function","uri":"004D","taxon":"Definition","tags":["public"],"route":"/004D/","metas":{}},{"title":"Convex set","uri":"004C","taxon":"Definition","tags":["public"],"route":"/004C/","metas":{}},{"title":"DeepSeek-V3 Technical Report","uri":"deepseek-aiDeepSeekV3TechnicalReport2025","taxon":"Reference","tags":[],"route":"/deepseek-aiDeepSeekV3TechnicalReport2025/","metas":{"doi":"10.48550/arXiv.2412.19437","external":"https://arxiv.org/abs/2412.19437","bibtex":"@misc{deepseek-aiDeepSeekV3TechnicalReport2025,\n title = {{{DeepSeek-V3 Technical Report}}},\n author = {{DeepSeek-AI} and Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Guo, Daya and Yang, Dejian and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Zhang, Haowei and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Li, Hui and Qu, Hui and Cai, J. L. and Liang, Jian and Guo, Jianzhong and Ni, Jiaqi and Li, Jiashi and Wang, Jiawei and Chen, Jin and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Song, Junxiao and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Xu, Lei and Xia, Leyi and Zhao, Liang and Wang, Litong and Zhang, Liyue and Li, Meng and Wang, Miaojun and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Mingming and Tian, Ning and Huang, Panpan and Wang, Peiyi and Zhang, Peng and Wang, Qiancheng and Zhu, Qihao and Chen, Qinyu and Du, Qiushi and Chen, R. J. and Jin, R. L. and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Xu, Runxin and Zhang, Ruoyu and Chen, Ruyi and Li, S. S. and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Wu, Shaoqing and Ye, Shengfeng and Ye, Shengfeng and Ma, Shirong and Wang, Shiyu and Zhou, Shuang and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Wang, T. and Yun, Tao and Pei, Tian and Sun, Tianyu and Xiao, W. L. and Zeng, Wangding and Zhao, Wanjia and An, Wei and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Li, X. Q. and Jin, Xiangyue and Wang, Xianzu and Bi, Xiao and Liu, Xiaodong and Wang, Xiaohan and Shen, Xiaojin and Chen, Xiaokang and Zhang, Xiaokang and Chen, Xiaosha and Nie, Xiaotao and Sun, Xiaowen and Wang, Xiaoxiang and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yu, Xingkai and Song, Xinnan and Shan, Xinxia and Zhou, Xinyi and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhu, Y. X. and Zhang, Yang and Xu, Yanhong and Xu, Yanhong and Huang, Yanping and Li, Yao and Zhao, Yao and Sun, Yaofeng and Li, Yaohui and Wang, Yaohui and Yu, Yi and Zheng, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Tang, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Wu, Yu and Ou, Yuan and Zhu, Yuchen and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Zha, Yukun and Xiong, Yunfan and Ma, Yunxian and Yan, Yuting and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Wu, Z. F. and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Huang, Zhen and Zhang, Zhen and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Gou, Zhibin and Ma, Zhicheng and Yan, Zhigang and Shao, Zhihong and Xu, Zhipeng and Wu, Zhiyu and Zhang, Zhongyu and Li, Zhuoshu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Gao, Ziyi and Pan, Zizheng},\n year = {2025},\n doi = {10.48550/arXiv.2412.19437},\n urldate = {2025-06-27},\n number = {arXiv:2412.19437},\n publisher = {arXiv},\n file = {/home/kellen/Downloads/pdfs/storage/6FVL6N8T/DeepSeek-AI et al. - 2025 - DeepSeek-V3 Technical Report.pdf},\n keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},\n langid = {english},\n archiveprefix = {arXiv},\n abstract = {We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks. The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.},\n primaryclass = {cs},\n eprint = {2412.19437},\n month = {February}\n}"}},{"title":"Gibb's inequality","uri":"004E","taxon":"Theorem","tags":["public"],"route":"/004E/","metas":{}},{"title":"Log-Sum Inequality","uri":"004F","taxon":null,"tags":["public"],"route":"/004F/","metas":{}},{"title":"Notebook: Information Theory","uri":"004B","taxon":null,"tags":["public","note","top"],"route":"/004B/","metas":{}},{"title":"Self-Attention","uri":"004G","taxon":null,"tags":["public","llms"],"route":"/004G/","metas":{}},{"title":"https://kellenkanarios.com/0048/","uri":"0048","taxon":"Definition","tags":["public"],"route":"/0048/","metas":{}},{"title":"https://kellenkanarios.com/0049/","uri":"0049","taxon":"Lemma","tags":["public"],"route":"/0049/","metas":{}},{"title":"https://kellenkanarios.com/0041/","uri":"0041","taxon":"Theorem","tags":["public"],"route":"/0041/","metas":{}},{"title":"Chapman-Kolmogorov Equation","uri":"0042","taxon":"Definition","tags":["public"],"route":"/0042/","metas":{}},{"title":"Communicates","uri":"0046","taxon":"Definition","tags":["public"],"route":"/0046/","metas":{}},{"title":"Group Relative Policy Optimization","uri":"003X","taxon":null,"tags":["public","rl","llms"],"route":"/003X/","metas":{}},{"title":"Markov Chain","uri":"0040","taxon":"Definition","tags":["public"],"route":"/0040/","metas":{}},{"title":"Notebook: Stochastic Processes","uri":"003Z","taxon":null,"tags":["public","note","prob","top"],"route":"/003Z/","metas":{}},{"title":"Old Talks","uri":"004A","taxon":null,"tags":["public"],"route":"/004A/","metas":{}},{"title":"Stopping time","uri":"0043","taxon":"Definition","tags":["public"],"route":"/0043/","metas":{}},{"title":"Strong Markov Property","uri":"0044","taxon":"Theorem","tags":["public"],"route":"/0044/","metas":{}},{"title":"The History and Evolution of Policy Gradient Algorithms","uri":"003Y","taxon":null,"tags":["public","blog","upcoming","rl"],"route":"/003Y/","metas":{}},{"title":"Transient and recurrent states","uri":"0045","taxon":"Definition","tags":["public"],"route":"/0045/","metas":{}},{"title":"Transitivity of communcation","uri":"0047","taxon":"Lemma","tags":["public"],"route":"/0047/","metas":{}},{"title":"Chain Rule of Mutual Info","uri":"003V","taxon":"Theorem","tags":["public","infot"],"route":"/003V/","metas":{}},{"title":"Threads on the hardware level","uri":"003U","taxon":null,"tags":["public"],"route":"/003U/","metas":{}},{"title":"Deepseek v1 through R1: RL is back!","uri":"003D","taxon":null,"tags":["public","blog","llms","upcoming"],"route":"/003D/","metas":{}},{"title":"First-order approximation","uri":"003N","taxon":"Theorem","tags":["public"],"route":"/003N/","metas":{}},{"title":"First-order convergence","uri":"003R","taxon":"Definition","tags":["public"],"route":"/003R/","metas":{}},{"title":"Lipschitz Continous","uri":"003J","taxon":"Definition","tags":["public"],"route":"/003J/","metas":{}},{"title":"Matrix Operator Norm","uri":"003G","taxon":"Definition","tags":["public"],"route":"/003G/","metas":{}},{"title":"Mean Value Theorem I","uri":"003L","taxon":"Theorem","tags":["public"],"route":"/003L/","metas":{}},{"title":"Mean Value Theorem II","uri":"003M","taxon":"Theorem","tags":["public"],"route":"/003M/","metas":{}},{"title":"Q-convergence","uri":"003Q","taxon":"Definition","tags":["public"],"route":"/003Q/","metas":{}},{"title":"R-convergence","uri":"003S","taxon":"Definition","tags":["public"],"route":"/003S/","metas":{}},{"title":"Schatten p-norm","uri":"003I","taxon":"Definition","tags":["public"],"route":"/003I/","metas":{}},{"title":"Second-order approximation","uri":"003O","taxon":"Theorem","tags":["public"],"route":"/003O/","metas":{}},{"title":"Smooth Function","uri":"003K","taxon":"Definition","tags":["public"],"route":"/003K/","metas":{}},{"title":"Stationary point","uri":"003P","taxon":"Definition","tags":["public"],"route":"/003P/","metas":{}},{"title":"Unitary Invariant Matrix Norm","uri":"003H","taxon":"Definition","tags":["public"],"route":"/003H/","metas":{}},{"title":"Best rank-r approximation","uri":"003C","taxon":"Theorem","tags":["public"],"route":"/003C/","metas":{}},{"title":"First-order condition","uri":"0034","taxon":"Theorem","tags":["public","optimization"],"route":"/0034/","metas":{}},{"title":"Notebook: Optimization Theory","uri":"0033","taxon":null,"tags":["public","note","top"],"route":"/0033/","metas":{}},{"title":"Positive (semi)definiteness","uri":"003A","taxon":"Definition","tags":["public"],"route":"/003A/","metas":{}},{"title":"Second-order condition","uri":"0035","taxon":"Theorem","tags":["public","optimization"],"route":"/0035/","metas":{}},{"title":"Singular Value Decomposition","uri":"003B","taxon":"Fact","tags":["public","optimization"],"route":"/003B/","metas":{}},{"title":"Smooth Problem","uri":"0037","taxon":"Definition","tags":["public","optimization"],"route":"/0037/","metas":{}},{"title":"Strong convexity","uri":"0036","taxon":"Definition","tags":["public","optimization"],"route":"/0036/","metas":{}},{"title":"Subdifferential","uri":"0039","taxon":"Definition","tags":["public","optimization"],"route":"/0039/","metas":{}},{"title":"Subgradient","uri":"0038","taxon":"Definition","tags":["public","optimization"],"route":"/0038/","metas":{}},{"title":"https://kellenkanarios.com/002Z/","uri":"002Z","taxon":null,"tags":["public"],"route":"/002Z/","metas":{}},{"title":"Soft Actor Critic","uri":"002T","taxon":null,"tags":["public","rl"],"route":"/002T/","metas":{}},{"title":"Unreasonable Effectiveness of Eligibility Traces","uri":"002U","taxon":null,"tags":["public","blog","draft"],"route":"/002U/","metas":{}},{"title":"https://kellenkanarios.com/002M/","uri":"002M","taxon":"Theorem","tags":["public"],"route":"/002M/","metas":{}},{"title":"Banach Space","uri":"002Q","taxon":null,"tags":["public"],"route":"/002Q/","metas":{}},{"title":"Hoeffding's Inequality","uri":"002N","taxon":"Theorem","tags":["public"],"route":"/002N/","metas":{}},{"title":"Holder's Inequality","uri":"002R","taxon":null,"tags":["public"],"route":"/002R/","metas":{}},{"title":"Linear MDP","uri":"002S","taxon":"Definition","tags":["public"],"route":"/002S/","metas":{}},{"title":"Sub-Gaussian Norm","uri":"002P","taxon":"Definition","tags":["public"],"route":"/002P/","metas":{}},{"title":"Sub-Gaussian Random Variables","uri":"002L","taxon":"Definition","tags":["public"],"route":"/002L/","metas":{}},{"title":"khinchin's Inequality","uri":"002O","taxon":"Corollary","tags":["public"],"route":"/002O/","metas":{}},{"title":"DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning","uri":"deepseek-aiDeepSeekR1IncentivizingReasoning2025","taxon":"Reference","tags":[],"route":"/deepseek-aiDeepSeekR1IncentivizingReasoning2025/","metas":{"doi":"10.48550/arXiv.2501.12948","external":"https://arxiv.org/abs/2501.12948","bibtex":"@misc{deepseek-aiDeepSeekR1IncentivizingReasoning2025,\n title = {{{DeepSeek-R1}}: {{Incentivizing Reasoning Capability}} in {{LLMs}} via {{Reinforcement Learning}}},\n author = {{DeepSeek-AI} and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},\n year = {2025},\n doi = {10.48550/arXiv.2501.12948},\n urldate = {2025-06-27},\n number = {arXiv:2501.12948},\n publisher = {arXiv},\n file = {/home/kellen/Downloads/pdfs/storage/WM8KGXDY/DeepSeek-AI et al. - 2025 - DeepSeek-R1 Incentivizing Reasoning Capability in.pdf},\n keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},\n langid = {english},\n archiveprefix = {arXiv},\n abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeekR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},\n primaryclass = {cs},\n eprint = {2501.12948},\n month = {January},\n shorttitle = {{{DeepSeek-R1}}}\n}"}},{"title":"Chebyshev's Inequality","uri":"002F","taxon":"Theorem","tags":["public"],"route":"/002F/","metas":{}},{"title":"Holder's Inequality","uri":"002H","taxon":"Theorem","tags":["public"],"route":"/002H/","metas":{}},{"title":"Jensen's Inequality","uri":"002G","taxon":"Theorem","tags":["public"],"route":"/002G/","metas":{}},{"title":"Markov's Inequality","uri":"002E","taxon":"Theorem","tags":["public"],"route":"/002E/","metas":{}},{"title":"https://kellenkanarios.com/0024/","uri":"0024","taxon":"Theorem","tags":["public"],"route":"/0024/","metas":{}},{"title":"https://kellenkanarios.com/002C/","uri":"002C","taxon":"Theorem","tags":["public"],"route":"/002C/","metas":{}},{"title":"https://kellenkanarios.com/002D/","uri":"002D","taxon":null,"tags":["public"],"route":"/002D/","metas":{}},{"title":"Almost Sure Convergence","uri":"001Z","taxon":null,"tags":["public"],"route":"/001Z/","metas":{}},{"title":"Convergence in Probability","uri":"0020","taxon":null,"tags":["public"],"route":"/0020/","metas":{}},{"title":"Dense Subset","uri":"001Y","taxon":"Definition","tags":["public","math"],"route":"/001Y/","metas":{}},{"title":"Distribution","uri":"0023","taxon":"Definition","tags":["public"],"route":"/0023/","metas":{}},{"title":"Expected Value","uri":"0029","taxon":"Definition","tags":["public"],"route":"/0029/","metas":{}},{"title":"Finite Sequence Measurability","uri":"0022","taxon":"Theorem","tags":["public"],"route":"/0022/","metas":{}},{"title":"Independence of Random Variable","uri":"0021","taxon":"Definition","tags":["public"],"route":"/0021/","metas":{}},{"title":"Simple Random Variable","uri":"001W","taxon":"Definition","tags":["public"],"route":"/001W/","metas":{}},{"title":"Uniformly Bounded","uri":"002B","taxon":"Definition","tags":["public"],"route":"/002B/","metas":{}},{"title":"\\sigma -field of RV","uri":"001X","taxon":"Definition","tags":["public"],"route":"/001X/","metas":{}},{"title":"kth Moment","uri":"002A","taxon":"Definition","tags":["public"],"route":"/002A/","metas":{}},{"title":"https://kellenkanarios.com/001S/","uri":"001S","taxon":"Definition","tags":["public"],"route":"/001S/","metas":{}},{"title":"https://kellenkanarios.com/001P/","uri":"001P","taxon":"Theorem","tags":["public"],"route":"/001P/","metas":{}},{"title":"Array Method","uri":"001R","taxon":"Theorem","tags":["public"],"route":"/001R/","metas":{}},{"title":"Borel-Cantelli One","uri":"001Q","taxon":"Theorem","tags":["public"],"route":"/001Q/","metas":{}},{"title":"Borel-Cantelli Two","uri":"001T","taxon":"Theorem","tags":["public"],"route":"/001T/","metas":{}},{"title":"Kolmogorov's Zero-one Law","uri":"001V","taxon":"Theorem","tags":["public"],"route":"/001V/","metas":{}},{"title":"Tail \\sigma -field","uri":"001U","taxon":"Definition","tags":["public"],"route":"/001U/","metas":{}},{"title":"Independence","uri":"001O","taxon":"Definition","tags":["public"],"route":"/001O/","metas":{}},{"title":"liminf of sets","uri":"001N","taxon":"Definition","tags":["public"],"route":"/001N/","metas":{}},{"title":"limsup of sets","uri":"001M","taxon":"Definition","tags":["public"],"route":"/001M/","metas":{}},{"title":"https://kellenkanarios.com/001K/","uri":"001K","taxon":"Theorem","tags":["public"],"route":"/001K/","metas":{}},{"title":"Chain Rule of Probability","uri":"001I","taxon":"Proposition","tags":["public"],"route":"/001I/","metas":{}},{"title":"Conditional Probability","uri":"001J","taxon":"Definition","tags":["public"],"route":"/001J/","metas":{}},{"title":"https://kellenkanarios.com/001A/","uri":"001A","taxon":"Lemma","tags":["public"],"route":"/001A/","metas":{}},{"title":"Axiom of Choice","uri":"001H","taxon":"Axiom","tags":["public"],"route":"/001H/","metas":{}},{"title":"Completeness of a measure","uri":"001F","taxon":"Definition","tags":["public","prog"],"route":"/001F/","metas":{}},{"title":"Dynkin's \\pi \\text {-}\\lambda ","uri":"001B","taxon":"Theorem","tags":["public"],"route":"/001B/","metas":{}},{"title":"Halmo's Monotone Class Theorem","uri":"001E","taxon":"Theorem","tags":["public"],"route":"/001E/","metas":{}},{"title":"Monotone Class","uri":"001D","taxon":"Definition","tags":["public"],"route":"/001D/","metas":{}},{"title":"Uniqueness of Extension","uri":"001C","taxon":"Theorem","tags":["public"],"route":"/001C/","metas":{}},{"title":"Vitali Sets","uri":"001G","taxon":"Example","tags":["public"],"route":"/001G/","metas":{}},{"title":"\\lambda -system","uri":"0019","taxon":"Definition","tags":["public"],"route":"/0019/","metas":{}},{"title":"\\pi -system","uri":"0018","taxon":"Definition","tags":["public"],"route":"/0018/","metas":{}},{"title":"https://kellenkanarios.com/0016/","uri":"0016","taxon":null,"tags":["public"],"route":"/0016/","metas":{}},{"title":"https://kellenkanarios.com/0017/","uri":"0017","taxon":null,"tags":["public"],"route":"/0017/","metas":{}},{"title":"GPU Training Stuff","uri":"0014","taxon":null,"tags":["public"],"route":"/0014/","metas":{}},{"title":"Notebooks","uri":"0015","taxon":null,"tags":["public"],"route":"/0015/","metas":{}},{"title":"Mean Square Value Error","uri":"0013","taxon":"Definition","tags":["public"],"route":"/0013/","metas":{}},{"title":"Notebook: Reinforcement learning: An introduction","uri":"0012","taxon":null,"tags":["public","rl","note","top"],"route":"/0012/","metas":{}},{"title":"Action Value Function","uri":"0011","taxon":"Definition","tags":["public"],"route":"/0011/","metas":{}},{"title":"Markov Decision Process","uri":"000Z","taxon":"Definition","tags":["public"],"route":"/000Z/","metas":{}},{"title":"Markov Decision Processes","uri":"000Y","taxon":null,"tags":["public"],"route":"/000Y/","metas":{}},{"title":"Value Function","uri":"0010","taxon":"Definition","tags":["public"],"route":"/0010/","metas":{}},{"title":"Kullback-Liebler Divergence","uri":"000W","taxon":"Definition","tags":["public"],"route":"/000W/","metas":{}},{"title":"Mutual Information","uri":"000V","taxon":"Definition","tags":["public"],"route":"/000V/","metas":{}},{"title":"Outer Measure","uri":"000T","taxon":"Definition","tags":["public"],"route":"/000T/","metas":{}},{"title":"P^*-measurable","uri":"000U","taxon":"Definition","tags":["public"],"route":"/000U/","metas":{}},{"title":"https://kellenkanarios.com/000R/","uri":"000R","taxon":"Theorem","tags":["public"],"route":"/000R/","metas":{}},{"title":"Additivity of Intervals","uri":"000S","taxon":"Theorem","tags":["public"],"route":"/000S/","metas":{}},{"title":"Probability Measure","uri":"000P","taxon":"Definition","tags":["public"],"route":"/000P/","metas":{}},{"title":"Probability Space","uri":"000Q","taxon":"Definition","tags":["public"],"route":"/000Q/","metas":{}},{"title":"\\sigma -field","uri":"000O","taxon":"Definition","tags":["public"],"route":"/000O/","metas":{}},{"title":"Problem 1.1 Billingsley","uri":"000N","taxon":"Solution","tags":["public"],"route":"/000N/","metas":{}},{"title":"Weak Law of Large Numbers (Dyadic)","uri":"000M","taxon":"Theorem","tags":["public"],"route":"/000M/","metas":{}},{"title":"Dyadic Intervals","uri":"000L","taxon":"Example","tags":["public"],"route":"/000L/","metas":{}},{"title":"On-policy Prediction with Approximation","uri":"000G","taxon":null,"tags":["public"],"route":"/000G/","metas":{}},{"title":"https://kellenkanarios.com/000D/","uri":"000D","taxon":null,"tags":["public"],"route":"/000D/","metas":{}},{"title":"Consistent estimator","uri":"000F","taxon":"Definition","tags":["public"],"route":"/000F/","metas":{}},{"title":"InfoNCE","uri":"000B","taxon":"Definition","tags":["public","loss"],"route":"/000B/","metas":{}},{"title":"Maximize Mutual info","uri":"000C","taxon":"Theorem","tags":["public"],"route":"/000C/","metas":{}},{"title":"NCE loss","uri":"000E","taxon":"Definition","tags":["public","loss"],"route":"/000E/","metas":{}},{"title":"TVM: What makes a compiler an ML compiler?","uri":"000A","taxon":null,"tags":["public","blog","draft"],"route":"/000A/","metas":{}},{"title":"Contrastive Learning","uri":"0009","taxon":null,"tags":["public"],"route":"/0009/","metas":{}},{"title":"Notes on Probability and measure","uri":"0007","taxon":null,"tags":["public","prob","note"],"route":"/0007/","metas":{}},{"title":"/dev/null","uri":"0004","taxon":null,"tags":["public"],"route":"/0004/","metas":{}},{"title":"Blog","uri":"0002","taxon":null,"tags":["public","top"],"route":"/0002/","metas":{}},{"title":"Contrastive Reinforcement Learning","uri":"0005","taxon":null,"tags":["public"],"route":"/0005/","metas":{}},{"title":"What's up with all these fancy optimizers?","uri":"0006","taxon":null,"tags":["public","blog","draft"],"route":"/0006/","metas":{}},{"title":"Meta Learning for Continual Reinforcement Learning: An Investigation","uri":"kanariosThesis2024","taxon":"Reference","tags":["research"],"route":"/kanariosThesis2024/","metas":{"slides":"https://kellenkanarios.com/bafkrmiatsfeu2hkk6jy2ixdsm5vufq4w7jybkq56oq4mrmphmx4fiy7cde.pdf","paper":"https://kellenkanarios.com/bafkrmiadhsesgrg4ie67bgm7bwzhrku3fucpwivzpaunkdg5jr7xulk4vu.pdf","image":"https://kellenkanarios.com/bafkrmiaalur6esfpgl25lftysiofd2dqqshovigrlisa7vzyhrzwgqikpq.png"}},{"title":"Cost Aware Best Arm Identification","uri":"kanariosCostAwareBest2024","taxon":"Reference","tags":["research"],"route":"/kanariosCostAwareBest2024/","metas":{"doi":"10.48550/arXiv.2402.16710","slides":"https://kellenkanarios.com/bafkrmigprjuluerfvbmngg4hy6ncbqejf2v5vxkq4praqkav736rsf3yse.pdf","poster":"https://kellenkanarios.com/bafkrmiejtaxo762x4ipx5fgdgzhef5jbv6zwnr2shrxtts57fggd7e3ad4.pdf","image":"https://kellenkanarios.com/bafkrmia2u3dd5angpqkfj5n75kr2r2mcbn2cuvoeihacpr32hyyoi6d5vq.png","bibtex":"@misc{kanariosCostAwareBest2024,\n title = {Cost {{Aware Best Arm Identification}}},\n author = {Kanarios, Kellen and Zhang, Qining and Ying, Lei},\n year = {2024},\n doi = {10.48550/arXiv.2402.16710},\n urldate = {2025-06-27},\n number = {arXiv:2402.16710},\n publisher = {arXiv},\n file = {/home/kellen/Downloads/pdfs/storage/KCBBU7NQ/Kanarios et al. - 2024 - Cost Aware Best Arm Identification.pdf},\n keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},\n langid = {english},\n archiveprefix = {arXiv},\n abstract = {In this paper, we study a best arm identification problem with dual objects. In addition to the classic reward, each arm is associated with a cost distribution and the goal is to identify the largest reward arm using the minimum expected cost. We call it Cost Aware Best Arm Identification (CABAI), which captures the separation of testing and implementation phases in product development pipelines and models the objective shift between phases, i.e., cost for testing and reward for implementation. We first derive a theoretical lower bound for CABAI and propose an algorithm called CTAS to match it asymptotically. To reduce the computation of CTAS, we further propose a simple algorithm called Chernoff Overlap (CO), based on a square-root rule, which we prove is optimal in simplified two-armed models and generalizes well in numerical experiments. Our results show that (i) ignoring the heterogeneous action cost results in sub-optimality in practice, and (ii) simple algorithms can deliver near-optimal performance over a wide range of problems.},\n primaryclass = {cs},\n eprint = {2402.16710},\n month = {July}\n}"}},{"title":"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models","uri":"shaoDeepSeekMathPushingLimits2024","taxon":"Reference","tags":[],"route":"/shaoDeepSeekMathPushingLimits2024/","metas":{"doi":"10.48550/arXiv.2402.03300","external":"https://arxiv.org/abs/2402.03300","bibtex":"@misc{shaoDeepSeekMathPushingLimits2024,\n title = {{{DeepSeekMath}}: {{Pushing}} the {{Limits}} of {{Mathematical Reasoning}} in {{Open Language Models}}},\n author = {Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, Y. K. and Wu, Y. and Guo, Daya},\n year = {2024},\n doi = {10.48550/arXiv.2402.03300},\n urldate = {2025-06-27},\n number = {arXiv:2402.03300},\n publisher = {arXiv},\n file = {/home/kellen/Downloads/pdfs/storage/A4KAUF66/Shao et al. - 2024 - DeepSeekMath Pushing the Limits of Mathematical R.pdf},\n keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},\n langid = {english},\n archiveprefix = {arXiv},\n abstract = {Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature. In this paper, we introduce DeepSeekMath 7B, which continues pretraining DeepSeek-Coder-Base-v1.5 7B with 120B math-related tokens sourced from Common Crawl, together with natural language and code data. DeepSeekMath 7B has achieved an impressive score of 51.7\\% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4. Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9\\% on MATH. The mathematical reasoning capability of DeepSeekMath is attributed to two key factors: First, we harness the significant potential of publicly available web data through a meticulously engineered data selection pipeline. Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical reasoning abilities while concurrently optimizing the memory usage of PPO.},\n primaryclass = {cs},\n eprint = {2402.03300},\n month = {April},\n shorttitle = {{{DeepSeekMath}}}\n}"}},{"title":"Parallel Algebraic Multigrid for Higher Order PDEs","uri":"kanariosParallelAMG2023","taxon":"Reference","tags":["research"],"route":"/kanariosParallelAMG2023/","metas":{"slides":"https://kellenkanarios.com/bafkrmignmsxm4a4sps6664cfy2fipolzrsomzmdxnhhhdtvjzfprlppuee.pdf","poster":"https://kellenkanarios.com/bafkrmibialj6fqnbce2i5qc6jhx2c6qdcecudy5e4u5nrnghmxmvdjvnre.pptx","doi":"10.2172/2205732","image":"https://kellenkanarios.com/bafkrmibm4snnzyzdaqzlgk52d7fm2kno2dehv7nbd4jjmw3qxzsj3m2tkq.png"}},{"title":"Contrastive Learning as Goal-Conditioned Reinforcement Learning","uri":"eysenbachContrastiveLearningGoalConditioned2023","taxon":"Reference","tags":[],"route":"/eysenbachContrastiveLearningGoalConditioned2023/","metas":{"doi":"10.48550/arXiv.2206.07568","external":"https://arxiv.org/abs/2206.07568","bibtex":"@misc{eysenbachContrastiveLearningGoalConditioned2023,\n title = {Contrastive {{Learning}} as {{Goal-Conditioned Reinforcement Learning}}},\n author = {Eysenbach, Benjamin and Zhang, Tianjun and Salakhutdinov, Ruslan and Levine, Sergey},\n year = {2023},\n doi = {10.48550/arXiv.2206.07568},\n urldate = {2024-09-06},\n number = {arXiv:2206.07568},\n publisher = {arXiv},\n file = {/home/kellen/Downloads/pdfs/storage/WVQKIMN4/Eysenbach et al. - 2023 - Contrastive Learning as Goal-Conditioned Reinforcement Learning.pdf},\n keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},\n archiveprefix = {arXiv},\n abstract = {In reinforcement learning (RL), it is easier to solve a task if given a good representation. While deep RL should automatically acquire such good representations, prior work often finds that learning representations in an end-to-end fashion is unstable and instead equip RL algorithms with additional representation learning parts (e.g., auxiliary losses, data augmentation). How can we design RL algorithms that directly acquire good representations? In this paper, instead of adding representation learning parts to an existing RL algorithm, we show (contrastive) representation learning methods can be cast as RL algorithms in their own right. To do this, we build upon prior work and apply contrastive representation learning to action-labeled trajectories, in such a way that the (inner product of) learned representations exactly corresponds to a goal-conditioned value function. We use this idea to reinterpret a prior RL method as performing contrastive learning, and then use the idea to propose a much simpler method that achieves similar performance. Across a range of goal-conditioned RL tasks, we demonstrate that contrastive RL methods achieve higher success rates than prior non-contrastive methods, including in the offline RL setting. We also show that contrastive RL outperforms prior methods on image-based tasks, without using data augmentation or auxiliary objectives.},\n primaryclass = {cs},\n eprint = {2206.07568},\n month = {February}\n}"}},{"title":"Flow Matching for Generative Modeling","uri":"lipmanFlowMatchingGenerative2023","taxon":"Reference","tags":[],"route":"/lipmanFlowMatchingGenerative2023/","metas":{"doi":"10.48550/arXiv.2210.02747","external":"https://arxiv.org/abs/2210.02747","bibtex":"@misc{lipmanFlowMatchingGenerative2023,\n title = {Flow {{Matching}} for {{Generative Modeling}}},\n author = {Lipman, Yaron and Chen, Ricky T. Q. and {Ben-Hamu}, Heli and Nickel, Maximilian and Le, Matt},\n year = {2023},\n doi = {10.48550/arXiv.2210.02747},\n urldate = {2025-06-20},\n number = {arXiv:2210.02747},\n publisher = {arXiv},\n file = {/home/kellen/Downloads/pdfs/storage/WMMQDW4B/Lipman et al. - 2023 - Flow Matching for Generative Modeling.pdf;/home/kellen/Downloads/pdfs/storage/R693NNL4/2210.html},\n keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},\n archiveprefix = {arXiv},\n abstract = {We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples -- which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers.},\n primaryclass = {cs},\n eprint = {2210.02747},\n month = {February}\n}"}},{"title":"Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model","uri":"schrittwieserMasteringAtariGo2020","taxon":"Reference","tags":[],"route":"/schrittwieserMasteringAtariGo2020/","metas":{"doi":"10.1038/s41586-020-03051-4","external":"https://arxiv.org/abs/1911.08265","bibtex":"@article{schrittwieserMasteringAtariGo2020,\n title = {Mastering {{Atari}}, {{Go}}, {{Chess}} and {{Shogi}} by {{Planning}} with a {{Learned Model}}},\n author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},\n year = {2020},\n doi = {10.1038/s41586-020-03051-4},\n urldate = {2025-03-31},\n journal = {Nature},\n volume = {588},\n number = {7839},\n pages = {604--609},\n file = {/home/kellen/Downloads/pdfs/storage/I7Y4VSFZ/Schrittwieser et al. - 2020 - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model.pdf},\n keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},\n langid = {english},\n archiveprefix = {arXiv},\n abstract = {Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess and Go, where a perfect simulator is available. However, in real-world problems the dynamics governing the environment are often complex and unknown. In this work we present the MuZero algorithm which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. MuZero learns a model that, when applied iteratively, predicts the quantities most directly relevant to planning: the reward, the action-selection policy, and the value function. When evaluated on 57 different Atari games - the canonical video game environment for testing AI techniques, in which model-based planning approaches have historically struggled - our new algorithm achieved a new state of the art. When evaluated on Go, chess and shogi, without any knowledge of the game rules, MuZero matched the superhuman performance of the AlphaZero algorithm that was supplied with the game rules.},\n issn = {0028-0836, 1476-4687},\n primaryclass = {cs},\n eprint = {1911.08265},\n month = {December}\n}"}},{"title":"Representation Learning with Contrastive Predictive Coding","uri":"oordRepresentationLearningContrastive2019","taxon":"Reference","tags":[],"route":"/oordRepresentationLearningContrastive2019/","metas":{"external":"https://arxiv.org/abs/1807.03748","bibtex":"@misc{oordRepresentationLearningContrastive2019,\n title = {Representation {{Learning}} with {{Contrastive Predictive Coding}}},\n author = {van den Oord, Aaron and Li, Yazhe and Vinyals, Oriol},\n year = {2019},\n urldate = {2024-11-21},\n number = {arXiv:1807.03748},\n publisher = {arXiv},\n file = {/home/kellen/Downloads/pdfs/storage/8ZBPFQEK/Oord et al. - 2019 - Representation Learning with Contrastive Predictive Coding.pdf;/home/kellen/Downloads/pdfs/storage/H9PLPKN6/Oord et al. - 2019 - Representation Learning with Contrastive Predictive Coding.pdf},\n keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},\n langid = {english},\n archiveprefix = {arXiv},\n abstract = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},\n primaryclass = {cs},\n eprint = {1807.03748},\n month = {January}\n}"}},{"title":"Reinforcement learning: An introduction","uri":"suttonReinforcementLearningIntroduction2018","taxon":"Reference","tags":[],"route":"/suttonReinforcementLearningIntroduction2018/","metas":{"bibtex":"@book{suttonReinforcementLearningIntroduction2018,\n title = {Reinforcement Learning: An Introduction},\n author = {Sutton, Richard S. and Barto, Andrew G.},\n year = {2018},\n isbn = {978-0-262-03924-6},\n edition = {Second edition},\n series = {Adaptive Computation and Machine Learning Series},\n publisher = {The MIT Press},\n address = {Cambridge, Massachusetts},\n file = {/home/kellen/Downloads/pdfs/storage/DY4UI6G7/Sutton and Barto - 2018 - Reinforcement learning an introduction.pdf},\n keywords = {Reinforcement learning},\n lccn = {Q325.6 .R45 2018},\n langid = {english},\n abstract = {\"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms.\"--},\n shorttitle = {Reinforcement Learning}\n}"}},{"title":"Proximal Policy Optimization Algorithms","uri":"schulmanProximalPolicyOptimization2017","taxon":"Reference","tags":[],"route":"/schulmanProximalPolicyOptimization2017/","metas":{"doi":"10.48550/arXiv.1707.06347","external":"https://arxiv.org/abs/1707.06347","bibtex":"@misc{schulmanProximalPolicyOptimization2017,\n title = {Proximal {{Policy Optimization Algorithms}}},\n author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},\n year = {2017},\n doi = {10.48550/arXiv.1707.06347},\n urldate = {2025-06-27},\n number = {arXiv:1707.06347},\n publisher = {arXiv},\n file = {/home/kellen/Downloads/pdfs/storage/UUPSNPZG/Schulman et al. - 2017 - Proximal Policy Optimization Algorithms.pdf},\n keywords = {Computer Science - Machine Learning},\n langid = {english},\n archiveprefix = {arXiv},\n abstract = {We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a ``surrogate'' objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.},\n primaryclass = {cs},\n eprint = {1707.06347},\n month = {August}\n}"}},{"title":"Noise-contrastive estimation: A new estimation principle for unnormalized statistical models","uri":"gutmannNoisecontrastiveEstimationNew2010","taxon":"Reference","tags":[],"route":"/gutmannNoisecontrastiveEstimationNew2010/","metas":{"bibtex":"@inproceedings{gutmannNoisecontrastiveEstimationNew2010,\n title = {Noise-Contrastive Estimation: {{A}} New Estimation Principle for Unnormalized Statistical Models},\n author = {Gutmann, Michael and Hyv{\\\"a}rinen, Aapo},\n year = {2010},\n urldate = {2025-01-24},\n booktitle = {Proceedings of the {{Thirteenth International Conference}} on {{Artificial Intelligence}} and {{Statistics}}},\n pages = {297--304},\n publisher = {{JMLR Workshop and Conference Proceedings}},\n file = {/home/kellenkanarios/Downloads/Papers/Papers/Contrastive RL/Gutmann_Hyvärinen_2010_Noise-contrastive estimation.pdf},\n langid = {english},\n abstract = {We present a new estimation principle for parameterized statistical models. The idea is to perform nonlinear logistic regression to discriminate between the observed data and some artificially generated noise, using the model log-density function in the regression nonlinearity.  We show that this leads to a consistent (convergent) estimator of the parameters, and analyze the asymptotic variance.  In particular, the method is shown to directly work for unnormalized models, i.e. models where the density function does not integrate to one. The normalization constant can be estimated just like any other parameter. For a tractable ICA model, we compare the method with other estimation methods that can be used to learn unnormalized models, including score matching, contrastive divergence, and maximum-likelihood where the normalization constant is estimated with importance sampling. Simulations show that noise-contrastive estimation offers the best trade-off between computational and statistical efficiency. The method is then applied to the modeling of natural images: We show that the method can successfully estimate a large-scale two-layer model and a Markov random field.},\n issn = {1938-7228},\n month = {March},\n shorttitle = {Noise-Contrastive Estimation}\n}"}},{"title":"Probability and measure","uri":"billingsleyProbabilityMeasure1995","taxon":"Reference","tags":[],"route":"/billingsleyProbabilityMeasure1995/","metas":{"bibtex":"@book{billingsleyProbabilityMeasure1995,\n title = {Probability and Measure},\n author = {Billingsley, Patrick},\n year = {1995},\n isbn = {978-0-471-00710-4},\n edition = {3. ed},\n series = {Wiley Series in Probability and Mathematical Statistics},\n publisher = {Wiley},\n address = {New York, NY},\n file = {/home/kellen/Downloads/pdfs/storage/JSCDN2UH/Billingsley - 1995 - Probability and measure.pdf},\n langid = {english}\n}"}},{"title":"https://kellenkanarios.com/005E/","uri":"005E","taxon":null,"tags":["public"],"route":"/005E/","metas":{}},{"title":"https://kellenkanarios.com/latex-preamble/","uri":"latex-preamble","taxon":null,"tags":["public"],"route":"/latex-preamble/","metas":{}},{"title":"https://kellenkanarios.com/007Q/","uri":"007Q","taxon":null,"tags":["public"],"route":"/007Q/","metas":{}},{"title":"Benjamin Eysenbach","uri":"beneysenbach","taxon":"Person","tags":["public"],"route":"/beneysenbach/","metas":{"external":"https://ben-eysenbach.github.io/","institution":"Princeton University","position":"Assistant Professor"}},{"title":"Cal Newport","uri":"calnewport","taxon":"Person","tags":["public"],"route":"/calnewport/","metas":{"external":"https://calnewport.com/","institution":"University of Georgetown","position":"Professor"}},{"title":"Cambridge Computer Laboratory","uri":"camcl","taxon":"Department","tags":["public"],"route":"/camcl/","metas":{"external":"https://www.cst.cam.ac.uk/"}},{"title":"Deliberate-Practice","uri":"007U","taxon":null,"tags":["public"],"route":"/007U/","metas":{}},{"title":"ELEMENTS OF INFORMATION THEORY","uri":"coverELEMENTSINFORMATIONTHEORY","taxon":"Reference","tags":[],"route":"/coverELEMENTSINFORMATIONTHEORY/","metas":{"bibtex":"@article{coverELEMENTSINFORMATIONTHEORY,\n title = {{{ELEMENTS OF INFORMATION THEORY}}},\n author = {Cover, Thomas M and Thomas, Joy A},\n file = {/home/kellen/Downloads/pdfs/storage/C6AJGW5I/Cover and Thomas - ELEMENTS OF INFORMATION THEORY.pdf},\n langid = {english}\n}"}},{"title":"Entropy","uri":"0081","taxon":"Definition","tags":["public"],"route":"/0081/","metas":{}},{"title":"Flow Matching Definitions","uri":"D8LA","taxon":null,"tags":["public"],"route":"/D8LA/","metas":{}},{"title":"Generated probability paths","uri":"008E","taxon":"Definition","tags":["public"],"route":"/008E/","metas":{}},{"title":"Jon Sterling","uri":"jonmsterling","taxon":"Person","tags":["public"],"route":"/jonmsterling/","metas":{"external":"https://www.jonmsterling.com/index/","institution":"Cambridge Computer Laboratory","orcid":"0000-0002-0585-5564","position":"Associate Professor"}},{"title":"Kellen Kanarios","uri":"kellenkanarios","taxon":"Person","tags":["public"],"route":"/kellenkanarios/","metas":{"external":"https://kellenkanarios.github.io/","institution":"University of Michigan","position":"PhD Student"}},{"title":"Kellen Kanarios","uri":"index","taxon":null,"tags":["public","home"],"route":"/index/","metas":{"author":"false"}},{"title":"LLMs Lecture 1 (Overview, tokenization)","uri":"007X","taxon":null,"tags":["public"],"route":"/007X/","metas":{}},{"title":"Lei Ying","uri":"leiying","taxon":"Person","tags":["public"],"route":"/leiying/","metas":{"external":"https://leiying.engin.umich.edu/","institution":"University of Michigan","position":"Professor"}},{"title":"Math 395 Notes","uri":"analysis","taxon":"Reference","tags":["public","texnote"],"route":"/analysis/","metas":{"paper":"https://kellenkanarios.com/bafkrmidkpdxz7j2mgqwwynwmv2ra5rzw45hem6sjgnhtjmgfxoakm2ys64.pdf"}},{"title":"Math 494 Notes","uri":"algebra","taxon":"Reference","tags":["public","texnote"],"route":"/algebra/","metas":{"paper":"https://kellenkanarios.com/bafkrmidjjjqif75agkmvsmz2bz627dgif5ark52gsvbyfbpzfthjwamyrq.pdf"}},{"title":"Math 597 Notes","uri":"measure","taxon":"Reference","tags":["public","texnote"],"route":"/measure/","metas":{"paper":"https://kellenkanarios.com/bafkrmiecxju5az4ffp7waq3lzh5nmftn2jdbb5xehtg5c63dmn2nm3d5qe.pdf"}},{"title":"Math 602 Notes","uri":"functional","taxon":"Reference","tags":["public","texnote"],"route":"/functional/","metas":{"paper":"https://kellenkanarios.com/bafkrmicgvuccv3l6jiuvek7r7rt4ojemnnwbd2qc7jztuxtesfghqjnrpm.pdf"}},{"title":"Nan Jiang","uri":"nanjiang","taxon":"Person","tags":["public"],"route":"/nanjiang/","metas":{"external":"https://nanjiang.cs.illinois.edu/","institution":"University of Illinois Urbana-Champaign","position":"Professor"}},{"title":"Operating Systems: Three Easy Pieces","uri":"arpaci2018operating","taxon":"Reference","tags":[],"route":"/arpaci2018operating/","metas":{"external":"https://pages.cs.wisc.edu/~remzi/OSTEP/","bibtex":"@article{arpaci2018operating,\n  title={Operating systems: Three easy pieces},\n  author={Arpaci-Dusseau, Remzi H and Arpaci-Dusseau, Andrea C},\n  year={2018},\n  publisher={Arpaci-Dusseau Books, LLC Madison, WI, USA}\n}"}},{"title":"Princeton University","uri":"princeton","taxon":"Institute","tags":["public"],"route":"/princeton/","metas":{"external":"https://www.princeton.edu/"}},{"title":"Qining Zhang","uri":"qiningzhang","taxon":"Person","tags":["public"],"route":"/qiningzhang/","metas":{"external":"https://thumichzqn.github.io/","institution":"University of Michigan","position":"PhD Student"}},{"title":"Reinforcement Learning Conference","uri":"rlc","taxon":"Conference","tags":["public"],"route":"/rlc/","metas":{"external":"https://rl-conference.cc/"}},{"title":"Reinforcement Learning and Decision Making","uri":"rldm","taxon":"Conference","tags":["public"],"route":"/rldm/","metas":{"external":"https://rldm.org/"}},{"title":"Richard Sutton","uri":"richardsutton","taxon":"Person","tags":["public"],"route":"/richardsutton/","metas":{"external":"http://incompleteideas.net","institution":"University of Alberta","position":"Professor"}},{"title":"Sanjay Shakkottai","uri":"sanjayshakkottai","taxon":"Person","tags":["public"],"route":"/sanjayshakkottai/","metas":{"external":"https://www.ece.utexas.edu/people/faculty/sanjay-shakkottai","institution":"University of Texas","position":"Professor"}},{"title":"Stanford University","uri":"stanford","taxon":"Institute","tags":["public"],"route":"/stanford/","metas":{"external":"https://www.stanford.edu/"}},{"title":"The Orskin-Uhlenbeck Process","uri":"007W","taxon":null,"tags":["public"],"route":"/007W/","metas":{}},{"title":"University of Georgetown","uri":"georgetown","taxon":"Institute","tags":["public"],"route":"/georgetown/","metas":{"external":"https://www.georgetown.edu/"}},{"title":"University of Michigan","uri":"umich","taxon":"Institute","tags":["public"],"route":"/umich/","metas":{"external":"https://umich.edu/"}},{"title":"University of Texas","uri":"utaustin","taxon":"Institute","tags":["public"],"route":"/utaustin/","metas":{"external":"https://www.ece.utexas.edu/"}},{"title":"Weekly Review 2025-W26","uri":"2025-W26","taxon":null,"tags":[],"route":"/2025-W26/","metas":{}},{"title":"basic macros","uri":"base-macros","taxon":null,"tags":["public"],"route":"/base-macros/","metas":{}},{"title":"Kellen Kanarios › About this website","uri":"about","taxon":null,"tags":[],"route":"/about/","metas":{}},{"title":"Kellen Kanarios › News","uri":"rn","taxon":null,"tags":[],"route":"/rn/","metas":{}},{"title":"Kellen Kanarios › Research","uri":"pub","taxon":null,"tags":[],"route":"/pub/","metas":{}}]