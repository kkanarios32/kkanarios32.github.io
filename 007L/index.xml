<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors />
    <fr:date>
      <fr:year>2025</fr:year>
      <fr:month>6</fr:month>
      <fr:day>5</fr:day>
    </fr:date>
    <fr:uri>https://kkanarios32.github.io/007L/</fr:uri>
    <fr:display-uri>007L</fr:display-uri>
    <fr:route>/007L/</fr:route>
    <fr:title text="Marginalia">Marginalia</fr:title>
  </fr:frontmatter>
  <fr:mainmatter>
    <html:p>This is my short-form blog, where I will jot down (primarily) self-contained notes about things I find interesting or other random stuff in my life.</html:p>
  </fr:mainmatter>
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>
                <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kkanarios32.github.io/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
              </fr:author>
            </fr:authors>
            <fr:date>
              <fr:year>2024</fr:year>
              <fr:month>10</fr:month>
              <fr:day>29</fr:day>
            </fr:date>
            <fr:uri>https://kkanarios32.github.io/0002/</fr:uri>
            <fr:display-uri>0002</fr:display-uri>
            <fr:route>/0002/</fr:route>
            <fr:title text="Blog">Blog</fr:title>
          </fr:frontmatter>
          <fr:mainmatter>
            <html:p>This is my blog, in which I write about a variety of topics including computer science, mathematics, and more. For more short-form blogs, see the <fr:link href="/007L/" title="Marginalia" uri="https://kkanarios32.github.io/007L/" display-uri="007L" type="local">marginalia</fr:link>. See <fr:link href="/007M/" title="Upcoming Blogs" uri="https://kkanarios32.github.io/007M/" display-uri="007M" type="local">upcoming blogs</fr:link> and feel free to request! This blog also has a corresponding <fr:link href="/0002/atom.xml" type="external">Atom feed</fr:link></html:p>
            <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
              <fr:frontmatter>
                <fr:authors>
                  <fr:author>
                    <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kkanarios32.github.io/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
                  </fr:author>
                </fr:authors>
                <fr:date>
                  <fr:year>2024</fr:year>
                  <fr:month>10</fr:month>
                  <fr:day>29</fr:day>
                </fr:date>
                <fr:uri>https://kkanarios32.github.io/0005/</fr:uri>
                <fr:display-uri>0005</fr:display-uri>
                <fr:route>/0005/</fr:route>
                <fr:title text="Contrastive Reinforcement Learning">Contrastive Reinforcement Learning</fr:title>
              </fr:frontmatter>
              <fr:mainmatter>
                <html:p>In this blog post, we aim to demistify <fr:link href="https://kkanarios32.github.io/gcrl/" type="external"><html:em>Contrastive Reinforcement Learning</html:em></fr:link>. This term often gets thrown around in the dark inner circles of the reinforcement learning community. However, for those that are not familiar with contrastive learning, what does contrastive even mean? For those that are, how can reinforcement learning be contrastive? Throughout this blog post, we will answer these questions and many more.</html:p>
                <fr:tree show-metadata="false">
                  <fr:frontmatter>
                    <fr:authors />
                    <fr:date>
                      <fr:year>2024</fr:year>
                      <fr:month>10</fr:month>
                      <fr:day>31</fr:day>
                    </fr:date>
                    <fr:uri>https://kkanarios32.github.io/0009/</fr:uri>
                    <fr:display-uri>0009</fr:display-uri>
                    <fr:route>/0009/</fr:route>
                    <fr:title text="Contrastive Learning">Contrastive Learning</fr:title>
                  </fr:frontmatter>
                  <fr:mainmatter><html:p>Prior to understanding contrastive reinforcement learning, it is important to have an at least rudimentary understanding of contrastive learning. Historically, contrastive learning has been used to learn representations. The fundamental idea behind contrastive learning is to encourage the representations of similar outputs to be similar in representation space.</html:p><html:p><html:strong>Supervised setting:</html:strong> For now, assume we are in the supervised setting (we have access to lables). Suppose that we are learning a representation in <fr:tex display="inline"><![CDATA[\mathbb {R}^d]]></fr:tex>. Our model is a classifier on dogs and cats. If we have two dogs <fr:tex display="inline"><![CDATA[y_1]]></fr:tex> and <fr:tex display="inline"><![CDATA[y_2]]></fr:tex> then we want the learned representation map <fr:tex display="block"><![CDATA[\phi : \{\text {dogs}, \text {cats}\} \to  \mathbb {R}^d]]></fr:tex> to be such that <fr:tex display="inline"><![CDATA[\phi (y_1)]]></fr:tex> and <fr:tex display="inline"><![CDATA[\phi (y_2)]]></fr:tex> are "close" in <fr:tex display="inline"><![CDATA[\mathbb {R}^d]]></fr:tex>. Now the notion of "close" is to be determined by the user. An example could be to minimize the inner product between their representation maps i.e. we could learn a feature map parametrized by <fr:tex display="inline"><![CDATA[\theta ]]></fr:tex> with the following objective <fr:tex display="block"><![CDATA[\max _{\theta }\ \langle  \phi _{\theta }(y_1), \phi _{\theta }(y_2) \rangle .]]></fr:tex> Similarly, we want dissimilar outputs to be far apart in representation space. If <fr:tex display="inline"><![CDATA[y_3]]></fr:tex> is a cat, then we can introduce a regularization to encourage this i.e.
<fr:tex display="block"><![CDATA[\max _{\theta }\ \langle  \phi _{\theta }(y_1), \phi _{\theta }(y_2) \rangle  - \sum _{i \in  \{1, 2\}} \langle  \phi _{\theta }(y_i), \phi _{\theta }(y_3) \rangle .]]></fr:tex></html:p><html:p><html:strong>Unsupervised setting:</html:strong> Now suppose that we get rid of labels and are just given <fr:tex display="inline"><![CDATA[n]]></fr:tex> dog samples <fr:tex display="inline"><![CDATA[\mathcal {D}]]></fr:tex> from some distribution <fr:tex display="inline"><![CDATA[p_{\mathcal {D}}]]></fr:tex>. We now want to be able to learn <fr:tex display="inline"><![CDATA[p_{\theta }]]></fr:tex> to somehow estimate this distribution. An approach is to learn to distinguish the sample dogs given from random noise. To do so, we generate <fr:tex display="inline"><![CDATA[n]]></fr:tex> random images <fr:tex display="inline"><![CDATA[\mathcal {R}]]></fr:tex> according to some distribution <fr:tex display="inline"><![CDATA[p_{\mathcal {R}}]]></fr:tex>. We can now return to the supervised learning setting, where we treat <fr:tex display="inline"><![CDATA[\mathcal {D}]]></fr:tex> and <fr:tex display="inline"><![CDATA[\mathcal {R}]]></fr:tex> as two classes. If we recall standard supervised learning practice, given a sample <fr:tex display="inline"><![CDATA[x]]></fr:tex>, we then want to find <fr:tex display="block"><![CDATA[p(\mathcal {D} \mid  x) = 1 - p(\mathcal {R} \mid  X).]]></fr:tex> 
As an explicit example, we will use logistic regression. Namely, we will model <fr:tex display="inline"><![CDATA[p(x) = p(\mathcal {D} \mid  x)]]></fr:tex> as <fr:tex display="block"><![CDATA[p_{\theta }(x) = \frac {1}{1 + e^{-G_{\theta }(x)}}.]]></fr:tex> However, <fr:tex display="inline"><![CDATA[p_{\theta }(x)]]></fr:tex> is estimating <fr:tex display="inline"><![CDATA[p(\mathcal {D} \mid  x)]]></fr:tex>, where we care about <fr:tex display="inline"><![CDATA[p(x \mid  \mathcal {D})]]></fr:tex>. To estimate the correct quantity, we need to leverage our knowledge of the noise distribution. Recall that if <fr:tex display="inline"><![CDATA[p_{\theta }(x) = p(\mathcal {D} \mid  x)]]></fr:tex> then <fr:tex display="inline"><![CDATA[G_{\theta }(x) = \log  \frac {p(x \mid  \mathcal {D})}{p(x \mid  \mathcal {R})}]]></fr:tex>. Since we generated the samples from <fr:tex display="inline"><![CDATA[\mathcal {R}]]></fr:tex>, we have the explicit distribution i.e. <fr:tex display="inline"><![CDATA[p(x \mid  \mathcal {R}) = p_{\mathcal {R}}(x)]]></fr:tex>. Therefore, we can restrict <fr:tex display="inline"><![CDATA[G_{\theta }]]></fr:tex> to explicitly learn <fr:tex display="inline"><![CDATA[p(x \mid  \mathcal {D})]]></fr:tex> by considering <fr:tex display="block"><![CDATA[G_{\theta }(x) = \log  p_{\theta }(x \mid  \mathcal {D}) - \log  p_{\mathcal {R}}(x),]]></fr:tex> considering the cross entropy loss we get the <fr:link href="https://kkanarios32.github.io/nce/" type="external">NCE loss</fr:link></html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kkanarios32.github.io/000E/</fr:uri><fr:display-uri>000E</fr:display-uri><fr:route>/000E/</fr:route><fr:title text="NCE loss">NCE loss</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The <html:em><fr:link href="https://kkanarios32.github.io/nce/" type="external">NCE</fr:link></html:em> loss aims to minimize the following objective <fr:tex display="block"><![CDATA[\mathcal {L}_{N} = - \sum _{t} \log  \left [h(x_t; \theta )\right ] + \log \left [1 - h(y_t; \theta )\right ],]]></fr:tex> where <fr:tex display="inline"><![CDATA[x_t]]></fr:tex> are samples from the data distribution and <fr:tex display="inline"><![CDATA[y_t]]></fr:tex> are randomly generated samples and <fr:tex display="block"><![CDATA[\begin {array}{r c l}{{h({\bf  u};\theta )}}&{{=}}&{{\frac {1}{1+\exp \left [-G({\bf  u};\theta )\right ]},}}\\ {{G({\bf  u};\theta )}}&{{=}}&{{\ln  p_{m}({\bf  u};\theta )-\ln  p_{n}({\bf  u}).}}\end {array}]]></fr:tex></html:p></fr:mainmatter></fr:tree><html:p>In <fr:link href="/gutmann2012/" title="Noise-contrastive Estimation" uri="https://kkanarios32.github.io/gutmann2012/" display-uri="gutmann2012" type="local">Noise-contrastive Estimation</fr:link>, they show under mild conditions that the estimator <fr:tex display="inline"><![CDATA[p_{\theta }(x \mid  D) \to  p_{\mathcal {D}}(x)]]></fr:tex> in probability as the number of samples in the loss goes to infinity. Equivalently, the estimator is <fr:link href="/000F/" title="Consistent estimator" uri="https://kkanarios32.github.io/000F/" display-uri="000F" type="local">consistent</fr:link>.</html:p><html:p><html:strong>Time series:</html:strong> Before we get to contrastive RL, it is a natural question to wonder how does this apply to temporal sequences? Concretely, we want to make predictions about the future given the current "context". However, we want to do so in an unsupervised way, meaning we are only given trajectories not a notion of what it means for a trajectory to be good. Naively, one can try to do this in a supervised manner. For a <fr:tex display="inline"><![CDATA[k]]></fr:tex> step prediction, this would just be your model predicting what will happen in <fr:tex display="inline"><![CDATA[k]]></fr:tex> steps then seeing if it matches what occured <fr:tex display="inline"><![CDATA[k]]></fr:tex> steps in the future in the sample trajectory. However, if your sample space <fr:tex display="inline"><![CDATA[\mathcal {X}]]></fr:tex> is very high-dimensional, modeling this relationship can require an exorbinant amount of trajectories.</html:p><html:p>Fast forwarding to contrastive RL, current work is primarily considered with a particular contrastive objective.</html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kkanarios32.github.io/000B/</fr:uri><fr:display-uri>000B</fr:display-uri><fr:route>/000B/</fr:route><fr:title text="InfoNCE">InfoNCE</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p>The <html:em><fr:link href="/vandenOord2018/" title="Contrastive Predictive Decoding" uri="https://kkanarios32.github.io/vandenOord2018/" display-uri="vandenOord2018" type="local">InfoNCE</fr:link></html:em> loss aims to minimize the following information-theoretic objective <fr:tex display="block"><![CDATA[\mathcal {L}_{N} = - \mathbb {E}_{\mathcal {X}} \left [\log  \frac {f_k(x_{t + k}, c_t)}{\sum _{x_j \in  \mathcal {X}} f_k(x_j, c_t)}\right ]]]></fr:tex></html:p></fr:mainmatter></fr:tree><html:p>Now we need to unpack this very ominous loss. To start, what are <fr:tex display="inline"><![CDATA[x_k]]></fr:tex> and <fr:tex display="inline"><![CDATA[c_t]]></fr:tex>?</html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:uri>https://kkanarios32.github.io/000C/</fr:uri><fr:display-uri>000C</fr:display-uri><fr:route>/000C/</fr:route><fr:title text="Maximize Mutual info">Maximize Mutual info</fr:title><fr:taxon>Theorem</fr:taxon></fr:frontmatter><fr:mainmatter><html:p><fr:tex display="inline"><![CDATA[\mathcal {L}_N]]></fr:tex> from <fr:link href="/vandenOord2018/" title="Contrastive Predictive Decoding" uri="https://kkanarios32.github.io/vandenOord2018/" display-uri="vandenOord2018" type="local">Contrastive Predictive Decoding</fr:link> maximizes a lower bound on the <fr:link href="/000V/" title="Mutual Information" uri="https://kkanarios32.github.io/000V/" display-uri="000V" type="local">Mutual Information</fr:link> between <fr:tex display="inline"><![CDATA[x_{t + k}]]></fr:tex> and <fr:tex display="inline"><![CDATA[c_t]]></fr:tex>.</html:p>
   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>11</fr:month><fr:day>4</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>All we must do is plug <fr:tex display="inline"><![CDATA[\frac {p(x \mid  c)}{p(x)}]]></fr:tex> back into the objective.
  <fr:tex display="block"><![CDATA[\begin {align*}
    \mathcal {L}_{\mathbb {N}}^{\text {opt}}&=-\,\mathbb {E}\log \left [\frac {\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}}{\frac {p(x_{t+k}|c_{t})}{p(x_{t+k})}+\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}}\right ] \\
    &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}\sum _{x_{j}\in  X_{\text {neg}}}\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\
    &\approx \mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k}|c_{t})}(N-1)\,\mathbb {E}\,\frac {p(x_{j}|c_{t})}{p(x_{j})}\right ] \\
    &=\mathbb {E}\log \left [1+\frac {p(x_{t+k})}{p(x_{t+k} \mid  c_t)}N\right ] \\
    &\geq  \mathbb {E} \log  \left [\frac {p(x_{t + k})}{p(x_{t + k} \mid  c_t)}N \right ] \\
    &= - I(x_{t + k}, c_t) + \log  N
 \end {align*}
  ]]></fr:tex>
</fr:mainmatter></fr:tree>
 

</fr:mainmatter></fr:tree><fr:tex display="block"><![CDATA[
\operatorname *{max}_{f(u,v)}\mathbb {E}_{(u,v^{+})\sim  p(u,v)}\left [\log \sigma (\underbrace {f(u,{\green  v^{+}})}_{\phi (u)^{T}\psi ({\green  v^{+}})})+\log (1-\sigma (\underbrace {f(u,{\red  v^{-}})}_{\phi (u)^{T}\psi ({\red  v^{-}})}))\right ]
]]></fr:tex><fr:tex display="block"><![CDATA[
\begin {align*}
&\operatorname *{max}_{f}\mathbb {E}_{(s,a)\sim  p(s,a),s_{f}^{-}\sim  p(s_{f})}\left [\mathcal {L}(s,a,s_{f}^{+},s_{f}^{-})\right ] \\
\end {align*}
]]></fr:tex><fr:tex display="block"><![CDATA[
\mathcal {L}_1(\theta ) = \log \sigma (f_{\theta }(s_1,a_1,{\color {green} s_{8}})) + \log (1-\sigma (f_{\theta }(s_1,a_1, {\color {red} s_3})))
]]></fr:tex><fr:tex display="block"><![CDATA[
\begin {align*}
\widehat {\mathcal {L}}(\theta ) &= \frac {1}{n} \sum _{i = 1}^{n} \mathcal {L}_i \\
&= \frac {1}{n} \sum _{i = 1}^{n} \Big [\log \sigma (f_{\theta }(s_i,a_i,{\color {green} s_{f}^{+}})) + \log (1-\sigma (f_{\theta }(s_i,a_i, {\color {red} s_{f}^{-}})))\Big ]
\end {align*}
]]></fr:tex><fr:tex display="block"><![CDATA[
\mathcal {L}(\theta ) = \mathbb {E}_{x \sim  p_X, y \sim  p_Y}\Big [\log \sigma (f_{\theta }(x)) + \log (1-\sigma (f_{\theta }(y)))\Big ]
]]></fr:tex><fr:tex display="block"><![CDATA[f^*(s, a, s_g) = \log \left (\frac {p^{\pi (\cdot  \mid  \cdot )}(s_g \mid  s, a)}{p(s_g)}\right )]]></fr:tex>
   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>10</fr:month><fr:day>31</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>
    We want to maximize
<fr:tex display="block"><![CDATA[
    \begin {align*}
\mathcal {L}(\theta ) &= \mathbb {E}_{x \sim  p_X, y \sim  p_Y}\Big [\log \sigma (f_{\theta }(x)) + \log (1-\sigma (f_{\theta }(y)))\Big ] \\
&= \int  \log \sigma (f_{\theta }(x)) P_X(x) + \int  \log (1-\sigma (f_{\theta }(y))) P_Y(y) \\
&= \int  \log \sigma (f_{\theta }(z)) P_X(z) + \log (1-\sigma (f_{\theta }(z))) P_Y(z)
    \end {align*}
    ]]></fr:tex>
    Since we are maximizing <fr:tex display="inline"><![CDATA[f(s)]]></fr:tex>, we can just maximize the integrand i.e.
<fr:tex display="block"><![CDATA[
      \begin {align*}
        \frac {\mathrm {d}}{\mathrm {d}f(z)} \Big [\log \sigma (f_{\theta }(z)) P_X(z) + \log (1-\sigma (f_{\theta }(z))) P_Y(z)\Big ] = 0
      \end {align*}
    ]]></fr:tex>
    Solving,
    <fr:tex display="block"><![CDATA[
        \begin {align*}
          P_X(z)\big (1 - \sigma (f(z))\big ) - P_Y(z)\sigma (f(z)) = 0 &\iff  \sigma (f(z)) = \frac {P_X(z)}{P_X(z) + P_Y(z)} \\
          &\iff  f(z) = \log \left (\frac {P_X(z)}{P_Y(z)}\right )
        \end {align*}
      ]]></fr:tex>
  </fr:mainmatter></fr:tree>
 


   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2024</fr:year><fr:month>10</fr:month><fr:day>31</fr:day></fr:date><fr:taxon>Proof</fr:taxon></fr:frontmatter><fr:mainmatter>
The first step is to prove that the average Q-values are close to the task-conditioned Q-values. Below, we will use <fr:tex display="inline"><![CDATA[R_{c}(\tau )\triangleq \sum _{\ell =0}^{\infty }\gamma ^{\ell }r_{\ell }(s_{\ell },a_{\ell })]]></fr:tex>:

<fr:tex display="block"><![CDATA[
\begin {align*}
\left |Q^{\beta (\cdot |\cdot ,a)}(s,a,e)-Q^{\beta (\cdot |\cdot ,\epsilon ^{\prime })}(s,a,e)\right |&=\left |\int \beta (\tau \mid  s,a,e)R_{e}(\tau )d\tau -\int \beta (\tau \mid  s,a,e^{\prime })R_{e}(\tau )d\tau \right |\\ 
&=\left |\int \beta (\tau \mid  s,a,e)-\beta (\tau \mid  s,a,e^{\prime })R_{e}(\tau )d\tau \right | \\
&=\left |\int \beta (\tau \mid  s,a,e)\left (1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right )R_{e}(\tau )d\tau \right | \\
&\leq \int \left |\beta (\tau \mid  s,a,e)\left (1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right )\right |d\tau \cdot \operatorname *{max}_{\tau }|R_{e}(\tau )d\tau | \\
&\leq \int \beta (\tau \mid  s,a,e)\left |1-\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}\right |d\tau \cdot  1 \\
&=\mathbb {E}_{\beta (\tau |s,a,e)}\left [\left |1-{\frac {\beta (\tau \mid  s,a,e^{\prime })}{\beta (\tau \mid  s,a,e)}}\right |\right ] \\
&\leq  \epsilon .
\end {align*}
  ]]></fr:tex>
</fr:mainmatter></fr:tree>
 

</fr:mainmatter>
                </fr:tree>
                <html:script src="https://utteranc.es/client.js" repo="kkanarios32/website-comments" issue-term="contrastive-rl" theme="boxy-light" crossorigin="anonymous" async="" />
              </fr:mainmatter>
            </fr:tree>
            <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
              <fr:frontmatter>
                <fr:authors />
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>3</fr:month>
                  <fr:day>4</fr:day>
                </fr:date>
                <fr:uri>https://kkanarios32.github.io/005F/</fr:uri>
                <fr:display-uri>005F</fr:display-uri>
                <fr:route>/005F/</fr:route>
                <fr:title text="Rebuilding My (Neo)Vim Config From Scratch">Rebuilding My (Neo)Vim Config From Scratch</fr:title>
              </fr:frontmatter>
              <fr:mainmatter><html:p>I have been using LazyVim for some time now, but I have now run into issues multiple times where understanding how LazyVim is doing something is far more difficult than if I had written my own setup. I allocated one day for this adventure and really just wanted to make sure I had support for <fr:tex display="inline"><![CDATA[\TeX ]]></fr:tex>, python, forester, and C/C++. Due to my (self-imposed) time constraint, I do not have the associated resources linked for each of the things discussed below. At some point, I hope to come back and more thoroughly cover each of the components.
</html:p>
  
    <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Sane Defaults">Sane Defaults</fr:title></fr:frontmatter><fr:mainmatter>
To my surprise, a lot of the features that I had come to take for granted were actually options set up internally by Lazyvim. For example, I was shocked with 8 space indents!! and I could not even copy from one terminal instance to another... Due to this, I went and found all of the options I liked from Lazyvim and added them to my new configuration in <html:code>configs/options.lua</html:code>.
</fr:mainmatter></fr:tree>
  

  
    <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Installing a Plugin Manager">Installing a Plugin Manager</fr:title></fr:frontmatter><fr:mainmatter>
For this, we will be using the defacto standard <html:code>lazy.nvim</html:code>. This is actually straightforward and kind of "just works". Just follow the installation guide in their documentation.
</fr:mainmatter></fr:tree>
  

  
    <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Setting up Auto Complete">Setting up Auto Complete</fr:title></fr:frontmatter><fr:mainmatter>
This is one of the main motivations for me making the switch. It seems <html:code>nvim-cmp</html:code> has finally been replaced with a new <html:code>blink.cmp</html:code>, so that is what we will be using.


  
    <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Rebuilding My (Neo)Vim Config From Scratch › Language Server Protocol"><fr:link href="/005F/" title="Rebuilding My (Neo)Vim Config From Scratch" uri="https://kkanarios32.github.io/005F/" display-uri="005F" type="local">Rebuilding My (Neo)Vim Config From Scratch</fr:link> › Language Server Protocol</fr:title></fr:frontmatter><fr:mainmatter>
It turns out there is a lot that goes into getting LSP setup correctly.
<html:ol><html:li>First we must actually install the language servers. To do this the easiest way, we use the <html:code>mason.nvim</html:code> and <html:code>mason.nvim-lspconfig</html:code> plugins. At some point, I might actually figure out how to set up lsp myself without lspconfig but that point is not now.
</html:li>
<html:li>Through <html:code>nvim-lspconfig</html:code>, we can set up each of the servers we want to have LSP support. I just set up clangd, pyright, and texlab.</html:li></html:ol>
This was a bit ridiculous. The first of many challenges was around import resolution in python. To remedy this, I needed to write a function to find the virtual environment directory and then set the <html:code>pythonPath</html:code> to the venv python binary. Previously, I think I was just using pylsp and installing it as a pip package to each python venv. I much prefer the new way, and I think pyright is overall a much better lsp.
</fr:mainmatter></fr:tree>
  


  
    <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Rebuilding My (Neo)Vim Config From Scratch › Forester Completion"><fr:link href="/005F/" title="Rebuilding My (Neo)Vim Config From Scratch" uri="https://kkanarios32.github.io/005F/" display-uri="005F" type="local">Rebuilding My (Neo)Vim Config From Scratch</fr:link> › Forester Completion</fr:title></fr:frontmatter><fr:mainmatter>
  Another necessary completion source for me is the one provided by <html:code>forester.nvim</html:code>. Similar to vimtex, the reference completion support is VERY useful. Obviously, I need completion when I am writing this blog!!! This was a little more involved. The first difficulty was that the completion source provided by the <html:code>forester.nvim</html:code> plugin was for <html:code>nvim-cmp</html:code>. It turns out this is a prevalent enough problem that the author of <html:code>blink.cmp</html:code> wrote an additional plugin <html:code>blink.compat</html:code> to allow for <html:code>nvim-cmp</html:code> completion sources. While this sounds all fine and good, <html:code>nvim-compat</html:code> expects plugins that return the completion source themselves, whereas in <html:code>forester.nvim</html:code> the completion source is just one submodule of a more feature-rich plugin. To get around this, I needed to look into the <html:code>blink.compat</html:code> code and find how they are registering the sources and just do it myself.
</fr:mainmatter></fr:tree>
  

</fr:mainmatter></fr:tree>
  

  
    <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Snippets">Snippets</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>
  Going all the way back to the <fr:link href="https://castel.dev/post/lecture-notes-1/" type="external">Gilles Castel blog post</fr:link>, I have always been partial to snippets that auto-expand. I had them set up prior to Lazyvim but with Lazyvim I had resigned to using friendly-snippets with native nvim snippets. Since I was already redoing everything, this time around I decided not to compromise. Once upon a time (right when it came out I think?) I tried out Luasnips, but it seems that they now have far more extensive features. They are also natively supported by <html:code>blink.cmp</html:code>!! It feels necessary that I plug the <fr:link href="https://github.com/iurimateus/luasnip-latex-snippets.nvim" type="external">awesome repo</fr:link> that ports the original Ultisnips snippets to Luasnip. With this, I was able to easily add my own forester snippets!!!
  </html:p>
  <html:p>
  A fun little thing that I had been hoping to do for awhile and is finally now possible - I can load latex snippets when inside math environments in forester!!!! To do this, I looked into the forester treesitter grammar and found the corresponding nodetypes for math envs. It was then straightforward to detect whether we were in a math env and to load the associated latex snippets.
  </html:p>
</fr:mainmatter></fr:tree>
  

  
    <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Anki">Anki</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>
  There is a very cool add-on to anki called <fr:link href="https://git.sr.ht/~foosoft/anki-connectdeck-actions" type="external">AnkiConnect</fr:link> that has an associated plugin <html:code>anki.nvim</html:code>. Basically, AnkiConnects allows you to make requests to Anki and receive/send useful information from/to your decks. Unfortunately, <html:code>anki.nvim</html:code> built-in commands didn't seem all that useful to me. However, it provided the necessary infrastructure for me to accomplish my desired workflow.
  </html:p>
  <html:p>
  Namely, I made my own command that queries Anki for the deck names, which you can then pick from using telescope pickers. When you select one it will create a new flashcard in a specified flashcard directory under a directory created based on the deck name. You can then send this card to that deck using the existing <html:code>AnkiSend</html:code> command.
  </html:p>
  <html:p>I also continued the snippet fun here. When writing Anki cards, you can write latex code between [latex] [/latex] delimiters. I wrote a quick function to detect whether we are in these delimiters and if we are then to load the latex snippets from the previous section. I also added some basic anki filetype plugins to insert things like these delimiters.</html:p>
</fr:mainmatter></fr:tree>
  

  
    <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Formatters and Linters">Formatters and Linters</fr:title></fr:frontmatter><fr:mainmatter>
  <html:code>compat.nvim</html:code>, <html:code>mason.nvim</html:code>, black, isort.
</fr:mainmatter></fr:tree>
  
<html:script src="https://utteranc.es/client.js" repo="kkanarios32/website-comments" issue-term="nvim" theme="boxy-light" crossorigin="anonymous" async="" /></fr:mainmatter>
            </fr:tree>
            <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
              <fr:frontmatter>
                <fr:authors />
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>3</fr:month>
                  <fr:day>31</fr:day>
                </fr:date>
                <fr:uri>https://kkanarios32.github.io/006Q/</fr:uri>
                <fr:display-uri>006Q</fr:display-uri>
                <fr:route>/006Q/</fr:route>
                <fr:title text="Test Time Compute in Reinforcement Learning">Test Time Compute in Reinforcement Learning</fr:title>
              </fr:frontmatter>
              <fr:mainmatter><html:p><html:em>One thing that should be learned [...] is the great power of general purpose methods, of methods that continue to scale with increased computation even as the available computation becomes very great. The two methods that seem to scale arbitrarily in this way are search and learning.</html:em> - <fr:link href="/richardsutton/" title="Richard Sutton" uri="https://kkanarios32.github.io/richardsutton/" display-uri="richardsutton" type="local">Richard Sutton</fr:link></html:p>
  
    <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>31</fr:day></fr:date><fr:title text="What is Planning?">What is Planning?</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>
    In <fr:link href="/suttonReinforcementLearningIntroduction2018/" title="Reinforcement learning: An introduction" uri="https://kkanarios32.github.io/suttonReinforcementLearningIntroduction2018/" display-uri="suttonReinforcementLearningIntroduction2018" type="local">Reinforcement learning: An introduction</fr:link>, they define planning as <html:em>a computational process that takes a model as input and outputs a policy</html:em>. Like everything Sutton writes, I agree with it for the most part. I have struggled with this question for a long time. In the RL community, you often here this vague term "planning" thrown around in all sorts of different situations. I think the key distinction between traditional methods is shown when looking at these methods directly. The only definition I have come up with that leaves me somewhat satisfied is "policy improvement in the absence of learning.
  </html:p>
  <html:p>
    As an example, in <fr:link href="/suttonReinforcementLearningIntroduction2018/" title="Reinforcement learning: An introduction" uri="https://kkanarios32.github.io/suttonReinforcementLearningIntroduction2018/" display-uri="suttonReinforcementLearningIntroduction2018" type="local">Q-learning</fr:link> you interact with the environment and learn via updating your Q-function. You then immediately recover an action via <fr:tex display="inline"><![CDATA[a \in  \arg \max _{a} Q(s, a)]]></fr:tex> This does not require that you input a model rather you only input the current state and receive the corresponding action. Learning can be seen as distilling everything needed into the model, where planning allows the model to see and plan based on the consequences of potential actions using a model of the environment.
  </html:p>
</fr:mainmatter></fr:tree>
  
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>31</fr:day></fr:date><fr:uri>https://kkanarios32.github.io/006R/</fr:uri><fr:display-uri>006R</fr:display-uri><fr:route>/006R/</fr:route><fr:title text="Alpha-Zero">Alpha-Zero</fr:title></fr:frontmatter><fr:mainmatter><html:p>The major break through of planning was in <fr:link href="/schrittwieserMasteringAtariGo2020/" title="Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model" uri="https://kkanarios32.github.io/schrittwieserMasteringAtariGo2020/" display-uri="schrittwieserMasteringAtariGo2020" type="local">alpha-zero</fr:link>, or more accurately at the time was just alpha-go. However, the core idea remained the same. The idea is to learn some notion of a "good" state in a game like chess or go and then leverage this information in combination with some planning.</html:p></fr:mainmatter></fr:tree><html:script src="https://utteranc.es/client.js" repo="kkanarios32/website-comments" issue-term="mcts" theme="boxy-light" crossorigin="anonymous" async="" /></fr:mainmatter>
            </fr:tree>
          </fr:mainmatter>
        </fr:tree>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>
                <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kkanarios32.github.io/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
              </fr:author>
            </fr:authors>
            <fr:uri>https://kkanarios32.github.io/about/</fr:uri>
            <fr:display-uri>about</fr:display-uri>
            <fr:route>/about/</fr:route>
            <fr:title text="Kellen Kanarios › About this website"><fr:link href="/0001/" title="Kellen Kanarios" uri="https://kkanarios32.github.io/0001/" display-uri="0001" type="local">Kellen Kanarios</fr:link> › About this website</fr:title>
          </fr:frontmatter>
          <fr:mainmatter>
            <html:p>
    This is my <fr:link href="https://www.forester-notes.org/index/index.xml" type="external">forest</fr:link> (shoutout to <fr:link href="/jonmsterling/" title="Jon Sterling" uri="https://kkanarios32.github.io/jonmsterling/" display-uri="jonmsterling" type="local">Jon Sterling</fr:link> who is remarkably helpful). This website functions both as a <fr:link href="https://en.wikipedia.org/wiki/Personal_knowledge_management" type="external">personal knowledge management system</fr:link>, where I store my notes in <fr:link href="/0015/" title="Notebooks" uri="https://kkanarios32.github.io/0015/" display-uri="0015" type="local">notebooks</fr:link> and also have some additional external resources in <fr:link href="/0004/" title="/dev/null" uri="https://kkanarios32.github.io/0004/" display-uri="0004" type="local">/dev/null</fr:link>. Additionally, I store my thoughts in a variety of consumption mediums. Namely, short-form notes / blog posts can be found in the "<fr:link href="/007L/" title="Marginalia" uri="https://kkanarios32.github.io/007L/" display-uri="007L" type="local">marginalia</fr:link>". I also maintain two weekly posting obligations: a <fr:link href="/0001/" title="Kellen Kanarios" uri="https://kkanarios32.github.io/0001/" display-uri="0001" type="local">weeknotes / lifelog</fr:link> and a <fr:link href="/005G/" title="Papers of a Week" uri="https://kkanarios32.github.io/005G/" display-uri="005G" type="local">paper of the week</fr:link>. 
      </html:p>
          </fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
