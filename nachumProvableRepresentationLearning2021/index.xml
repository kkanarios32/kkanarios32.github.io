<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors>
      <fr:author>Ofir Nachum</fr:author>
      <fr:author>Mengjiao Yang</fr:author>
    </fr:authors>
    <fr:date>
      <fr:year>2021</fr:year>
      <fr:month>10</fr:month>
    </fr:date>
    <fr:uri>https://kellenkanarios.com/nachumProvableRepresentationLearning2021/</fr:uri>
    <fr:display-uri>nachumProvableRepresentationLearning2021</fr:display-uri>
    <fr:route>/nachumProvableRepresentationLearning2021/</fr:route>
    <fr:title text="Provable Representation Learning for Imitation with Contrastive Fourier Features">Provable Representation Learning for Imitation with Contrastive Fourier Features</fr:title>
    <fr:taxon>Reference</fr:taxon>
    <fr:meta name="doi">10.48550/arXiv.2105.12272</fr:meta>
    <fr:meta name="external">https://arxiv.org/abs/2105.12272</fr:meta>
    <fr:meta name="bibtex"><![CDATA[@misc{nachumProvableRepresentationLearning2021,
 title = {Provable {{Representation Learning}} for {{Imitation}} with {{Contrastive Fourier Features}}},
 author = {Nachum, Ofir and Yang, Mengjiao},
 year = {2021},
 doi = {10.48550/arXiv.2105.12272},
 urldate = {2025-05-13},
 number = {arXiv:2105.12272},
 publisher = {arXiv},
 file = {/home/kellen/Downloads/pdfs/storage/GSS265YF/Nachum and Yang - 2021 - Provable Representation Learning for Imitation with Contrastive Fourier Features.pdf;/home/kellen/Downloads/pdfs/storage/DPCP6C3X/2105.html},
 keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
 archiveprefix = {arXiv},
 abstract = {In imitation learning, it is common to learn a behavior policy to match an unknown target policy via max-likelihood training on a collected set of target demonstrations. In this work, we consider using offline experience datasets - potentially far from the target distribution - to learn low-dimensional state representations that provably accelerate the sample-efficiency of downstream imitation learning. A central challenge in this setting is that the unknown target policy itself may not exhibit low-dimensional behavior, and so there is a potential for the representation learning objective to alias states in which the target policy acts differently. Circumventing this challenge, we derive a representation learning objective that provides an upper bound on the performance difference between the target policy and a lowdimensional policy trained with max-likelihood, and this bound is tight regardless of whether the target policy itself exhibits low-dimensional structure. Moving to the practicality of our method, we show that our objective can be implemented as contrastive learning, in which the transition dynamics are approximated by either an implicit energy-based model or, in some special cases, an implicit linear model with representations given by random Fourier features. Experiments on both tabular environments and high-dimensional Atari games provide quantitative evidence for the practical benefits of our proposed objective.},
 primaryclass = {cs},
 eprint = {2105.12272},
 month = {October}
}]]></fr:meta>
  </fr:frontmatter>
  <fr:mainmatter />
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
