<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors>
      <fr:author>
        <fr:link href="https://kkanarios32.github.io/Daniel%20Snider/" type="external">Daniel Snider</fr:link>
      </fr:author>
      <fr:author>
        <fr:link href="https://kkanarios32.github.io/Ruofan%20Liang/" type="external">Ruofan Liang</fr:link>
      </fr:author>
    </fr:authors>
    <fr:date>
      <fr:year>2023</fr:year>
      <fr:month>1</fr:month>
    </fr:date>
    <fr:uri>https://kkanarios32.github.io/sniderOperatorFusionXLA2023/</fr:uri>
    <fr:display-uri>sniderOperatorFusionXLA2023</fr:display-uri>
    <fr:route>/sniderOperatorFusionXLA2023/</fr:route>
    <fr:title text="Operator Fusion in XLA: Analysis and Evaluation">Operator Fusion in XLA: Analysis and Evaluation</fr:title>
    <fr:taxon>Reference</fr:taxon>
    <fr:meta name="external">https://arxiv.org/abs/2301.13062</fr:meta>
    <fr:meta name="bibtex"><![CDATA[@misc{sniderOperatorFusionXLA2023,
 title = {Operator {{Fusion}} in {{XLA}}: {{Analysis}} and {{Evaluation}}},
 author = {Snider, Daniel and Liang, Ruofan},
 year = {2023},
 urldate = {2024-10-20},
 number = {arXiv:2301.13062},
 publisher = {arXiv},
 file = {/home/kellen/Zotero/storage/9M5P2JQF/Snider and Liang - 2023 - Operator Fusion in XLA Analysis and Evaluation.pdf},
 keywords = {Computer Science - Machine Learning},
 langid = {english},
 archiveprefix = {arXiv},
 abstract = {Machine learning (ML) compilers are an active area of research because they offer the potential to automatically speedup tensor programs. Kernel fusion is often cited as an important optimization performed by ML compilers. However, there exists a knowledge gap about how XLA, the most common ML compiler, applies this nuanced optimization, what kind of speedup it can afford, and what low-level effects it has on hardware. Our paper aims to bridge this knowledge gap by studying key compiler passes of XLA's source code. Our evaluation on a reinforcement learning environment Cartpole shows how different fusion decisions in XLA are made in practice. Furthermore, we implement several XLA kernel fusion strategies that can achieve up to 10.56x speedup compared to our baseline implementation.},
 primaryclass = {cs},
 eprint = {2301.13062},
 month = {January},
 shorttitle = {Operator {{Fusion}} in {{XLA}}}
}]]></fr:meta>
  </fr:frontmatter>
  <fr:mainmatter />
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
