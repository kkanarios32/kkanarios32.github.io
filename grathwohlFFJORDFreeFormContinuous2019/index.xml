<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors>
      <fr:author>Will Grathwohl</fr:author>
      <fr:author>Ricky T Q Chen</fr:author>
      <fr:author>Jesse Bettencourt</fr:author>
      <fr:author>Ilya Sutskever</fr:author>
      <fr:author>David Duvenaud</fr:author>
    </fr:authors>
    <fr:date>
      <fr:year>2019</fr:year>
    </fr:date>
    <fr:uri>https://kellenkanarios.com/grathwohlFFJORDFreeFormContinuous2019/</fr:uri>
    <fr:display-uri>grathwohlFFJORDFreeFormContinuous2019</fr:display-uri>
    <fr:route>/grathwohlFFJORDFreeFormContinuous2019/</fr:route>
    <fr:title text="FFJORD: Free-Form Continuous DYnamics for Scalable Reversible Generative Models">FFJORD: Free-Form Continuous DYnamics for Scalable Reversible Generative Models</fr:title>
    <fr:taxon>Reference</fr:taxon>
    <fr:meta name="bibtex"><![CDATA[@article{grathwohlFFJORDFreeFormContinuous2019,
 title = {{{FFJORD}}: {{Free-Form Continuous DYnamics}} for {{Scalable Reversible Generative Models}}},
 author = {Grathwohl, Will and Chen, Ricky T Q and Bettencourt, Jesse and Sutskever, Ilya and Duvenaud, David},
 year = {2019},
 file = {/home/kellen/Downloads/pdfs/storage/2H337KKY/Grathwohl et al. - 2019 - FFJORD FREE-FORM CONTINUOUS DYNAMICS FOR SCALABLE.pdf},
 langid = {english},
 abstract = {Reversible generative models map points from a simple distribution to a complex distribution through an easily invertible neural network. Likelihood-based training of these models requires restricting their architectures to allow cheap computation of Jacobian determinants. Alternatively, the Jacobian trace can be used if the transformation is specified by an ordinary differential equation. In this paper, we use Hutchinson's trace estimator to give a scalable unbiased estimate of the logdensity. The result is a continuous-time invertible generative model with unbiased density estimation and one-pass sampling, while allowing unrestricted neural network architectures. We demonstrate our approach on high-dimensional density estimation, image generation, and variational inference, improving the state-ofthe-art among exact likelihood methods with efficient sampling.}
}]]></fr:meta>
  </fr:frontmatter>
  <fr:mainmatter />
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
