<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors />
    <fr:date>
      <fr:year>2025</fr:year>
      <fr:month>7</fr:month>
      <fr:day>29</fr:day>
    </fr:date>
    <fr:uri>https://kellenkanarios.com/SAYD/</fr:uri>
    <fr:display-uri>SAYD</fr:display-uri>
    <fr:route>/SAYD/</fr:route>
    <fr:title text="Memory Intro">Memory Intro</fr:title>
  </fr:frontmatter>
  <fr:mainmatter><html:p>
We are now moving on from scheduling into the wonderful world of all things memory.
  </html:p>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:title text="Address Spaces">Address Spaces</fr:title></fr:frontmatter><fr:mainmatter>
If we think about what we have done so far, we have an assortment of processes that are constantly being switched between. However, each of these process has their own assortment of register states, but more importantly they each have their own state in <html:em>memory</html:em>.
<html:ol><html:li>For register states, the OS has its own reserved memory, where it can easily store and switch between register states.</html:li>
  <html:li>For memory, when we switch processes, are we expected to clear out memory for the next process by storing to disk? <html:strong>NO!</html:strong></html:li></html:ol>
This motivates the idea behind <html:em>address spaces</html:em>. Namely, each process is given its own address space (chunk in memory) to use at its own discretion. This will then ensure that other processes do not overwrite the program state of one another. The address space of a process typically consists of three components
<html:ol><html:li>Code of the program</html:li>
  <html:li>Stack: local var, arguments, return values</html:li>
  <html:li>Heap: dynamically allocated memory</html:li></html:ol>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
As we will see later, every address we see is actually <html:em>virtual</html:em>, meaning it is not the location in physical memory.
</fr:mainmatter></fr:tree>

<html:p><html:strong>API:</html:strong> We only really need two methods, a way to get memory and a way to release memory. These are implemented via <html:code>malloc</html:code> and <html:code>free</html:code>. However, the use of these is usually accompanied with a handful of common errors:</html:p>
<html:ol><html:li>Forget to initialize mem.</html:li>
  <html:li>Forget to free mem.</html:li>
  <html:li>Freeing memory early: <html:em>dangling pointer</html:em>.</html:li>
  <html:li>Freeing the same memory twice: <html:em>double free</html:em>.</html:li>
  <html:li>Passing something not allocated earlier: <html:em>invalid free</html:em>.</html:li></html:ol>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
When a process dies, the OS reclaims all of that process memory. This means that as long as your program memory is bounded, leakage will not do any sort of catastrophic damage. However, it is still not good practice.
</fr:mainmatter></fr:tree>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
<html:code>malloc</html:code> and <html:code>free</html:code> are not syscalls. The heap is pre-allocated with some allotment of memory. If the program exceeds this memory then <html:code>malloc</html:code> will call a syscall <html:code>brk</html:code> / <html:code>sbrk</html:code> to increment / decrement heap mem pointer.
</fr:mainmatter></fr:tree>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
You can actually initialize and use your own heap-like memory through <html:code>mmap</html:code>. This memory is not associated with any particular file and is an <html:em>anonymous</html:em> memory region within your program.
</fr:mainmatter></fr:tree>

</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:title text="Address Translation">Address Translation</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>The next question is once each program has their own address space, how do we unify the experience for the user.</html:p>
  <html:ol><html:li>We want every process to have the <html:em>illusion</html:em> that is starts at address <fr:tex display="inline"><![CDATA[0]]></fr:tex></html:li>
    <html:li>We want every process to have the <html:em>illusion</html:em> of a large address space.</html:li></html:ol>
  <html:p>However, we also do not want to give up the protection / speed of the address space abstraction. The overarching idea is <html:em>virualizing</html:em> the address space. This means that the address the user sees is not the true address in physical memory. How we achieve this will be a longstanding topic for the next few entries of these notes.</html:p>
  <html:p><html:strong>Base and Bounds:</html:strong> The first approach is <html:em>base and bounds</html:em>. For this approach, the hardware has a dedicated base and bound register to indicate where the address space for a given process begins and ends. It is the OSes job to ensure that these registers are filled with the correct values for the current process.
  <html:ul><html:li>The hardware must provide protected instructions to allow the OS to modify the base and bound registers.</html:li></html:ul></html:p>
  <html:p>An <html:em>address translation</html:em> is then performed by the hardware by adding the base to the virtual address and checking it remains within the bounds. This is done by the <html:em>memory management unit</html:em> (MMU). A common theme we will see is that hardware support is crucial to achieve good virtualization.</html:p>
  
 <html:div class="jms-indent-block" style="
  margin-left: 1em;
  margin-bottom: 1em;
  border-left: 4px solid black;
  padding-left: 12px;
  background-color: whitesmoke;
  ">
    <html:strong>Problem:</html:strong> <html:em>to support a large addres space with base and bounds we suffer significant <html:em>internal fragmentation</html:em> i.e. in between the base and bound there is a lot of unused memory.</html:em>
  </html:div>

  <html:p>To better understand why fragmentation is such an issue: if we have 16kb total memory and each process requests 4kb but only uses 2kb, then we can only maintain 4 processes despite having the memory to service 8! To attempt to remedy this, we will introduce the idea of <html:em>segmentation</html:em>.</html:p> 
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:title text="Segmentation">Segmentation</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>Instead of pre-allocating the memory between the heap and stack, why don't we <html:em>allocate on demand</html:em>. To do so, we can treat the code, heap, and stack as their own <html:em>segments</html:em> with their own base and bound registers. An address could then be decomposed as 
<fr:tex display="block"><![CDATA[\underbrace {0 1}_{\text {segment}}\underbrace {0 1 \cdots  11}_{\text {offset}}]]></fr:tex>
This also enables an idea of <html:em>memory sharing</html:em>, where process can share a portion of memory (such as the code) to save memory on the system.
<html:ul><html:li>Need to add a protection bit to indicate whether a process can modify certain addrs.</html:li></html:ul></html:p>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
This limits flexibility in the sense that we have no control over where the middle region was allocated and therefore we cannot grow beyond the initial bound.
</fr:mainmatter></fr:tree>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
The hardware also has to support the stack growing backwards when it checks the bounds. To do so, it has to perform an additional check based on the segment number.
</fr:mainmatter></fr:tree>

</fr:mainmatter></fr:tree>
</fr:mainmatter>
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors />
            <fr:date>
              <fr:year>2025</fr:year>
              <fr:month>8</fr:month>
              <fr:day>16</fr:day>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/TQSZ/</fr:uri>
            <fr:display-uri>TQSZ</fr:display-uri>
            <fr:route>/TQSZ/</fr:route>
            <fr:title text="TEP Memory"><fr:link href="/arpaci2018operating/" title="Operating Systems: Three Easy Pieces" uri="https://kellenkanarios.com/arpaci2018operating/" display-uri="arpaci2018operating" type="local">TEP</fr:link> Memory</fr:title>
          </fr:frontmatter>
          <fr:mainmatter>
            <fr:tree show-metadata="false">
              <fr:frontmatter>
                <fr:authors />
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>7</fr:month>
                  <fr:day>29</fr:day>
                </fr:date>
                <fr:uri>https://kellenkanarios.com/SAYD/</fr:uri>
                <fr:display-uri>SAYD</fr:display-uri>
                <fr:route>/SAYD/</fr:route>
                <fr:title text="Memory Intro">Memory Intro</fr:title>
              </fr:frontmatter>
              <fr:mainmatter><html:p>
We are now moving on from scheduling into the wonderful world of all things memory.
  </html:p>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:title text="Address Spaces">Address Spaces</fr:title></fr:frontmatter><fr:mainmatter>
If we think about what we have done so far, we have an assortment of processes that are constantly being switched between. However, each of these process has their own assortment of register states, but more importantly they each have their own state in <html:em>memory</html:em>.
<html:ol><html:li>For register states, the OS has its own reserved memory, where it can easily store and switch between register states.</html:li>
  <html:li>For memory, when we switch processes, are we expected to clear out memory for the next process by storing to disk? <html:strong>NO!</html:strong></html:li></html:ol>
This motivates the idea behind <html:em>address spaces</html:em>. Namely, each process is given its own address space (chunk in memory) to use at its own discretion. This will then ensure that other processes do not overwrite the program state of one another. The address space of a process typically consists of three components
<html:ol><html:li>Code of the program</html:li>
  <html:li>Stack: local var, arguments, return values</html:li>
  <html:li>Heap: dynamically allocated memory</html:li></html:ol>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
As we will see later, every address we see is actually <html:em>virtual</html:em>, meaning it is not the location in physical memory.
</fr:mainmatter></fr:tree>

<html:p><html:strong>API:</html:strong> We only really need two methods, a way to get memory and a way to release memory. These are implemented via <html:code>malloc</html:code> and <html:code>free</html:code>. However, the use of these is usually accompanied with a handful of common errors:</html:p>
<html:ol><html:li>Forget to initialize mem.</html:li>
  <html:li>Forget to free mem.</html:li>
  <html:li>Freeing memory early: <html:em>dangling pointer</html:em>.</html:li>
  <html:li>Freeing the same memory twice: <html:em>double free</html:em>.</html:li>
  <html:li>Passing something not allocated earlier: <html:em>invalid free</html:em>.</html:li></html:ol>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
When a process dies, the OS reclaims all of that process memory. This means that as long as your program memory is bounded, leakage will not do any sort of catastrophic damage. However, it is still not good practice.
</fr:mainmatter></fr:tree>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
<html:code>malloc</html:code> and <html:code>free</html:code> are not syscalls. The heap is pre-allocated with some allotment of memory. If the program exceeds this memory then <html:code>malloc</html:code> will call a syscall <html:code>brk</html:code> / <html:code>sbrk</html:code> to increment / decrement heap mem pointer.
</fr:mainmatter></fr:tree>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
You can actually initialize and use your own heap-like memory through <html:code>mmap</html:code>. This memory is not associated with any particular file and is an <html:em>anonymous</html:em> memory region within your program.
</fr:mainmatter></fr:tree>

</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:title text="Address Translation">Address Translation</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>The next question is once each program has their own address space, how do we unify the experience for the user.</html:p>
  <html:ol><html:li>We want every process to have the <html:em>illusion</html:em> that is starts at address <fr:tex display="inline"><![CDATA[0]]></fr:tex></html:li>
    <html:li>We want every process to have the <html:em>illusion</html:em> of a large address space.</html:li></html:ol>
  <html:p>However, we also do not want to give up the protection / speed of the address space abstraction. The overarching idea is <html:em>virualizing</html:em> the address space. This means that the address the user sees is not the true address in physical memory. How we achieve this will be a longstanding topic for the next few entries of these notes.</html:p>
  <html:p><html:strong>Base and Bounds:</html:strong> The first approach is <html:em>base and bounds</html:em>. For this approach, the hardware has a dedicated base and bound register to indicate where the address space for a given process begins and ends. It is the OSes job to ensure that these registers are filled with the correct values for the current process.
  <html:ul><html:li>The hardware must provide protected instructions to allow the OS to modify the base and bound registers.</html:li></html:ul></html:p>
  <html:p>An <html:em>address translation</html:em> is then performed by the hardware by adding the base to the virtual address and checking it remains within the bounds. This is done by the <html:em>memory management unit</html:em> (MMU). A common theme we will see is that hardware support is crucial to achieve good virtualization.</html:p>
  
 <html:div class="jms-indent-block" style="
  margin-left: 1em;
  margin-bottom: 1em;
  border-left: 4px solid black;
  padding-left: 12px;
  background-color: whitesmoke;
  ">
    <html:strong>Problem:</html:strong> <html:em>to support a large addres space with base and bounds we suffer significant <html:em>internal fragmentation</html:em> i.e. in between the base and bound there is a lot of unused memory.</html:em>
  </html:div>

  <html:p>To better understand why fragmentation is such an issue: if we have 16kb total memory and each process requests 4kb but only uses 2kb, then we can only maintain 4 processes despite having the memory to service 8! To attempt to remedy this, we will introduce the idea of <html:em>segmentation</html:em>.</html:p> 
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:title text="Segmentation">Segmentation</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>Instead of pre-allocating the memory between the heap and stack, why don't we <html:em>allocate on demand</html:em>. To do so, we can treat the code, heap, and stack as their own <html:em>segments</html:em> with their own base and bound registers. An address could then be decomposed as 
<fr:tex display="block"><![CDATA[\underbrace {0 1}_{\text {segment}}\underbrace {0 1 \cdots  11}_{\text {offset}}]]></fr:tex>
This also enables an idea of <html:em>memory sharing</html:em>, where process can share a portion of memory (such as the code) to save memory on the system.
<html:ul><html:li>Need to add a protection bit to indicate whether a process can modify certain addrs.</html:li></html:ul></html:p>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
This limits flexibility in the sense that we have no control over where the middle region was allocated and therefore we cannot grow beyond the initial bound.
</fr:mainmatter></fr:tree>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
The hardware also has to support the stack growing backwards when it checks the bounds. To do so, it has to perform an additional check based on the segment number.
</fr:mainmatter></fr:tree>

</fr:mainmatter></fr:tree>
</fr:mainmatter>
            </fr:tree>
            <fr:tree show-metadata="false">
              <fr:frontmatter>
                <fr:authors />
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>7</fr:month>
                  <fr:day>29</fr:day>
                </fr:date>
                <fr:uri>https://kellenkanarios.com/67X5/</fr:uri>
                <fr:display-uri>67X5</fr:display-uri>
                <fr:route>/67X5/</fr:route>
                <fr:title text="Free-Space Management">Free-Space Management</fr:title>
              </fr:frontmatter>
              <fr:mainmatter><html:p>We have been talking a lot about how to abstract physical address to provide ease of use for the programmer. However, we have yet to discuss how to actually allocate these physical addresses in the first place. When allocating memory, there are a few issues we need to be careful about
<html:ol><html:li><html:em>External fragmentation</html:em>: lots of small unallocated non-contiguous chunks of memory.</html:li>
  <html:li><html:em>Internal fragmentation</html:em>: allocated memory that is unused in the process it is allocated for.</html:li></html:ol>
To start, we make a few simplifying assumptions:
<html:ol><html:li>After memory has been allocated, it cannot be moved.</html:li>
  <html:li>The size of memory is fixed.</html:li>
  <html:li>The user does not specify the size in <html:code>free</html:code>.</html:li></html:ol>
First, we can quickly deal with the last problem by introducing a <html:em>header</html:em>. The OS stores additional metadata, such as the size of the allocated memory in a header directly preceding the returned pointer in memory.
<html:ul><html:li>If <html:code>int* x = malloc(sizeof(int))</html:code> then <html:code>header = (header_t)* x - 1</html:code>.</html:li>
  <html:li>OS needs to find memory for the requested memory + size of the header.</html:li></html:ul></html:p>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:title text="Malloc Policies">Malloc Policies</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>The general allocation algorithm consists of maintaining some <html:em>free-list</html:em> that contains the address and length of free memory. An allocation is done by some policy over this list. When memory is re-claimed, the list is searched for adjacent memory and if it is found then it is <html:em>coalesced</html:em> into a larger chunk of free memory.</html:p>
<html:ol><html:li><html:em>Best fit</html:em>: find smallest chunk that is big enough</html:li>
  <html:ul><html:li>leaves lots of small chunks</html:li></html:ul>
  <html:li><html:em>Worst fit</html:em>: find largest chunk</html:li></html:ol>
Both of these require searching the entire list, so instead we can introduce some heuristics.
<html:ol><html:li><html:em>First fit</html:em>: find first block that can service.</html:li>
  <html:li><html:em>Next fit</html:em>: find first block that can service starting from the previous allocation.</html:li></html:ol>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:title text="Segregated Lists">Segregated Lists</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>Outside of the allocation policy, we can make data-structure level optimization. One such optimization is segmentation lists. The idea is to maintain different lists that correspond to different commonly allocated object types.</html:p>
  <html:ul><html:li>Grow list by requesting segments as multiple size of the objects.</html:li>
    <html:li>Can return to main list when no references.</html:li>
    <html:li>Can also leave objects pre-iitialized on list to eliminate calls to constructor / destructor.</html:li></html:ul>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>29</fr:day></fr:date><fr:title text="Buddy Allocation">Buddy Allocation</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>Assume memory is size <fr:tex display="inline"><![CDATA[2^n]]></fr:tex>. Search through memory to find smallest block that can service request.</html:p>
<html:figure><html:img width="50%" src="/bafkrmigwzou6llta75hya6llhd6ixa6gjzeoyjqecitht2op5xxutkjgnu.png" />
<html:figcaption>Memory <fr:tex display="inline"><![CDATA[2^n]]></fr:tex>.</html:figcaption></html:figure>
<html:p>When block is freed,
<html:ol><html:li>Check if the buddy is free.</html:li>
  <html:li>If the buddy is free.</html:li>
  <html:ul><html:li>Coalesce into larger block</html:li>
    <html:li>Repeat.</html:li></html:ul></html:ol>
Can easily check buddy because address differ by one bit at each level. Just modify the corresponding bit and check the free data structure (bitmap?) if the address is free. If it is then move up and check the next bit.
</html:p>
</fr:mainmatter></fr:tree>
</fr:mainmatter>
            </fr:tree>
            <fr:tree show-metadata="false">
              <fr:frontmatter>
                <fr:authors />
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>7</fr:month>
                  <fr:day>31</fr:day>
                </fr:date>
                <fr:uri>https://kellenkanarios.com/SB61/</fr:uri>
                <fr:display-uri>SB61</fr:display-uri>
                <fr:route>/SB61/</fr:route>
                <fr:title text="Paging">Paging</fr:title>
              </fr:frontmatter>
              <fr:mainmatter><html:p>Previously, we have only dealt with memory allocations as variable sized chunks i.e. the amount of memory allocated can be anything. A simple idea to avoid the drastic fragmentation this can induce is to instead divide memory into fixed size chunks. This idea is called <html:em>paging</html:em>, where each chunk is a <html:em>page</html:em>.</html:p>
 <html:div class="jms-indent-block" style="
  margin-left: 1em;
  margin-bottom: 1em;
  border-left: 4px solid black;
  padding-left: 12px;
  background-color: whitesmoke;
  ">
  <html:strong>Main question:</html:strong> <html:em>how do we virtualize memory with pages?</html:em>
</html:div>
<html:p><html:strong>Idea:</html:strong> we decompose the address into a <html:em>virtual page number</html:em> (VPN) and offset i.e. 
<fr:tex display="block"><![CDATA[\underbrace {01}_{\text {VPN}}\underbrace {110\cdots  01}_{\text {offset}}]]></fr:tex>
we then maintain a datastructure to map <fr:tex display="inline"><![CDATA[\text {VPN} \mapsto  \text {PPN}]]></fr:tex>, where the PPN is the <html:em>physical page number</html:em> (we divide both virtual and physical memory into pages). We call this data structure a <html:em>page table</html:em>.
</html:p><html:p><html:strong>Problem 1:</html:strong> The page table can get ridiculously large.</html:p>
   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>31</fr:day></fr:date><fr:taxon>Example</fr:taxon></fr:frontmatter><fr:mainmatter>
For now, we consider a linear page table (an array with entry for each VPN). If we support a 32 bit address space with 4kb pages and each entry in the page table is 4 bytes then this is <fr:tex display="inline"><![CDATA[2^{32} / 2^{12} * 4 = 2^{22}]]></fr:tex> bytes of memory for the page table!
</fr:mainmatter></fr:tree>
 
<html:p>Before, we relied on the MMU to translate between physical and virtual addresses via simple operations like base and bound. However, there is no way the MMU could support this many arbitrary translations. Therefore, the page table itself must be stored in physical memory.</html:p><html:p>In addition to the address translation, the page table also keeps track of the following bits:
<html:ol><html:li>
Valid bit: whether this particular VPN has memory allocated to it i.e. mem between stack / heap does not need to be allocated.
  </html:li>
  <html:li>
Protection bit: determines whether the calling program can read / write / execute.
  </html:li>
  <html:li>
Present bit: whether the page currently resides in physical memory.
  </html:li>
  <html:li>
Dirty bit: has the page been modified since being paged in.
  </html:li>
  <html:li>
Reference bit: has the page been accessed (used for eviction policy).
    </html:li></html:ol></html:p><html:p><html:strong>Problem 2:</html:strong> Every time we want to perform an address translation (very often) we must
<html:ol><html:li>Compute VPN from address</html:li>
  <html:li>Access page table entry in physical memory (slow)</html:li>
  <html:li>Compute address with offset + PPN.</html:li>
  <html:li>Access corresponding physical page in physical memory.</html:li></html:ol>
This is very slow!
</html:p>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>31</fr:day></fr:date><fr:title text="TLB">TLB</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>Due to the previously discussed issues, we need a faster way of performing address translation to make paging a feasible option. A common theme: we will throw hardware at it</html:p>
<html:p>Specifically, we will add an additional cache known as the <html:em>translation lookaside buffer</html:em> that caches address translations. Generally, an address translation proceeds as:
<html:ol><html:li>Extract VPN</html:li>
  <html:li>Check if VPN in TLB</html:li>
  <html:li>If in TLB: get translation</html:li>
  <html:li>Otherwise: TLB miss -&gt; trap to OS (RISC)</html:li></html:ol></html:p>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>31</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
We have to be a little careful. The OS code itself is located in memory and is therefore subject to our paging system. We can imagine that on TLB miss the hardware tries to load the TLB miss handler code by checking the TLB, getting the translation, and loading the code. But what if the translation for the TLB miss handler is not in the TLB?!?! To not worry about these things the TLB miss handler gets a permanent spot in physical memory.
</fr:mainmatter></fr:tree>

<html:p>Formally, an entry in the TLB consists of 
<html:ol><html:li>VPN</html:li>
  <html:li>PPN</html:li>
  <html:li>Other bits</html:li>
  <html:ul><html:li>Valid bit: has valid translation (different from PTE valid bit) can be invalid on initialization, eviction, or context switch.</html:li>
    <html:li>Protection bit: whether the requested access can be performed.</html:li></html:ul></html:ol></html:p>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>31</fr:day></fr:date><fr:taxon>Problem</fr:taxon></fr:frontmatter><fr:mainmatter>
  Each process has different address translations corresponding to the same VPN.
</fr:mainmatter></fr:tree>


 
   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>31</fr:day></fr:date><fr:taxon>Solution</fr:taxon></fr:frontmatter><fr:mainmatter>
  Keep additional <html:em>address space identifier</html:em> (ASID) in TLB entry. We also need an ASID register that we set at every process switch to identify the current running process.
</fr:mainmatter></fr:tree>
 

<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>31</fr:day></fr:date><fr:uri>https://kellenkanarios.com/P9UM/</fr:uri><fr:display-uri>P9UM</fr:display-uri><fr:route>/P9UM/</fr:route><fr:title text="Culler's Law">Culler's Law</fr:title><fr:taxon>Definition</fr:taxon></fr:frontmatter><fr:mainmatter><html:p><html:em>"Ram is not always ram"</html:em>. Referring to the fact that a physical memory access takes a substantial different amount of time depending on whether it hit in the TLB.</html:p></fr:mainmatter></fr:tree>

   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>31</fr:day></fr:date><fr:taxon>Example</fr:taxon></fr:frontmatter><fr:mainmatter>
In a real software managed TLB, the TLB consisted of the following components:
<html:ol><html:li>Global bits for globally shared pages,</html:li>
  <html:li>8 bit ASID,</html:li>
  <html:li>Coherence bits for cache-coherence,</html:li>
  <html:li>32-64 TLB entries,</html:li>
  <html:li>A wired register to indicate how many slots to reserve in the TLB for things like TLB miss handler.</html:li></html:ol>
</fr:mainmatter></fr:tree>
 


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>31</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
Another important tidbit: when using very fast caches, even an access to the TLB is a CPU bottleneck (accessing TLB is longer than accessing cache). To get around this, there are <html:em>virtually indexed caches</html:em> that circumvent the need for performing an address translation.
</fr:mainmatter></fr:tree>

</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>31</fr:day></fr:date><fr:title text="Smaller Tables">Smaller Tables</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>As previously discussed, as it currently stands, the page table takes up too much memory.</html:p>
<html:p><html:strong>Solution 1:</html:strong> Just use bigger pages! Unfortunately, this will suffer from severe internal fragmentation (processes not using their allocated memory) and so we would prefer to avoid this solution.</html:p>
<html:p><html:strong>Solution 2:</html:strong> Paging + segmentation. Instead of a page table for all of memory, keep 3 page tables: one for code, stack, and heap. This only partially resolves the problem.
<html:ol><html:li>Same problems as segmentation. Variable sized page tables will cause external fragmentation</html:li>
  <html:li>We can do better. Within each heap, there is still a (smaller) version of the same problem: a bunch of unused allocated PTEs.</html:li></html:ol></html:p>
<html:p><html:strong>Multi-level page tables:</html:strong> Finally, we have arrived to the idea of a multi-level page table. The idea can be summarized as</html:p>
<html:ol><html:li>Chop page table up into pages.</html:li>
  <html:li>Do not allocated pages with no valid references (i.e. none of the corresponding are being used).</html:li></html:ol>
<html:figure><html:img width="80%" src="/bafkrmihf7gcws2u2ay4ecuwqwpgnziozltgjbsn7zo6x5bs6ismwq76jby.png" /></html:figure>
<html:p>This has a few advantages:</html:p>
<html:ol><html:li>Fits easily in memory. Allocate one page when an entry is used.</html:li> 
 <html:li>Proportional to the amount of address space actually in use.</html:li></html:ol>
<html:p>The obvious downside is the added complexity. Namely, on every TLB miss we must make two loads of memory (1) the page directory entry and (2) the page table entry.</html:p>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>31</fr:day></fr:date><fr:title text="What happens when memory is full?">What happens when memory is full?</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>We reserve space on disk for pages that cannot fit in physical memory. This is referred to as <html:em>swap space</html:em>.</html:p>
<html:p>We need to add an additional <html:em>present bit</html:em> to the PTE. On a TLB miss, the hardware (or software) will check the page table and see the present bit to indicate whether the page is in physical memory. If not, we must trap to the OS and this is known as a <html:em>page fault</html:em>.</html:p>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>31</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
The hardware <html:strong>never</html:strong> handles page faults because this would require understanding swap space + knowing how to perform I/O with disk.
</fr:mainmatter></fr:tree>

<html:p>Three important cases to consider:</html:p>
<html:ol><html:li>Page is <html:strong>present</html:strong> and <html:strong>valid</html:strong>.</html:li>
  <html:ul><html:li>Hardware can just grab physical address from PTE.</html:li></html:ul>
  <html:li>Page is not <html:strong>present</html:strong> but <html:strong>valid</html:strong>.</html:li>
  <html:ul><html:li>Hardware must call page fault handler to retrieve page.</html:li></html:ul>
  <html:li>Page is not <html:strong>valid</html:strong>.</html:li>
  <html:ul><html:li>Throw exception and likely terminate process as it is accessing invalid memory.</html:li></html:ul></html:ol>
</fr:mainmatter></fr:tree>
</fr:mainmatter>
            </fr:tree>
            <fr:tree show-metadata="false">
              <fr:frontmatter>
                <fr:authors />
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>8</fr:month>
                  <fr:day>8</fr:day>
                </fr:date>
                <fr:uri>https://kellenkanarios.com/HK73/</fr:uri>
                <fr:display-uri>HK73</fr:display-uri>
                <fr:route>/HK73/</fr:route>
                <fr:title text="Beyond Physical Memory">Beyond Physical Memory</fr:title>
              </fr:frontmatter>
              <fr:mainmatter><html:p>
Up to this point, we have reduced our focus to assuming physical memory was sufficiently large memory. In practice, this is rarely the case. To complete our discussion on memory, we must lift this assumption.
  </html:p>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>8</fr:day></fr:date><fr:title text="Mechanisms">Mechanisms</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>In order to handle overflowing memory, we must reserve some space on physical disk to store the additional pages. This space is referred to as <html:em>swap space</html:em>.
</html:p>
<html:p>
To keep track of such memory, the page table entry instead contains a <html:em>disk address</html:em>. The OS knows what to do because of the additional present bit indicating whether the page is in physical memory. If not, we must trap to the OS and this is known as a <html:em>page fault</html:em>.</html:p>
</fr:mainmatter></fr:tree>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>8</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
The hardware <html:strong>never</html:strong> handles page faults because this would require understanding swap space + knowing how to perform I/O with disk.
</fr:mainmatter></fr:tree>
<html:p>Three important cases to consider:</html:p><html:ol><html:li>Page is <html:strong>present</html:strong> and <html:strong>valid</html:strong>.</html:li>
  <html:ul><html:li>Hardware can just grab physical address from PTE.</html:li></html:ul>
  <html:li>Page is not <html:strong>present</html:strong> but <html:strong>valid</html:strong>.</html:li>
  <html:ul><html:li>Hardware must call page fault handler to retrieve page.</html:li></html:ul>
  <html:li>Page is not <html:strong>valid</html:strong>.</html:li>
  <html:ul><html:li>Throw exception and likely terminate process as it is accessing invalid memory.</html:li></html:ul></html:ol>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>8</fr:day></fr:date><fr:title text="Policies">Policies</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>Now that we know we must occasionally <html:em>page out</html:em> some pages from physical memory to swap spaces. The large question remains:</html:p>

 <html:div class="jms-indent-block" style="
  margin-left: 1em;
  margin-bottom: 1em;
  border-left: 4px solid black;
  padding-left: 12px;
  background-color: whitesmoke;
  ">
  <html:em>What page do you evict at any given time?</html:em>
</html:div>

<html:p>Such a decision is a <html:em>policy</html:em>, and the quality of a policy is often weighed by the <html:em>average mean access time</html:em> (AMAT) given by 
<fr:tex display="block"><![CDATA[AMAT = (1 - P_{miss})T_P + P_{miss} T_D ]]></fr:tex>
where <fr:tex display="inline"><![CDATA[T_P]]></fr:tex> is the time to access physical memory and <fr:tex display="inline"><![CDATA[T_D]]></fr:tex> is time to access disk. For large discrepancies in <fr:tex display="inline"><![CDATA[T_M]]></fr:tex> and <fr:tex display="inline"><![CDATA[T_D]]></fr:tex>, we can have a substantial difference in AMAT for even very low <fr:tex display="inline"><![CDATA[P_{miss}]]></fr:tex>.
</html:p>
<html:p>The "optimal" policy is one that evicts the page whose next use is farthest away. Unfortunately, this is not feasible to implement as we do not know the future.</html:p>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>8</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
A desirable and surprisingly not guaranteed property we want in our policy is the <html:em>stack property</html:em>, which guarantess that if the cache size increases our miss rate gets no worse. This is not the case with FIFO and is known as <html:em>Belady's anomaly</html:em>.
</fr:mainmatter></fr:tree>

<html:p>We instead consider the <html:em>least recently used</html:em> (LRU) heuristic. The effectiveness of such a policy can be attributed to the <html:em>principle of locality</html:em>. Namely, in this case, we enforce temporal locality, where resident pages are close in terms of time accessed. </html:p>

    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>8</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
In practice, we do not implement pure LRU either. This would require maintaining a separate data structure and modifying at every memory access. Instead, we utilize the <html:em>clock algorithm</html:em>, where a reference bit is set to <fr:tex display="inline"><![CDATA[1]]></fr:tex> each time an access occurs. The algorithm then proceeds by looping through all pages 
<html:ol><html:li>If reference bit is <fr:tex display="inline"><![CDATA[1]]></fr:tex>, set to <fr:tex display="inline"><![CDATA[0]]></fr:tex> and proceed to next page.</html:li>
  <html:li>If reference bit is <fr:tex display="inline"><![CDATA[0]]></fr:tex> evict the current page.</html:li></html:ol>
</fr:mainmatter></fr:tree>


    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>8</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
LRU is by no means optimal and in the looping workload (where we loop access one more page than the page table size) we miss 100 percent of the time.
</fr:mainmatter></fr:tree>

</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>8</fr:day></fr:date><fr:title text="Case studies: Useful Tricks">Case studies: Useful Tricks</fr:title></fr:frontmatter><fr:mainmatter>

   
   <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>8</fr:month><fr:day>8</fr:day></fr:date><fr:taxon>Example</fr:taxon></fr:frontmatter><fr:mainmatter>
<html:strong>What happens when you dereference a nullptr?</html:strong> First, we check the TLB for the VPN 0. We miss and then check the page table. The page will be marked invalid, and we will trap to the OS.
</fr:mainmatter></fr:tree>
 

<html:p>LRU is a <html:em>global policy</html:em>, meaning that it does not distinguish the memory use by process. Therefore, memory hog processes can hog memory. To deal with this, one approach is <html:em>segmented FIFO</html:em>, where they maintain a FIFO queue for each process. If the queue exceeds the <html:em>resident set size</html:em> then the first-in page is evicted. They maintain two lists: <html:em>clean page free list</html:em> and <html:em>dirty page list</html:em>. 
<html:ol><html:li>If a page is evicted but free it is put on the clean page free list.</html:li>
  <html:li>Otherwise, it is put on the dirty page list.</html:li></html:ol>
If the original process faults on a page still on the dirty page list it reclaims that page and avoids the I/O.
</html:p>
<html:p><html:em>on-demand zeroing</html:em>
<html:ul><html:li>When heap memory is allocated a lot of it goes unused.</html:li>
  <html:li>Do not need to zero allocated memory until it is used</html:li></html:ul>
<html:em>copy on write</html:em>
<html:ul><html:li>We do not need to copy pages across address spaces unless they are modified.</html:li>
  <html:li>i.e. <html:code>fork()</html:code>, shared libraries, etc.</html:li>
  <html:li>Both VPNs map to same PPN.</html:li>
  <html:li>PTE has additional bits to trap to OS on write.</html:li></html:ul>
<html:em>Page clustering</html:em>
<html:ul><html:li>Cluster small page I/O together and perform one write all at once.</html:li>
  <html:li>Collect large batch from global dirty list.</html:li></html:ul></html:p>
<html:p>A common convention for ease of implementation is also to include the kernel in each process address space. This can be made even more efficiently via <html:em>copy on write</html:em>, where each process will just refer to the same kernel code in physical memory.</html:p>
</fr:mainmatter></fr:tree>
</fr:mainmatter>
            </fr:tree>
          </fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
