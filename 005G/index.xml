<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="/default.xsl"?>
<fr:tree xmlns:fr="http://www.forester-notes.org" xmlns:html="http://www.w3.org/1999/xhtml" xmlns:xml="http://www.w3.org/XML/1998/namespace" root="false" base-url="/">
  <fr:frontmatter>
    <fr:authors>
      <fr:author>
        <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
      </fr:author>
    </fr:authors>
    <fr:date>
      <fr:year>2025</fr:year>
      <fr:month>3</fr:month>
      <fr:day>22</fr:day>
    </fr:date>
    <fr:uri>https://kellenkanarios.com/005G/</fr:uri>
    <fr:display-uri>005G</fr:display-uri>
    <fr:route>/005G/</fr:route>
    <fr:title text="Research Bible">Research Bible</fr:title>
  </fr:frontmatter>
  <fr:mainmatter>
    <html:p>I will be reading and reviewing ~2ish paper a week (tentatively). More accurately, I have allocated roughly 8hrs a week to reading papers. However much I accomplish in this time will determine the actual rate of these reviews. These reviews are mainly just for my own understanding. Rather than techinical details, I will aim to cover
<html:ol><html:li>Existing / related work and their issues.</html:li>
  <html:li>Key components of the methodology and how it solves these issues.</html:li>
  <html:li>Limitations / future directions or relationships to my work.</html:li></html:ol></html:p>
    <html:p>For more in-depth coverage of papers I find particularly interesting, see my <fr:link href="/0002/" title="Blog" uri="https://kellenkanarios.com/0002/" display-uri="0002" type="local">blog</fr:link>. There will likely be overlap i.e. most blogs will start here...</html:p>
    <html:p>See <fr:link href="/007N/" title="Upcoming papers of the week" uri="https://kellenkanarios.com/007N/" display-uri="007N" type="local">upcoming papers</fr:link>!</html:p>
    <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
      <fr:frontmatter>
        <fr:authors>
          <fr:author>
            <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
          </fr:author>
        </fr:authors>
        <fr:date>
          <fr:year>2025</fr:year>
          <fr:month>7</fr:month>
          <fr:day>14</fr:day>
        </fr:date>
        <fr:uri>https://kellenkanarios.com/W4YP/</fr:uri>
        <fr:display-uri>W4YP</fr:display-uri>
        <fr:route>/W4YP/</fr:route>
        <fr:title text="Multi Query Attention">Multi Query Attention</fr:title>
      </fr:frontmatter>
      <fr:mainmatter><html:p>Notes on the paper <fr:link href="/shazeerFastTransformerDecoding2019/" title="Fast Transformer Decoding: One Write-Head is All You Need" uri="https://kellenkanarios.com/shazeerFastTransformerDecoding2019/" display-uri="shazeerFastTransformerDecoding2019" type="local">Fast Transformer Decoding: One Write-Head is All You Need</fr:link>.</html:p><html:p>For, 
<html:ul><html:li><fr:tex display="inline"><![CDATA[b]]></fr:tex> batch dimension,</html:li>
  <html:li><fr:tex display="inline"><![CDATA[n]]></fr:tex> sequence length,</html:li>
  <html:li><fr:tex display="inline"><![CDATA[d]]></fr:tex> hidden dimension,</html:li>
  <html:li><fr:tex display="inline"><![CDATA[h]]></fr:tex> number of heads.</html:li></html:ul>
The total <fr:link href="/4K5H/" title="Floating Point Operations" uri="https://kellenkanarios.com/4K5H/" display-uri="4K5H" type="local">FLOPS</fr:link> for <fr:link href="/004G/" title="Self-Attention" uri="https://kellenkanarios.com/004G/" display-uri="004G" type="local">attention</fr:link> are roughly <fr:tex display="inline"><![CDATA[bnd^2]]></fr:tex>. This comes from 
<html:ol><html:li><fr:tex display="inline"><![CDATA[3nd^2]]></fr:tex> FLOPS to compute <fr:tex display="inline"><![CDATA[Q = XW_Q, K = XW_K, V = XW_V]]></fr:tex>.</html:li>
  <html:li>Need to do this <fr:tex display="inline"><![CDATA[b]]></fr:tex> times for each input in batch.</html:li></html:ol>
and the total memory accesses are roughly <fr:tex display="inline"><![CDATA[\underbrace {bnd}_{X} + \underbrace {bhn^2}_{\text {softmax}} + \underbrace {d^2}_{\text {projection}}]]></fr:tex>.
This gives high arithmetic intensity
<fr:tex display="block"><![CDATA[O\left (\left (\frac {h}{d} + \frac {1}{bn}\right )^{-1}\right )]]></fr:tex></html:p><html:p>However, if we do incremental inference then we must multiply our total number of memory accesses by <fr:tex display="inline"><![CDATA[n]]></fr:tex> i.e. <fr:tex display="inline"><![CDATA[bn^2d + nd^2]]></fr:tex>. This gives arithmetic intensity
<fr:tex display="block"><![CDATA[O\left (\left (\frac {n}{d} + \frac {1}{b}\right )^{-1}\right ),]]></fr:tex>
which requires large batch and short sequence length.
</html:p>
    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
I believe we just ignore the softmax memory contribution in the inference case because it does not scale with <fr:tex display="inline"><![CDATA[n]]></fr:tex> anymore as we are computing the logits just for the next token. Therefore, it becomes a <fr:tex display="inline"><![CDATA[\frac {d}{h}]]></fr:tex> term, which we can safely ignore?
</fr:mainmatter></fr:tree>
<html:p>The key is that the <fr:tex display="inline"><![CDATA[\frac {n}{d}]]></fr:tex> term comes from the <fr:tex display="inline"><![CDATA[bn^2d]]></fr:tex> term, where we are loading <fr:tex display="inline"><![CDATA[h]]></fr:tex> <fr:tex display="inline"><![CDATA[(b \times  n \times  d / h)]]></fr:tex> <fr:tex display="inline"><![CDATA[K]]></fr:tex> and <fr:tex display="inline"><![CDATA[V]]></fr:tex> matrices <fr:tex display="inline"><![CDATA[n]]></fr:tex> times. Thus, we can improve the <fr:tex display="inline"><![CDATA[\frac {n}{d}]]></fr:tex> term by a factor of <fr:tex display="inline"><![CDATA[h]]></fr:tex> by simply not using a different <fr:tex display="inline"><![CDATA[K]]></fr:tex> and <fr:tex display="inline"><![CDATA[V]]></fr:tex> matrix for each head. This is the entire idea behind <fr:link href="/shazeerFastTransformerDecoding2019/" title="Fast Transformer Decoding: One Write-Head is All You Need" uri="https://kellenkanarios.com/shazeerFastTransformerDecoding2019/" display-uri="shazeerFastTransformerDecoding2019" type="local">MQA</fr:link>.</html:p>
    <fr:tree show-metadata="false" toc="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:taxon>Remark</fr:taxon></fr:frontmatter><fr:mainmatter>
Similar to the <fr:link href="https://kellenkanarios.com/TJLA/" type="external">TJLA</fr:link>, we still can use <fr:tex display="inline"><![CDATA[h]]></fr:tex> <fr:tex display="inline"><![CDATA[Q]]></fr:tex> matrices because we do not need to load <fr:tex display="inline"><![CDATA[n]]></fr:tex> of them into memory because only the last one matters for inference.
</fr:mainmatter></fr:tree>
<fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/XUVV/</fr:uri><fr:display-uri>XUVV</fr:display-uri><fr:route>/XUVV/</fr:route><fr:title text="Group Query Attention">Group Query Attention</fr:title></fr:frontmatter><fr:mainmatter><html:p><html:em>Group query attention</html:em> is the same idea as <fr:link href="/shazeerFastTransformerDecoding2019/" title="Fast Transformer Decoding: One Write-Head is All You Need" uri="https://kellenkanarios.com/shazeerFastTransformerDecoding2019/" display-uri="shazeerFastTransformerDecoding2019" type="local">MQA</fr:link> but instead of using one <fr:tex display="inline"><![CDATA[K]]></fr:tex> and <fr:tex display="inline"><![CDATA[V]]></fr:tex> for every head, they use a <html:em>group</html:em> of them. Where obviously the number of groups needs to be less than the number of heads.</html:p><html:figure><html:img width="80%" src="/bafkrmicmjlgi2o3oetsssjdwk6y2pqce4vrdwiw2ah4wwe3ulnt74upkiu.png" />
<html:figcaption>Grouped query uses subset of <fr:tex display="inline"><![CDATA[K]]></fr:tex> and <fr:tex display="inline"><![CDATA[V]]></fr:tex> matrices.</html:figcaption></html:figure></fr:mainmatter></fr:tree><html:p>Also inspired by this idea of reducing the dependence of <fr:tex display="inline"><![CDATA[K]]></fr:tex> and <fr:tex display="inline"><![CDATA[V]]></fr:tex> on the sequence length is sliding window attention.</html:p><fr:tree show-metadata="false"><fr:frontmatter><fr:authors /><fr:date><fr:year>2025</fr:year><fr:month>7</fr:month><fr:day>14</fr:day></fr:date><fr:uri>https://kellenkanarios.com/WM3M/</fr:uri><fr:display-uri>WM3M</fr:display-uri><fr:route>/WM3M/</fr:route><fr:title text="Sliding Window Attention">Sliding Window Attention</fr:title></fr:frontmatter><fr:mainmatter><html:p>The idea behind <html:em>sliding window attention</html:em> is to ensure the number of weight matrices needed for the keys <fr:tex display="inline"><![CDATA[K]]></fr:tex> and values <fr:tex display="inline"><![CDATA[V]]></fr:tex> does not scale with the sequence length. Intuitively, this means allowing each word to "attend" to only some fixed number of previous words rather than the whole sequence</html:p><html:figure><html:img width="80%" src="/bafkrmidqeoo6wx6s4ry6u74fcelfzxvwreyf7d44whnql4ffnnyd2dwcha.png" />
<html:figcaption>"the" only sees "on" and "sat" rather than the full sentence.</html:figcaption></html:figure></fr:mainmatter></fr:tree></fr:mainmatter>
    </fr:tree>
  </fr:mainmatter>
  <fr:backmatter>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="References">References</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>Noam Shazeer</fr:author>
            </fr:authors>
            <fr:date>
              <fr:year>2019</fr:year>
              <fr:month>11</fr:month>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/shazeerFastTransformerDecoding2019/</fr:uri>
            <fr:display-uri>shazeerFastTransformerDecoding2019</fr:display-uri>
            <fr:route>/shazeerFastTransformerDecoding2019/</fr:route>
            <fr:title text="Fast Transformer Decoding: One Write-Head is All You Need">Fast Transformer Decoding: One Write-Head is All You Need</fr:title>
            <fr:taxon>Reference</fr:taxon>
            <fr:meta name="doi">10.48550/arXiv.1911.02150</fr:meta>
            <fr:meta name="external">https://arxiv.org/abs/1911.02150</fr:meta>
            <fr:meta name="bibtex"><![CDATA[@misc{shazeerFastTransformerDecoding2019,
 title = {Fast {{Transformer Decoding}}: {{One Write-Head}} Is {{All You Need}}},
 author = {Shazeer, Noam},
 year = {2019},
 doi = {10.48550/arXiv.1911.02150},
 urldate = {2025-07-14},
 number = {arXiv:1911.02150},
 publisher = {arXiv},
 file = {/home/kellen/Downloads/pdfs/storage/BQ6F9K2H/Shazeer - 2019 - Fast Transformer Decoding One Write-Head is All Y.pdf},
 keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
 langid = {english},
 archiveprefix = {arXiv},
 abstract = {Multi-head attention layers, as used in the Transformer neural sequence model, are a powerful alternative to RNNs for moving information across and between sequences. While training these layers is generally fast and simple, due to parallelizability across the length of the sequence, incremental inference (where such paralleization is impossible) is often slow, due to the memory-bandwidth cost of repeatedly loading the large "keys" and "values" tensors. We propose a variant called multi-query attention, where the keys and values are shared across all of the different attention "heads", greatly reducing the size of these tensors and hence the memory bandwidth requirements of incremental decoding. We verify experimentally that the resulting models can indeed be much faster to decode, and incur only minor quality degradation from the baseline.},
 primaryclass = {cs},
 eprint = {1911.02150},
 month = {November},
 shorttitle = {Fast {{Transformer Decoding}}}
}]]></fr:meta>
          </fr:frontmatter>
          <fr:mainmatter />
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Context">Context</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Backlinks">Backlinks</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>
                <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
              </fr:author>
            </fr:authors>
            <fr:uri>https://kellenkanarios.com/2025-W29/</fr:uri>
            <fr:display-uri>2025-W29</fr:display-uri>
            <fr:route>/2025-W29/</fr:route>
            <fr:title text="Weekly Review 2025-W29">Weekly Review 2025-W29</fr:title>
          </fr:frontmatter>
          <fr:mainmatter>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:title text="The Quantified Me">The Quantified Me</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>This section is in large part to gaslight myself on the internet into being more productive but with the information provided let us introspect on what happened this week. </html:p>
  <html:p><html:strong>Coding:</html:strong> I will now proceed to justify and provide excuses on what went wrong this week. On Monday, we see that I spent a large part of my time on this forest. However, this was actually writing up my notes on <fr:link href="/ESQ3/" title="CS336 Lecture 3" uri="https://kellenkanarios.com/ESQ3/" display-uri="ESQ3" type="local">lecture 3</fr:link> of <fr:link href="/0085/" title="Notebook: Stanford CS336" uri="https://kellenkanarios.com/0085/" display-uri="0085" type="local">CS336</fr:link>. My goal of roughly 1ish hour of miscellaneous learning a day snowballed into what was seemingly <fr:tex display="inline"><![CDATA[4]]></fr:tex> hours of random activity, where I spiraled into <fr:link href="/W4YP/" title="Multi Query Attention" uri="https://kellenkanarios.com/W4YP/" display-uri="W4YP" type="local">MQA</fr:link>. I am thinking of putting this self-study on the backburner in favor of focusing on <fr:link href="/0084/" title="Notebook: Three Easy Pieces" uri="https://kellenkanarios.com/0084/" display-uri="0084" type="local">three easy pieces</fr:link> until the semester starts. I intend to take two courses on what is essentially LLMs systems this fall (very excited), so I might as well not double dip now. I am thinking about using projects 1 and 2 of this course to develop my own working LLM implementation. I can then use it as reference to try out and learn any new optimization tricks like <fr:link href="/W4YP/" title="Multi Query Attention" uri="https://kellenkanarios.com/W4YP/" display-uri="W4YP" type="local">MQA</fr:link> or <fr:link href="https://kellenkanarios.com/TJLA/" type="external">TJLA</fr:link>, etc. 
  <html:p>These plots also finally confirm what I noticed as a general trend in my working life. Namely, I spend a lot of time working Monday-Thu because of my weekly meetings with my advisor on Thursday. However, I do not properly make use of the rest of the week. This is a trend I hope to improve upon in future entries.</html:p></html:p>
<html:figure><html:img width="100%" src="/bafkrmibvtysmzc5gyedcfaj2sxjpviob6lxrcdiontte4cg4zu3cueiv7u.png" />
  <html:figcaption>Wakatime stats for week 2025-W29.</html:figcaption></html:figure>
  <html:p><html:strong>Rest of (computer) life:</html:strong> This week I did a pretty good job staying on task (at least on my computer). Very little brainrot was consumed and a decent amount of work was accomplished. Tune in next week to see if we can keep that up!
  </html:p>
<html:figure><html:img width="100%" src="/bafkrmie3tohm4dhy7zqt47zdirbm4xxk432rr4n3yncjdggmq4zetriwku.png" />
  <html:figcaption>Arbtt-stats for week 2025-W29.</html:figcaption></html:figure>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:title text="VO2 Max(ing)">VO2 Max(ing)</fr:title></fr:frontmatter><fr:mainmatter>
  <html:ul><html:li><html:strong>Current VO2 Max</html:strong>: 53</html:li>
    <html:li><html:strong>Weekly Mileage</html:strong>: 17.2</html:li></html:ul>
  <html:p>Unfortunately, I missed one run this week. The same one I miss every week: Sunday. I will still blame the shin splints, but this may be the last week I can do so (finally!). I am still maintaining a pretty good SPM, but I need to get some more lower HR runs in. From here on out, we should not dip below 20 miles a week. I have some travel coming up at <fr:link href="/rlc/" title="Reinforcement Learning Conference" uri="https://kellenkanarios.com/rlc/" display-uri="rlc" type="local">RLC</fr:link>, but I should be able to still run while I am there.</html:p>
<html:figure><html:img width="100%" src="/bafkrmicxnrelkrspghbameeb74obgst3bk2dj5vlirqeq73qymd7jsjuny.png" />
  <html:figcaption>Running stats for this week.</html:figcaption></html:figure>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:title text="Goals for next week">Goals for next week</fr:title></fr:frontmatter><fr:mainmatter>
<html:p>This is another section, where I gaslight myself into some accountability on the internet.</html:p>
<html:p>For my imaginary audience, you should have a lot to look forward to in the next week. Namely, 
<html:ol><html:li>Look forward to an in-depth blog on <fr:link href="/lipmanFlowMatchingGenerative2023/" title="Flow Matching for Generative Modeling" uri="https://kellenkanarios.com/lipmanFlowMatchingGenerative2023/" display-uri="lipmanFlowMatchingGenerative2023" type="local">flow matching</fr:link> to accompany my <fr:link href="/FMTD/" title="Flow Matching and TD Flows" uri="https://kellenkanarios.com/FMTD/" display-uri="FMTD" type="local">slides</fr:link>.</html:li>
<html:li>I also should have two new <fr:link href="/005G/" title="Research Bible" uri="https://kellenkanarios.com/005G/" display-uri="005G" type="local">research bible</fr:link> entries one on the <fr:link href="/touatiLearningOneRepresentation2021/" title="Learning One Representation to Optimize All Rewards" uri="https://kellenkanarios.com/touatiLearningOneRepresentation2021/" display-uri="touatiLearningOneRepresentation2021" type="local">forward backward representation</fr:link> and the other on <fr:link href="/nachumNearOptimalRepresentationLearning2019/" title="Near-Optimal Representation Learning for Hierarchical Reinforcement Learning" uri="https://kellenkanarios.com/nachumNearOptimalRepresentationLearning2019/" display-uri="nachumNearOptimalRepresentationLearning2019" type="local">hierarchical rl</fr:link>.</html:li>
<html:li>For my <fr:link href="/0084/" title="Notebook: Three Easy Pieces" uri="https://kellenkanarios.com/0084/" display-uri="0084" type="local">OS adventure</fr:link>, you should see me (hopefully) get through memory virtualization.
However, I should definitely get to at least the TLB. Unlikely, I will continue to do all the exercises (because I spend more time writing them down than doing them). I might do one or two of the projects, but they are quite intimidating TBD.</html:li></html:ol>
Check back in next week to see if I am productive! Also TBD if in the future I will put research-related stuff in this review.
</html:p>
</fr:mainmatter></fr:tree>
</fr:mainmatter>
        </fr:tree>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>
                <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
              </fr:author>
            </fr:authors>
            <fr:uri>https://kellenkanarios.com/about/</fr:uri>
            <fr:display-uri>about</fr:display-uri>
            <fr:route>/about/</fr:route>
            <fr:title text="Kellen Kanarios › About this website"><fr:link href="/index/" title="Kellen Kanarios" uri="https://kellenkanarios.com/index/" display-uri="index" type="local">Kellen Kanarios</fr:link> › About this website</fr:title>
          </fr:frontmatter>
          <fr:mainmatter>
            <html:p>
    This is my <fr:link href="https://www.forester-notes.org/index/index.xml" type="external">forest</fr:link> (shoutout to <fr:link href="/jonmsterling/" title="Jon Sterling" uri="https://kellenkanarios.com/jonmsterling/" display-uri="jonmsterling" type="local">Jon Sterling</fr:link> who is remarkably helpful). This website functions both as a <fr:link href="https://en.wikipedia.org/wiki/Personal_knowledge_management" type="external">personal knowledge management system</fr:link>, where I store my notes in <fr:link href="/0015/" title="Notebooks" uri="https://kellenkanarios.com/0015/" display-uri="0015" type="local">notebooks</fr:link> and also have some additional external resources in <fr:link href="/0004/" title="/dev/null" uri="https://kellenkanarios.com/0004/" display-uri="0004" type="local">/dev/null</fr:link>. Additionally, I store my thoughts in a variety of consumption mediums. Namely, short-form notes / blog posts can be found in the "<fr:link href="/007L/" title="Marginalia" uri="https://kellenkanarios.com/007L/" display-uri="007L" type="local">marginalia</fr:link>". I also maintain two weekly posting obligations: a <fr:link href="/007S/" title="Weeknotes" uri="https://kellenkanarios.com/007S/" display-uri="007S" type="local">weeknotes / lifelog</fr:link> and a <fr:link href="/005G/" title="Research Bible" uri="https://kellenkanarios.com/005G/" display-uri="005G" type="local">paper of the week</fr:link>. 
      </html:p>
          </fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Related">Related</fr:title>
      </fr:frontmatter>
      <fr:mainmatter>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors />
            <fr:date>
              <fr:year>2025</fr:year>
              <fr:month>6</fr:month>
              <fr:day>5</fr:day>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/007N/</fr:uri>
            <fr:display-uri>007N</fr:display-uri>
            <fr:route>/007N/</fr:route>
            <fr:title text="Upcoming papers of the week">Upcoming papers of the week</fr:title>
          </fr:frontmatter>
          <fr:mainmatter>
            <html:p>Here I am storing interesting papers I come across and want to review at some point.</html:p>
            <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
              <fr:frontmatter>
                <fr:authors>
                  <fr:author>Ofir Nachum</fr:author>
                  <fr:author>Shixiang Gu</fr:author>
                  <fr:author>Honglak Lee</fr:author>
                  <fr:author>Sergey Levine</fr:author>
                </fr:authors>
                <fr:date>
                  <fr:year>2019</fr:year>
                  <fr:month>1</fr:month>
                </fr:date>
                <fr:uri>https://kellenkanarios.com/nachumNearOptimalRepresentationLearning2019/</fr:uri>
                <fr:display-uri>nachumNearOptimalRepresentationLearning2019</fr:display-uri>
                <fr:route>/nachumNearOptimalRepresentationLearning2019/</fr:route>
                <fr:title text="Near-Optimal Representation Learning for Hierarchical Reinforcement Learning">Near-Optimal Representation Learning for Hierarchical Reinforcement Learning</fr:title>
                <fr:taxon>Reference</fr:taxon>
                <fr:meta name="external">https://arxiv.org/abs/1810.01257</fr:meta>
                <fr:meta name="bibtex"><![CDATA[@misc{nachumNearOptimalRepresentationLearning2019,
 title = {Near-{{Optimal Representation Learning}} for {{Hierarchical Reinforcement Learning}}},
 author = {Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
 year = {2019},
 urldate = {2024-11-07},
 number = {arXiv:1810.01257},
 publisher = {arXiv},
 file = {/home/kellen/Downloads/pdfs/storage/SIK848RC/Nachum et al. - 2019 - Near-Optimal Representation Learning for Hierarchical Reinforcement Learning.pdf},
 keywords = {Computer Science - Artificial Intelligence},
 langid = {english},
 archiveprefix = {arXiv},
 abstract = {We study the problem of representation learning in goal-conditioned hierarchical reinforcement learning. In such hierarchical structures, a higher-level controller solves tasks by iteratively communicating goals which a lower-level policy is trained to reach. Accordingly, the choice of representation -- the mapping of observation space to goal space -- is crucial. To study this problem, we develop a notion of sub-optimality of a representation, defined in terms of expected reward of the optimal hierarchical policy using this representation. We derive expressions which bound the sub-optimality and show how these expressions can be translated to representation learning objectives which may be optimized in practice. Results on a number of difficult continuous-control tasks show that our approach to representation learning yields qualitatively better representations as well as quantitatively better hierarchical policies, compared to existing methods (see videos at https://sites.google.com/view/representation-hrl).},
 primaryclass = {cs},
 eprint = {1810.01257},
 month = {January}
}]]></fr:meta>
              </fr:frontmatter>
              <fr:mainmatter />
            </fr:tree>
            <html:p>Taking requests below!</html:p>
            <html:script src="https://utteranc.es/client.js" repo="kkanarios32/website-comments" issue-term="poaw-requests" theme="boxy-light" crossorigin="anonymous" async="" />
          </fr:mainmatter>
        </fr:tree>
        <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
          <fr:frontmatter>
            <fr:authors>
              <fr:author>
                <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
              </fr:author>
            </fr:authors>
            <fr:date>
              <fr:year>2024</fr:year>
              <fr:month>10</fr:month>
              <fr:day>29</fr:day>
            </fr:date>
            <fr:uri>https://kellenkanarios.com/0002/</fr:uri>
            <fr:display-uri>0002</fr:display-uri>
            <fr:route>/0002/</fr:route>
            <fr:title text="Blog">Blog</fr:title>
          </fr:frontmatter>
          <fr:mainmatter>
            <html:p>This is my blog, in which I write about a variety of topics including computer science, mathematics, and more. For more short-form blogs, see the <fr:link href="/007L/" title="Marginalia" uri="https://kellenkanarios.com/007L/" display-uri="007L" type="local">marginalia</fr:link>. See <fr:link href="/007M/" title="Upcoming Blogs" uri="https://kellenkanarios.com/007M/" display-uri="007M" type="local">upcoming blogs</fr:link> and feel free to request! This blog also has a corresponding <fr:link href="/0002/atom.xml" type="external">Atom feed</fr:link>.</html:p>
            <fr:tree show-metadata="true" expanded="false" toc="false" numbered="false">
              <fr:frontmatter>
                <fr:authors>
                  <fr:author>
                    <fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link>
                  </fr:author>
                </fr:authors>
                <fr:date>
                  <fr:year>2025</fr:year>
                  <fr:month>3</fr:month>
                  <fr:day>4</fr:day>
                </fr:date>
                <fr:uri>https://kellenkanarios.com/005F/</fr:uri>
                <fr:display-uri>005F</fr:display-uri>
                <fr:route>/005F/</fr:route>
                <fr:title text="Rebuilding My (Neo)Vim Config From Scratch">Rebuilding My (Neo)Vim Config From Scratch</fr:title>
              </fr:frontmatter>
              <fr:mainmatter><html:p>I have been using LazyVim for some time now, but I have now run into issues multiple times where understanding how LazyVim is doing something is far more difficult than if I had written my own setup. I allocated one day for this adventure and really just wanted to make sure I had support for <fr:tex display="inline"><![CDATA[\TeX ]]></fr:tex>, python, forester, and C/C++. Due to my (self-imposed) time constraint, I do not have the associated resources linked for each of the things discussed below. At some point, I hope to come back and more thoroughly cover each of the components.
</html:p>
  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Sane Defaults">Sane Defaults</fr:title></fr:frontmatter><fr:mainmatter>
To my surprise, a lot of the features that I had come to take for granted were actually options set up internally by Lazyvim. For example, I was shocked with 8 space indents!! and I could not even copy from one terminal instance to another... Due to this, I went and found all of the options I liked from Lazyvim and added them to my new configuration in <html:code>configs/options.lua</html:code>.
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Installing a Plugin Manager">Installing a Plugin Manager</fr:title></fr:frontmatter><fr:mainmatter>
For this, we will be using the defacto standard <html:code>lazy.nvim</html:code>. This is actually straightforward and kind of "just works". Just follow the installation guide in their documentation.
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Setting up Auto Complete">Setting up Auto Complete</fr:title></fr:frontmatter><fr:mainmatter>
This is one of the main motivations for me making the switch. It seems <html:code>nvim-cmp</html:code> has finally been replaced with a new <html:code>blink.cmp</html:code>, so that is what we will be using.


  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Rebuilding My (Neo)Vim Config From Scratch › Language Server Protocol"><fr:link href="/005F/" title="Rebuilding My (Neo)Vim Config From Scratch" uri="https://kellenkanarios.com/005F/" display-uri="005F" type="local">Rebuilding My (Neo)Vim Config From Scratch</fr:link> › Language Server Protocol</fr:title></fr:frontmatter><fr:mainmatter>
It turns out there is a lot that goes into getting LSP setup correctly.
<html:ol><html:li>First we must actually install the language servers. To do this the easiest way, we use the <html:code>mason.nvim</html:code> and <html:code>mason.nvim-lspconfig</html:code> plugins. At some point, I might actually figure out how to set up lsp myself without lspconfig but that point is not now.
</html:li>
<html:li>Through <html:code>nvim-lspconfig</html:code>, we can set up each of the servers we want to have LSP support. I just set up clangd, pyright, and texlab.</html:li></html:ol>
This was a bit ridiculous. The first of many challenges was around import resolution in python. To remedy this, I needed to write a function to find the virtual environment directory and then set the <html:code>pythonPath</html:code> to the venv python binary. Previously, I think I was just using pylsp and installing it as a pip package to each python venv. I much prefer the new way, and I think pyright is overall a much better lsp.
</fr:mainmatter></fr:tree>


  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Rebuilding My (Neo)Vim Config From Scratch › Forester Completion"><fr:link href="/005F/" title="Rebuilding My (Neo)Vim Config From Scratch" uri="https://kellenkanarios.com/005F/" display-uri="005F" type="local">Rebuilding My (Neo)Vim Config From Scratch</fr:link> › Forester Completion</fr:title></fr:frontmatter><fr:mainmatter>
  Another necessary completion source for me is the one provided by <html:code>forester.nvim</html:code>. Similar to vimtex, the reference completion support is VERY useful. Obviously, I need completion when I am writing this blog!!! This was a little more involved. The first difficulty was that the completion source provided by the <html:code>forester.nvim</html:code> plugin was for <html:code>nvim-cmp</html:code>. It turns out this is a prevalent enough problem that the author of <html:code>blink.cmp</html:code> wrote an additional plugin <html:code>blink.compat</html:code> to allow for <html:code>nvim-cmp</html:code> completion sources. While this sounds all fine and good, <html:code>nvim-compat</html:code> expects plugins that return the completion source themselves, whereas in <html:code>forester.nvim</html:code> the completion source is just one submodule of a more feature-rich plugin. To get around this, I needed to look into the <html:code>blink.compat</html:code> code and find how they are registering the sources and just do it myself.
</fr:mainmatter></fr:tree>

</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Snippets">Snippets</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>
  Going all the way back to the <fr:link href="https://castel.dev/post/lecture-notes-1/" type="external">Gilles Castel blog post</fr:link>, I have always been partial to snippets that auto-expand. I had them set up prior to Lazyvim but with Lazyvim I had resigned to using friendly-snippets with native nvim snippets. Since I was already redoing everything, this time around I decided not to compromise. Once upon a time (right when it came out I think?) I tried out Luasnips, but it seems that they now have far more extensive features. They are also natively supported by <html:code>blink.cmp</html:code>!! It feels necessary that I plug the <fr:link href="https://github.com/iurimateus/luasnip-latex-snippets.nvim" type="external">awesome repo</fr:link> that ports the original Ultisnips snippets to Luasnip. With this, I was able to easily add my own forester snippets!!!
  </html:p>
  <html:p>
  A fun little thing that I had been hoping to do for awhile and is finally now possible - I can load latex snippets when inside math environments in forester!!!! To do this, I looked into the forester treesitter grammar and found the corresponding nodetypes for math envs. It was then straightforward to detect whether we were in a math env and to load the associated latex snippets.
  </html:p>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Anki">Anki</fr:title></fr:frontmatter><fr:mainmatter>
  <html:p>
  There is a very cool add-on to anki called <fr:link href="https://git.sr.ht/~foosoft/anki-connectdeck-actions" type="external">AnkiConnect</fr:link> that has an associated plugin <html:code>anki.nvim</html:code>. Basically, AnkiConnects allows you to make requests to Anki and receive/send useful information from/to your decks. Unfortunately, <html:code>anki.nvim</html:code> built-in commands didn't seem all that useful to me. However, it provided the necessary infrastructure for me to accomplish my desired workflow.
  </html:p>
  <html:p>
  Namely, I made my own command that queries Anki for the deck names, which you can then pick from using telescope pickers. When you select one it will create a new flashcard in a specified flashcard directory under a directory created based on the deck name. You can then send this card to that deck using the existing <html:code>AnkiSend</html:code> command.
  </html:p>
  <html:p>I also continued the snippet fun here. When writing Anki cards, you can write latex code between [latex] [/latex] delimiters. I wrote a quick function to detect whether we are in these delimiters and if we are then to load the latex snippets from the previous section. I also added some basic anki filetype plugins to insert things like these delimiters.</html:p>
</fr:mainmatter></fr:tree>

  <fr:tree show-metadata="false"><fr:frontmatter><fr:authors><fr:author><fr:link href="/kellenkanarios/" title="Kellen Kanarios" uri="https://kellenkanarios.com/kellenkanarios/" display-uri="kellenkanarios" type="local">Kellen Kanarios</fr:link></fr:author></fr:authors><fr:date><fr:year>2025</fr:year><fr:month>3</fr:month><fr:day>4</fr:day></fr:date><fr:title text="Formatters and Linters">Formatters and Linters</fr:title></fr:frontmatter><fr:mainmatter>
  <html:code>compat.nvim</html:code>, <html:code>mason.nvim</html:code>, black, isort.
</fr:mainmatter></fr:tree>
<html:script src="https://utteranc.es/client.js" repo="kkanarios32/website-comments" issue-term="nvim" theme="boxy-light" crossorigin="anonymous" async="" /></fr:mainmatter>
            </fr:tree>
          </fr:mainmatter>
        </fr:tree>
      </fr:mainmatter>
    </fr:tree>
    <fr:tree show-metadata="false" hidden-when-empty="true">
      <fr:frontmatter>
        <fr:authors />
        <fr:title text="Contributions">Contributions</fr:title>
      </fr:frontmatter>
      <fr:mainmatter />
    </fr:tree>
  </fr:backmatter>
</fr:tree>
